import logging
import time
from datetime import datetime, timezone
from typing import Dict, List, Optional

from fastapi import (
    APIRouter,
    Depends,
    HTTPException,
    WebSocket,
    WebSocketDisconnect,
    status,
)

logger = logging.getLogger(__name__)

from ... import schemas  # Relative imports for app directory
from ...core.auth import User, require_verification_triggerer  # Placeholder auth
from ...core.bias_detector import bias_detector

# Task 7 imports
from ...core.parallel_validation_pipeline import parallel_pipeline
from ...core.safety_conflict_checker import conflict_detector, safety_property_checker

# Phase 3 imports
from ...core.tiered_validation import tiered_validation_pipeline
from ...core.verification_logic import verify_policy_rules
from ...services.ac_client import ACPrinciple, ac_service_client
from ...services.integrity_client import PolicyRule, integrity_service_client


# Local implementations to avoid shared module dependencies
class MockWebSocketStreamer:
    async def connect(self, websocket, client_id):
    // requires: Valid input parameters
    // ensures: Correct function execution
    // sha256: func_hash
        await websocket.accept()

    async def disconnect(self, websocket):
    // requires: Valid input parameters
    // ensures: Correct function execution
    // sha256: func_hash
        pass

    async def send_alert(self, alert_type: str, details: dict):
    // requires: Valid input parameters
    // ensures: Correct function execution
    // sha256: func_hash
        pass

    async def get_connection_stats(self):
    // requires: Valid input parameters
    // ensures: Correct function execution
    // sha256: func_hash
        return {"active_connections": 0}


websocket_streamer = MockWebSocketStreamer()

router = APIRouter()


# Local service authentication
async def get_service_token():
    // requires: Valid input parameters
    // ensures: Correct function execution
    // sha256: func_hash
    """Mock function to get service token."""
    return "mock_service_token"


@router.post(
    "/", response_model=schemas.VerificationResponse, status_code=status.HTTP_200_OK
)
async def verify_policies(
    request_data: schemas.VerificationRequest,
    current_user: User = Depends(
        require_verification_triggerer
    ),  # Protect this endpoint
):
    """
    Orchestrates the formal verification of Datalog policy rules against AC principles.
    """
    if not request_data.policy_rule_refs:
        raise HTTPException(
            status_code=400,
            detail="No policy rule references provided for verification.",
        )

    # 1. Fetch Policy Rules from Integrity Service
    policy_rules_to_verify: List[PolicyRule] = []
    rule_ids_to_fetch = [ref.id for ref in request_data.policy_rule_refs]

    fetched_rules_from_integrity = (
        await integrity_service_client.get_policy_rules_by_ids(
            rule_ids=rule_ids_to_fetch, auth_token=INTEGRITY_SERVICE_MOCK_TOKEN
        )
    )
    if len(fetched_rules_from_integrity) != len(rule_ids_to_fetch):
        # Handle case where some rules couldn't be fetched
        # For now, raising an error. Could also proceed with found rules.
        found_ids = {r.id for r in fetched_rules_from_integrity}
        missing_ids = set(rule_ids_to_fetch) - found_ids
        raise HTTPException(
            status_code=404,
            detail=f"Could not fetch policy rules with IDs: {list(missing_ids)} from Integrity Service.",
        )
    policy_rules_to_verify = fetched_rules_from_integrity

    # 2. Determine and Fetch AC Principles
    # Principles can be directly referenced in the request or derived from the policy rules.
    ac_principles_for_obligations: List[ACPrinciple] = []
    principle_ids_to_fetch = set()

    if request_data.ac_principle_refs:
        for ref in request_data.ac_principle_refs:
            principle_ids_to_fetch.add(ref.id)
    else:
        # If not specified, use source_principle_ids from the fetched policy rules
        for rule in policy_rules_to_verify:
            if rule.source_principle_ids:
                for pid in rule.source_principle_ids:
                    principle_ids_to_fetch.add(pid)

    if not principle_ids_to_fetch:
        # If no principles are identified, verification cannot proceed meaningfully against custom obligations
        # Or, it could mean verification against a "default" set of obligations, if applicable.
        # For now, let's assume principles are required.
        results = [
            schemas.VerificationResult(
                policy_rule_id=rule.id,
                status="error",
                message="No AC principles identified for deriving proof obligations.",
            )
            for rule in policy_rules_to_verify
        ]
        return schemas.VerificationResponse(
            results=results,
            overall_status="error",
            summary_message="Missing AC principle context.",
        )

    service_token = await get_service_token()
    fetched_ac_principles = await ac_service_client.list_principles_by_ids(
        principle_ids=list(principle_ids_to_fetch), auth_token=service_token
    )
    if len(fetched_ac_principles) != len(principle_ids_to_fetch):
        found_pids = {p.id for p in fetched_ac_principles}
        missing_pids = principle_ids_to_fetch - found_pids
        # Decide: error out, or proceed with found principles?
        # For now, proceed with found principles, but a real system might log/error.
        print(f"Warning: Could not fetch AC principles with IDs: {list(missing_pids)}")
        if not fetched_ac_principles:
            results = [
                schemas.VerificationResult(
                    policy_rule_id=rule.id,
                    status="error",
                    message=f"Could not fetch any of the specified AC principles: {list(missing_pids)}.",
                )
                for rule in policy_rules_to_verify
            ]
            return schemas.VerificationResponse(
                results=results,
                overall_status="error",
                summary_message="AC principle fetching failed.",
            )

    ac_principles_for_obligations = fetched_ac_principles

    # 3. Perform Verification using Verification Logic
    verification_results: List[schemas.VerificationResult] = await verify_policy_rules(
        policy_rules=policy_rules_to_verify, ac_principles=ac_principles_for_obligations
    )

    # 4. Update verification status in Integrity Service for each rule
    for result in verification_results:
        # Only update if status is not "error" (error might be due to FV service itself)
        if result.status in ["verified", "failed"]:
            updated_rule = await integrity_service_client.update_policy_rule_status(
                rule_id=result.policy_rule_id,
                status=result.status,  # "verified" or "failed"
                auth_token=INTEGRITY_SERVICE_MOCK_TOKEN,
            )
            if not updated_rule:
                result.message = (
                    result.message or ""
                ) + f" | Failed to update status in Integrity Service."
                # Potentially change result.status to "error_updating_status" here if needed

    # 5. Determine overall status and return response
    overall_status = "all_verified"
    if any(r.status == "failed" for r in verification_results):
        overall_status = "some_failed"
    if any(r.status == "error" for r in verification_results):
        overall_status = "error"  # Or more granular if mixed results

    summary = (
        f"Verification process completed. {len(verification_results)} rules processed."
    )
    if overall_status == "error":
        summary += " Errors occurred during verification."

    return schemas.VerificationResponse(
        results=verification_results,
        overall_status=overall_status,
        summary_message=summary,
    )


# --- Phase 3: Advanced Verification Endpoints ---


@router.post(
    "/tiered",
    response_model=schemas.TieredVerificationResponse,
    status_code=status.HTTP_200_OK,
)
async def tiered_verification(
    request_data: schemas.TieredVerificationRequest,
    current_user: User = Depends(require_verification_triggerer),
):
    """
    Phase 3: Tiered formal verification with Automated, HITL, and Rigorous validation levels.
    """
    if not request_data.policy_rule_refs:
        raise HTTPException(
            status_code=400,
            detail="No policy rule references provided for tiered verification.",
        )

    # Fetch Policy Rules from Integrity Service
    rule_ids_to_fetch = [ref.id for ref in request_data.policy_rule_refs]

    fetched_rules = await integrity_service_client.get_policy_rules_by_ids(
        rule_ids=rule_ids_to_fetch, auth_token=INTEGRITY_SERVICE_MOCK_TOKEN
    )

    if len(fetched_rules) != len(rule_ids_to_fetch):
        found_ids = {r.id for r in fetched_rules}
        missing_ids = set(rule_ids_to_fetch) - found_ids
        raise HTTPException(
            status_code=404,
            detail=f"Could not fetch policy rules with IDs: {list(missing_ids)} from Integrity Service.",
        )

    # Fetch AC Principles for context
    principle_ids_to_fetch = set()
    for rule in fetched_rules:
        if rule.source_principle_ids:
            for pid in rule.source_principle_ids:
                principle_ids_to_fetch.add(pid)

    ac_principles = []
    if principle_ids_to_fetch:
        service_token = await get_service_token()
        ac_principles = await ac_service_client.list_principles_by_ids(
            principle_ids=list(principle_ids_to_fetch), auth_token=service_token
        )

    # Perform tiered validation
    response = await tiered_validation_pipeline.validate_tiered(
        request=request_data, policy_rules=fetched_rules, ac_principles=ac_principles
    )

    return response


@router.post(
    "/safety-check",
    response_model=schemas.SafetyCheckResponse,
    status_code=status.HTTP_200_OK,
)
async def safety_property_check(
    request_data: schemas.SafetyCheckRequest,
    current_user: User = Depends(require_verification_triggerer),
):
    """
    Phase 3: Safety property verification for policy rules.
    """
    if not request_data.safety_properties:
        raise HTTPException(
            status_code=400, detail="No safety properties provided for verification."
        )

    # For this endpoint, we'll check safety properties against all active policy rules
    # In a real implementation, you might want to specify which rules to check
    all_rules = await integrity_service_client.get_all_policy_rules(
        auth_token=INTEGRITY_SERVICE_MOCK_TOKEN
    )

    # Perform safety property checking
    response = await safety_property_checker.check_safety_properties(
        request=request_data, policy_rules=all_rules
    )

    return response


@router.post(
    "/conflict-check",
    response_model=schemas.ConflictCheckResponse,
    status_code=status.HTTP_200_OK,
)
async def conflict_detection(
    request_data: schemas.ConflictCheckRequest,
    current_user: User = Depends(require_verification_triggerer),
):
    """
    Phase 3: Conflict detection between policy rule sets.
    """
    if not request_data.rule_sets:
        raise HTTPException(
            status_code=400, detail="No rule sets provided for conflict detection."
        )

    # Fetch rules for each rule set
    # In this simplified implementation, we'll treat rule_sets as categories or tags
    # In a real implementation, you'd have a more sophisticated rule set management system
    all_rules_by_set: Dict[str, List[PolicyRule]] = {}

    for rule_set_name in request_data.rule_sets:
        # For demonstration, we'll fetch all rules and filter by a hypothetical category
        # In practice, you'd have proper rule set management
        all_rules = await integrity_service_client.get_all_policy_rules(
            auth_token=INTEGRITY_SERVICE_MOCK_TOKEN
        )

        # Simple filtering - in practice, you'd have proper rule set categorization
        filtered_rules = [
            rule
            for rule in all_rules
            if rule_set_name.lower() in rule.rule_content.lower()
        ]
        all_rules_by_set[rule_set_name] = filtered_rules

    # Perform conflict detection
    response = await conflict_detector.detect_conflicts(
        request=request_data, all_policy_rules=all_rules_by_set
    )

    return response


@router.get(
    "/validation-status/{rule_id}", response_model=Dict, status_code=status.HTTP_200_OK
)
async def get_validation_status(
    rule_id: int, current_user: User = Depends(require_verification_triggerer)
):
    """
    Phase 3: Get comprehensive validation status for a specific rule.
    """
    # Fetch the rule
    try:
        rules = await integrity_service_client.get_policy_rules_by_ids(
            rule_ids=[rule_id], auth_token=INTEGRITY_SERVICE_MOCK_TOKEN
        )

        if not rules:
            raise HTTPException(
                status_code=404, detail=f"Policy rule {rule_id} not found."
            )

        rule = rules[0]

        # Return comprehensive status information
        # In a real implementation, this would query validation history, cache results, etc.
        return {
            "rule_id": rule_id,
            "rule_content": rule.rule_content,
            "verification_status": rule.verification_status,
            "last_verified": rule.verified_at,
            "available_validation_tiers": [
                "automated",
                "human_in_the_loop",
                "rigorous",
            ],
            "safety_check_status": "not_checked",  # Would be populated from actual checks
            "conflict_status": "not_checked",  # Would be populated from actual checks
            "recommendations": [
                "Consider running tiered validation for comprehensive verification",
                "Safety property checking recommended for critical rules",
                "Conflict detection recommended when multiple rule sets are active",
            ],
        }

    except Exception as e:
        raise HTTPException(
            status_code=500, detail=f"Error retrieving validation status: {str(e)}"
        )


# --- Task 7: Parallel Validation Pipeline Endpoints ---


@router.post(
    "/parallel",
    response_model=schemas.VerificationResponse,
    status_code=status.HTTP_200_OK,
)
async def parallel_verify_policies(
    request_data: schemas.VerificationRequest,
    current_user: User = Depends(require_verification_triggerer),
    enable_parallel: bool = True,
    amendment_id: Optional[int] = None,
    voting_session_id: Optional[str] = None,
    governance_workflow_stage: str = "validation",
):
    """
    Task 7: Enhanced parallel policy verification with constitutional compliance and 1000+ concurrent validations.

    Features:
    - 1000+ concurrent constitutional decision validations
    - 90% resource utilization efficiency
    - Constitutional Council workflow integration
    - Federated evaluation framework integration
    - Real-time performance monitoring and alerting
    - Comprehensive error handling with rollback capabilities
    """
    if not request_data.policy_rule_ids:
        raise HTTPException(
            status_code=400, detail="No policy rule IDs provided for verification."
        )

    try:
        # Task 7: Create constitutional validation context
        constitutional_context = None
        if amendment_id or voting_session_id:
            from ..core.parallel_validation_pipeline import (
                ConstitutionalValidationContext,
            )

            constitutional_context = ConstitutionalValidationContext(
                amendment_id=amendment_id,
                voting_session_id=voting_session_id,
                governance_workflow_stage=governance_workflow_stage,
                democratic_legitimacy_required=True,
            )

        # Use enhanced parallel validation pipeline
        response = await parallel_pipeline.process_verification_request(
            request_data,
            enable_parallel=enable_parallel,
            constitutional_context=constitutional_context,
        )
        return response

    except Exception as e:
        raise HTTPException(
            status_code=500, detail=f"Parallel verification failed: {str(e)}"
        )


@router.post("/constitutional-compliance", status_code=200)
async def verify_constitutional_compliance(
    request_data: dict,
    current_user: User = Depends(require_verification_triggerer),
):
    """
    Phase 2 Enhanced Constitutional Compliance Verification with Z3 Formal Proofs.

    This endpoint provides comprehensive constitutional verification with:
    - Z3 theorem prover integration
    - Mathematical proof generation
    - Checksum validation following ACGS-1 Protocol v2.0
    - Constitutional compliance certificates
    - Formal verification with constitutional integrity
    """
    import time
    from ..core.constitutional_verification_engine import (
        ConstitutionalVerificationEngine,
        ConstitutionalProperty,
        VerificationLevel,
        get_constitutional_verification_engine,
    )

    verification_start = time.time()

    try:
        # Extract request parameters
        policy_content = request_data.get("policy_content", "")
        if not policy_content:
            raise HTTPException(
                status_code=400,
                detail="Policy content is required for constitutional verification"
            )

        verification_level_str = request_data.get("verification_level", "standard")
        verification_level = VerificationLevel(verification_level_str)

        # Extract constitutional properties
        properties_data = request_data.get("constitutional_properties", [])
        constitutional_properties = []

        for prop_data in properties_data:
            prop = ConstitutionalProperty(
                property_id=prop_data.get("property_id", f"prop-{len(constitutional_properties)}"),
                name=prop_data.get("name", "Constitutional Property"),
                description=prop_data.get("description", ""),
                formal_specification=prop_data.get("formal_specification", ""),
                constitutional_principle_id=prop_data.get("constitutional_principle_id", ""),
                verification_level=verification_level,
            )
            constitutional_properties.append(prop)

        # If no properties provided, create default constitutional properties
        if not constitutional_properties:
            default_properties = [
                ConstitutionalProperty(
                    property_id="const-compliance-1",
                    name="Constitutional Integrity",
                    description="Policy must maintain constitutional integrity",
                    formal_specification="constitutional_integrity(policy) => compliant(policy)",
                    constitutional_principle_id="cdd01ef066bc6cf2",
                    verification_level=verification_level,
                ),
                ConstitutionalProperty(
                    property_id="const-compliance-2",
                    name="Democratic Governance",
                    description="Policy must support democratic governance principles",
                    formal_specification="democratic_governance(policy) => legitimate(policy)",
                    constitutional_principle_id="cdd01ef066bc6cf2",
                    verification_level=verification_level,
                ),
                ConstitutionalProperty(
                    property_id="const-compliance-3",
                    name="Rights Protection",
                    description="Policy must protect fundamental rights",
                    formal_specification="rights_protection(policy) => constitutional(policy)",
                    constitutional_principle_id="cdd01ef066bc6cf2",
                    verification_level=verification_level,
                ),
            ]
            constitutional_properties = default_properties

        # Get constitutional verification engine
        verification_engine = await get_constitutional_verification_engine()

        # Perform constitutional compliance verification
        verification_result = await verification_engine.verify_constitutional_compliance(
            policy_content=policy_content,
            constitutional_properties=constitutional_properties,
            verification_level=verification_level
        )

        # Calculate total response time
        total_time_ms = (time.time() - verification_start) * 1000

        # Enhance result with Phase 2 specific information
        enhanced_result = {
            **verification_result,
            "phase2_enhancements": {
                "z3_theorem_prover": "integrated",
                "formal_proof_generation": "enabled",
                "checksum_validation": "protocol_v2.0_compliant",
                "constitutional_hash_verified": verification_result.get("constitutional_compliance", {}).get("constitutional_hash") == "cdd01ef066bc6cf2",
            },
            "performance_analysis": {
                "total_response_time_ms": total_time_ms,
                "verification_efficiency": "optimized" if total_time_ms < 5000 else "standard",
                "formal_proof_count": len(verification_result.get("formal_proofs", [])),
                "properties_verified": len(constitutional_properties),
            },
            "protocol_compliance": {
                "acgs_protocol_version": "v2.0",
                "checksum_format": "sha256_16char",
                "constitutional_reference": "cdd01ef066bc6cf2",
                "formal_verification_standard": "z3_smt_solver",
            },
        }

        logger.info(
            f"Constitutional compliance verification completed in {total_time_ms:.2f}ms: "
            f"{'COMPLIANT' if verification_result.get('constitutional_compliance', {}).get('overall_compliant') else 'NON-COMPLIANT'}"
        )

        return enhanced_result

    except Exception as e:
        total_time_ms = (time.time() - verification_start) * 1000
        logger.error(f"Constitutional compliance verification failed after {total_time_ms:.2f}ms: {e}")

        raise HTTPException(
            status_code=500,
            detail=f"Constitutional compliance verification failed: {str(e)}"
        )


@router.post("/generate-formal-proof", status_code=200)
async def generate_formal_proof(
    request_data: dict,
    current_user: User = Depends(require_verification_triggerer),
):
    """
    Generate formal mathematical proof for constitutional property verification.

    This endpoint provides Z3-based formal proof generation with:
    - Mathematical proof steps
    - Constitutional compliance verification
    - Checksum validation
    - Proof integrity verification
    """
    import time
    from ..core.constitutional_verification_engine import (
        ProofType,
        get_constitutional_verification_engine,
    )

    proof_start = time.time()

    try:
        # Extract proof parameters
        property_specification = request_data.get("property_specification", "")
        if not property_specification:
            raise HTTPException(
                status_code=400,
                detail="Property specification is required for formal proof generation"
            )

        policy_constraints = request_data.get("policy_constraints", [])
        proof_type_str = request_data.get("proof_type", "constitutional_compliance")
        proof_type = ProofType(proof_type_str)

        # Get verification engine
        verification_engine = await get_constitutional_verification_engine()

        # Generate formal proof
        formal_proof = await verification_engine.generate_formal_proof(
            property_specification=property_specification,
            policy_constraints=policy_constraints,
            proof_type=proof_type
        )

        # Calculate response time
        proof_time_ms = (time.time() - proof_start) * 1000

        # Prepare comprehensive proof response
        proof_response = {
            "proof_id": formal_proof.proof_id,
            "property_id": formal_proof.property_id,
            "proof_type": formal_proof.proof_type.value,
            "verification_level": formal_proof.verification_level.value,

            # Proof content with ACGS-1 Protocol v2.0 format
            "formal_proof": {
                "proof_steps": formal_proof.proof_steps,
                "z3_model": formal_proof.z3_model,
                "counter_example": formal_proof.counter_example,
                "proof_checksum": formal_proof.proof_checksum,
            },

            # Verification results
            "verification_result": {
                "verified": formal_proof.verified,
                "confidence_score": formal_proof.confidence_score,
                "constitutional_compliance": formal_proof.compliance_verified,
                "constitutional_hash": formal_proof.constitutional_hash,
            },

            # Performance metrics
            "performance_metrics": {
                "proof_generation_time_ms": proof_time_ms,
                "verification_time_ms": formal_proof.verification_time_ms,
                "proof_steps_count": len(formal_proof.proof_steps),
                "z3_solver_performance": "optimal" if proof_time_ms < 1000 else "standard",
            },

            # Protocol compliance
            "protocol_compliance": {
                "checksum_format": "sha256_16char",
                "proof_format": "acgs_protocol_v2.0",
                "constitutional_reference": "cdd01ef066bc6cf2",
                "formal_verification_engine": "z3_smt_solver",
            },

            "timestamp": formal_proof.timestamp.isoformat(),
        }

        logger.info(
            f"Formal proof {formal_proof.proof_id} generated in {proof_time_ms:.2f}ms: "
            f"{'PROVEN' if formal_proof.verified else 'NOT PROVEN'}"
        )

        return proof_response

    except Exception as e:
        proof_time_ms = (time.time() - proof_start) * 1000
        logger.error(f"Formal proof generation failed after {proof_time_ms:.2f}ms: {e}")

        raise HTTPException(
            status_code=500,
            detail=f"Formal proof generation failed: {str(e)}"
        )


@router.get("/verification-metrics", status_code=200)
async def get_verification_performance_metrics(
    current_user: User = Depends(require_verification_triggerer),
):
    """
    Get comprehensive performance metrics for the formal verification engine.

    Returns metrics including:
    - Verification success rates
    - Average proof generation times
    - Z3 solver performance
    - Constitutional compliance rates
    - Cache hit rates
    """
    try:
        from ..core.constitutional_verification_engine import get_constitutional_verification_engine

        # Get verification engine
        verification_engine = await get_constitutional_verification_engine()

        # Get performance metrics
        metrics = verification_engine.get_performance_metrics()

        # Enhance with additional derived metrics
        enhanced_metrics = {
            "verification_engine_metrics": metrics,
            "performance_analysis": {
                "verification_grade": "A" if metrics["success_rate"] >= 0.95 else "B" if metrics["success_rate"] >= 0.85 else "C",
                "efficiency_score": min(100, metrics["cache_hit_rate"] * 100),
                "formal_proof_capability": "advanced",
                "z3_integration_status": "active",
            },
            "constitutional_compliance": {
                "constitutional_hash": "cdd01ef066bc6cf2",
                "protocol_version": "v2.0",
                "checksum_validation": "enabled",
                "formal_verification_standard": "z3_smt_solver",
            },
            "performance_targets": {
                "target_success_rate": 0.95,
                "target_avg_verification_time_ms": 5000,
                "target_cache_hit_rate": 0.80,
                "target_proof_generation_time_ms": 1000,
            },
            "timestamp": datetime.utcnow().isoformat(),
        }

        return enhanced_metrics

    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Failed to retrieve verification metrics: {str(e)}"
        )


@router.get("/parallel/statistics", status_code=status.HTTP_200_OK)
async def get_parallel_validation_statistics(
    current_user: User = Depends(require_verification_triggerer),
):
    """
    Task 7: Get parallel validation pipeline performance statistics and metrics.

    Returns:
    - Resource utilization efficiency (target: 90%)
    - Concurrent validation metrics (target: 1000+)
    - Constitutional compliance rates
    - Federated consensus rates
    - Performance monitoring data
    - Rollback operation statistics
    """
    try:
        statistics = await parallel_pipeline.get_pipeline_statistics()
        return {
            "status": "success",
            "statistics": statistics,
            "timestamp": datetime.now(timezone.utc).isoformat(),
        }
    except Exception as e:
        raise HTTPException(
            status_code=500, detail=f"Failed to get statistics: {str(e)}"
        )


@router.post("/parallel/scale", status_code=status.HTTP_200_OK)
async def manual_scale_parallel_pipeline(
    scale_factor: float, current_user: User = Depends(require_verification_triggerer)
):
    """
    Task 7: Manually scale the parallel validation pipeline.

    Args:
        scale_factor: Scaling factor (0.5 to 2.0)
    """
    if not 0.5 <= scale_factor <= 2.0:
        raise HTTPException(
            status_code=400, detail="Scale factor must be between 0.5 and 2.0"
        )

    try:
        if scale_factor > parallel_pipeline.current_scale_factor:
            await parallel_pipeline._scale_up()
        elif scale_factor < parallel_pipeline.current_scale_factor:
            await parallel_pipeline._scale_down()

        return {
            "status": "success",
            "message": f"Pipeline scaled to factor {parallel_pipeline.current_scale_factor:.2f}",
            "current_concurrent_tasks": parallel_pipeline.parallel_executor.max_concurrent,
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Scaling failed: {str(e)}")


@router.get("/parallel/stats", response_model=Dict, status_code=status.HTTP_200_OK)
async def get_parallel_pipeline_stats(
    current_user: User = Depends(require_verification_triggerer),
):
    """
    Task 7: Get parallel validation pipeline performance statistics.
    """
    try:
        stats = await parallel_pipeline.get_pipeline_statistics()
        return stats

    except Exception as e:
        raise HTTPException(
            status_code=500, detail=f"Failed to get pipeline stats: {str(e)}"
        )


@router.websocket("/ws/progress")
async def websocket_progress_endpoint(websocket: WebSocket):
    // requires: Valid input parameters
    // ensures: Correct function execution
    // sha256: func_hash
    """
    Task 7: WebSocket endpoint for real-time validation progress updates.
    """
    client_id = f"fv_client_{int(time.time() * 1000)}"

    try:
        await websocket_streamer.connect(websocket, client_id)

        # Keep connection alive and handle messages
        while True:
            try:
                # Wait for client messages (ping/pong, etc.)
                data = await websocket.receive_text()

                # Handle client requests
                if data == "ping":
                    await websocket.send_text("pong")
                elif data == "stats":
                    stats = await websocket_streamer.get_connection_stats()
                    await websocket.send_json(stats)

            except WebSocketDisconnect:
                break
            except Exception as e:
                logger.error(f"WebSocket error: {e}")
                break

    except Exception as e:
        logger.error(f"WebSocket connection error: {e}")
    finally:
        await websocket_streamer.disconnect(websocket)


# --- Phase 3: Algorithmic Fairness Endpoints ---


@router.post(
    "/bias-detection",
    response_model=schemas.BiasDetectionResponse,
    status_code=status.HTTP_200_OK,
)
async def bias_detection_analysis(
    request_data: schemas.BiasDetectionRequest,
    current_user: User = Depends(require_verification_triggerer),
):
    """
    Phase 3: Comprehensive bias detection analysis for policy rules.
    """
    if not request_data.policy_rule_ids:
        raise HTTPException(
            status_code=400, detail="No policy rule IDs provided for bias detection."
        )

    if not request_data.bias_metrics:
        raise HTTPException(
            status_code=400, detail="No bias metrics specified for analysis."
        )

    # Fetch Policy Rules from Integrity Service
    fetched_rules = await integrity_service_client.get_policy_rules_by_ids(
        rule_ids=request_data.policy_rule_ids, auth_token=INTEGRITY_SERVICE_MOCK_TOKEN
    )

    if len(fetched_rules) != len(request_data.policy_rule_ids):
        found_ids = {r.id for r in fetched_rules}
        missing_ids = set(request_data.policy_rule_ids) - found_ids
        raise HTTPException(
            status_code=404,
            detail=f"Could not fetch policy rules with IDs: {list(missing_ids)} from Integrity Service.",
        )

    # Perform bias detection analysis
    response = await bias_detector.detect_bias(
        request=request_data, policy_rules=fetched_rules
    )

    return response


@router.post(
    "/fairness-validation",
    response_model=schemas.FairnessValidationResponse,
    status_code=status.HTTP_200_OK,
)
async def fairness_validation_analysis(
    request_data: schemas.FairnessValidationRequest,
    current_user: User = Depends(require_verification_triggerer),
):
    """
    Phase 3: Fairness property validation for policy rules.
    """
    if not request_data.policy_rule_ids:
        raise HTTPException(
            status_code=400,
            detail="No policy rule IDs provided for fairness validation.",
        )

    if not request_data.fairness_properties:
        raise HTTPException(
            status_code=400, detail="No fairness properties specified for validation."
        )

    # Fetch Policy Rules from Integrity Service
    fetched_rules = await integrity_service_client.get_policy_rules_by_ids(
        rule_ids=request_data.policy_rule_ids, auth_token=INTEGRITY_SERVICE_MOCK_TOKEN
    )

    if len(fetched_rules) != len(request_data.policy_rule_ids):
        found_ids = {r.id for r in fetched_rules}
        missing_ids = set(request_data.policy_rule_ids) - found_ids
        raise HTTPException(
            status_code=404,
            detail=f"Could not fetch policy rules with IDs: {list(missing_ids)} from Integrity Service.",
        )

    # Perform fairness validation
    response = await bias_detector.validate_fairness(
        request=request_data, policy_rules=fetched_rules
    )

    return response


@router.get("/bias-metrics", response_model=List[Dict], status_code=status.HTTP_200_OK)
async def get_available_bias_metrics(
    current_user: User = Depends(require_verification_triggerer),
):
    """
    Phase 3: Get available bias detection metrics and their configurations.
    """
    # Return predefined bias metrics
    bias_metrics = [
        {
            "metric_id": "demographic_parity",
            "metric_type": "statistical",
            "metric_name": "Demographic Parity",
            "description": "Ensures equal positive outcome rates across protected groups",
            "threshold": 0.1,
            "parameters": {"requires_dataset": True},
        },
        {
            "metric_id": "counterfactual_fairness",
            "metric_type": "counterfactual",
            "metric_name": "Counterfactual Fairness",
            "description": "Detects differential treatment based on protected attributes",
            "threshold": 0.2,
            "parameters": {"protected_attributes_required": True},
        },
        {
            "metric_id": "semantic_bias",
            "metric_type": "embedding",
            "metric_name": "Semantic Bias Detection",
            "description": "Analyzes semantic embeddings for bias-associated patterns",
            "threshold": 0.15,
            "parameters": {"embedding_model": "default"},
        },
        {
            "metric_id": "llm_bias_review",
            "metric_type": "llm_review",
            "metric_name": "LLM Bias Review",
            "description": "Expert-level bias review using large language models",
            "threshold": 0.3,
            "parameters": {"model": "gpt-4", "review_depth": "comprehensive"},
        },
    ]

    return bias_metrics


@router.get(
    "/fairness-properties", response_model=List[Dict], status_code=status.HTTP_200_OK
)
async def get_available_fairness_properties(
    current_user: User = Depends(require_verification_triggerer),
):
    """
    Phase 3: Get available fairness properties and their definitions.
    """
    # Return predefined fairness properties
    fairness_properties = [
        {
            "property_id": "demographic_parity",
            "property_type": "demographic_parity",
            "property_name": "Demographic Parity",
            "description": "P(킷 = 1|A = 0) = P(킷 = 1|A = 1) - Equal positive outcome rates",
            "threshold": 0.1,
            "criticality_level": "high",
        },
        {
            "property_id": "equalized_odds",
            "property_type": "equalized_odds",
            "property_name": "Equalized Odds",
            "description": "P(킷 = 1|Y = y, A = a) independent of A - Equal true/false positive rates",
            "threshold": 0.1,
            "criticality_level": "high",
        },
        {
            "property_id": "calibration",
            "property_type": "calibration",
            "property_name": "Calibration",
            "description": "P(Y = 1|킷 = s, A = a) independent of A - Consistent prediction accuracy",
            "threshold": 0.05,
            "criticality_level": "medium",
        },
        {
            "property_id": "individual_fairness",
            "property_type": "individual_fairness",
            "property_name": "Individual Fairness",
            "description": "Similar individuals receive similar treatment",
            "threshold": 0.2,
            "criticality_level": "medium",
        },
    ]

    return fairness_properties
