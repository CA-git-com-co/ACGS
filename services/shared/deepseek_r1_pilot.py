#!/usr/bin/env python3
"""
DeepSeek R1 Migration Pilot Framework for ACGS-PGP

This module implements the A/B testing framework for migrating from expensive
AI models (Claude, GPT-4) to DeepSeek R1 while maintaining constitutional
compliance >95% and response times â‰¤2s.

Key Features:
- A/B traffic routing with configurable percentage
- Constitutional compliance validation
- Cost tracking and ROI measurement
- Automatic fallback on performance degradation
- DGM safety pattern preservation
- Constitutional hash integrity maintenance

Expected Savings: 96.4% reduction in AI model costs ($1.62M annually)
"""

import asyncio
import hashlib
import logging
import time
import uuid
from dataclasses import dataclass, field
from datetime import datetime, timezone
from enum import Enum
from typing import Any, Dict, List, Optional

import httpx
from services.shared.utils import get_config

logger = logging.getLogger(__name__)


class ModelProvider(Enum):
    """AI model providers for ACGS-PGP."""
    ANTHROPIC = "anthropic"
    OPENAI = "openai"
    DEEPSEEK_R1 = "deepseek_r1"
    OPENROUTER = "openrouter"


class TestGroup(Enum):
    """A/B testing groups."""
    CONTROL = "control"  # Current models (Claude, GPT-4)
    TREATMENT = "treatment"  # DeepSeek R1


@dataclass
class ConstitutionalValidationResult:
    """Result of constitutional compliance validation."""
    compliant: bool
    confidence_score: float
    constitutional_hash: str
    validation_time_ms: float
    reasoning: str
    violations: List[str] = field(default_factory=list)


@dataclass
class ModelPerformanceMetrics:
    """Performance metrics for model comparison."""
    model_id: str
    provider: str
    response_time_ms: float
    constitutional_compliance: float
    cost_per_request: float
    success_rate: float
    timestamp: datetime
    constitutional_hash: str
    request_id: str


@dataclass
class PilotConfiguration:
    """Configuration for DeepSeek R1 pilot deployment."""
    enabled: bool = False
    traffic_percentage: int = 10
    constitutional_compliance_threshold: float = 0.95
    response_time_threshold_ms: int = 2000
    cost_tracking_enabled: bool = True
    fallback_on_failure: bool = True
    constitutional_hash: str = "cdd01ef066bc6cf2"
    
    # OpenRouter API configuration
    openrouter_api_key: str = ""
    openrouter_endpoint: str = "https://openrouter.ai/api/v1/chat/completions"
    deepseek_r1_model: str = "deepseek/deepseek-r1-0528:free"


class DeepSeekR1PilotManager:
    """
    Manages the DeepSeek R1 migration pilot with A/B testing.
    
    Implements systematic migration from expensive models to DeepSeek R1
    while maintaining constitutional compliance and performance targets.
    """
    
    def __init__(self, config: Optional[PilotConfiguration] = None):
        self.config = config or self._load_configuration()
        self.http_client = httpx.AsyncClient(timeout=30.0)
        self.metrics_store: List[ModelPerformanceMetrics] = []
        self.constitutional_validator = ConstitutionalComplianceValidator()
        
        # Cost tracking (current vs DeepSeek R1)
        self.cost_per_1k_tokens = {
            "claude-3-7-sonnet": 15.00,  # $15.00/1M tokens
            "gpt-4": 30.00,              # $30.00/1M tokens  
            "deepseek-r1": 0.55,         # $0.55/1M tokens (96.4% reduction)
        }
        
        logger.info(f"DeepSeek R1 Pilot initialized: {self.config.traffic_percentage}% traffic routing")
    
    def _load_configuration(self) -> PilotConfiguration:
        """Load pilot configuration from environment and config files."""
        config = get_config()
        pilot_config = config.get("deepseek_r1_pilot", {})
        
        return PilotConfiguration(
            enabled=pilot_config.get("enabled", False),
            traffic_percentage=pilot_config.get("traffic_percentage", 10),
            constitutional_compliance_threshold=pilot_config.get("constitutional_compliance_threshold", 0.95),
            response_time_threshold_ms=pilot_config.get("response_time_threshold_ms", 2000),
            cost_tracking_enabled=pilot_config.get("cost_tracking_enabled", True),
            fallback_on_failure=pilot_config.get("fallback_on_failure", True),
            constitutional_hash=pilot_config.get("constitutional_hash", "cdd01ef066bc6cf2"),
            openrouter_api_key=config.get("api_keys", {}).get("openrouter", ""),
        )
    
    def should_use_deepseek_r1(self, request_id: str) -> bool:
        """
        Determine if request should use DeepSeek R1 based on A/B testing.
        
        Uses consistent hashing to ensure same user gets same experience.
        """
        if not self.config.enabled:
            return False
            
        # Use request hash for consistent routing
        hash_value = int(hashlib.md5(request_id.encode()).hexdigest()[:8], 16)
        return (hash_value % 100) < self.config.traffic_percentage
    
    async def process_request(self, request: Dict[str, Any], request_id: str) -> Dict[str, Any]:
        """
        Process AI request with A/B testing between current models and DeepSeek R1.
        
        Maintains constitutional compliance and performance monitoring.
        """
        start_time = time.time()
        test_group = TestGroup.TREATMENT if self.should_use_deepseek_r1(request_id) else TestGroup.CONTROL
        
        try:
            if test_group == TestGroup.TREATMENT:
                response = await self._call_deepseek_r1(request, request_id)
                model_id = self.config.deepseek_r1_model
                provider = "deepseek_r1"
            else:
                response = await self._call_control_model(request, request_id)
                model_id = "claude-3-7-sonnet"  # Current primary model
                provider = "anthropic"
            
            # Validate constitutional compliance
            compliance_result = await self.constitutional_validator.validate_response(
                response, self.config.constitutional_hash
            )
            
            # Record performance metrics
            response_time_ms = (time.time() - start_time) * 1000
            await self._record_metrics(
                model_id, provider, response_time_ms, 
                compliance_result, request_id, test_group
            )
            
            # Check if fallback is needed
            if (compliance_result.confidence_score < self.config.constitutional_compliance_threshold or
                response_time_ms > self.config.response_time_threshold_ms):
                
                if test_group == TestGroup.TREATMENT and self.config.fallback_on_failure:
                    logger.warning(f"DeepSeek R1 performance below threshold, falling back to control model")
                    return await self._call_control_model(request, request_id)
            
            return response
            
        except Exception as e:
            logger.error(f"Error in pilot request processing: {e}")
            if test_group == TestGroup.TREATMENT and self.config.fallback_on_failure:
                return await self._call_control_model(request, request_id)
            raise
    
    async def _call_deepseek_r1(self, request: Dict[str, Any], request_id: str) -> Dict[str, Any]:
        """Call DeepSeek R1 via OpenRouter API."""
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.config.openrouter_api_key}",
            "HTTP-Referer": "https://acgs-pgp.ai",  # Required by OpenRouter
            "X-Title": "ACGS-PGP Constitutional AI",
        }
        
        payload = {
            "model": self.config.deepseek_r1_model,
            "messages": request.get("messages", []),
            "temperature": request.get("temperature", 0.0),
            "max_tokens": request.get("max_tokens", 8192),
            "stream": False,
        }
        
        response = await self.http_client.post(
            self.config.openrouter_endpoint,
            headers=headers,
            json=payload
        )
        response.raise_for_status()
        
        return response.json()
    
    async def _call_control_model(self, request: Dict[str, Any], request_id: str) -> Dict[str, Any]:
        """Call current control model (Claude/GPT-4)."""
        # This would integrate with existing AI model service
        # For now, return mock response maintaining same structure
        return {
            "choices": [{
                "message": {
                    "role": "assistant",
                    "content": "Control model response (Claude/GPT-4)"
                }
            }],
            "usage": {
                "prompt_tokens": 100,
                "completion_tokens": 50,
                "total_tokens": 150
            }
        }
    
    async def _record_metrics(self, model_id: str, provider: str, response_time_ms: float,
                            compliance_result: ConstitutionalValidationResult, 
                            request_id: str, test_group: TestGroup):
        """Record performance metrics for analysis."""
        cost_per_request = self._calculate_cost(model_id, 150)  # Estimated tokens
        
        metrics = ModelPerformanceMetrics(
            model_id=model_id,
            provider=provider,
            response_time_ms=response_time_ms,
            constitutional_compliance=compliance_result.confidence_score,
            cost_per_request=cost_per_request,
            success_rate=1.0 if compliance_result.compliant else 0.0,
            timestamp=datetime.now(timezone.utc),
            constitutional_hash=self.config.constitutional_hash,
            request_id=request_id
        )
        
        self.metrics_store.append(metrics)
        
        # Log key metrics
        logger.info(f"Pilot metrics - Group: {test_group.value}, Model: {model_id}, "
                   f"Response: {response_time_ms:.1f}ms, Compliance: {compliance_result.confidence_score:.3f}, "
                   f"Cost: ${cost_per_request:.6f}")
    
    def _calculate_cost(self, model_id: str, total_tokens: int) -> float:
        """Calculate cost per request based on token usage."""
        if "deepseek" in model_id.lower():
            cost_per_1k = self.cost_per_1k_tokens["deepseek-r1"]
        elif "claude" in model_id.lower():
            cost_per_1k = self.cost_per_1k_tokens["claude-3-7-sonnet"]
        else:
            cost_per_1k = self.cost_per_1k_tokens["gpt-4"]
        
        return (total_tokens / 1000) * (cost_per_1k / 1000)  # Convert to actual cost
    
    def get_pilot_summary(self) -> Dict[str, Any]:
        """Generate pilot performance summary for monitoring."""
        if not self.metrics_store:
            return {"status": "no_data", "message": "No pilot data available"}
        
        deepseek_metrics = [m for m in self.metrics_store if "deepseek" in m.model_id.lower()]
        control_metrics = [m for m in self.metrics_store if "deepseek" not in m.model_id.lower()]
        
        summary = {
            "pilot_status": "active" if self.config.enabled else "disabled",
            "traffic_percentage": self.config.traffic_percentage,
            "constitutional_hash": self.config.constitutional_hash,
            "total_requests": len(self.metrics_store),
            "deepseek_requests": len(deepseek_metrics),
            "control_requests": len(control_metrics),
        }
        
        if deepseek_metrics:
            summary["deepseek_performance"] = {
                "avg_response_time_ms": sum(m.response_time_ms for m in deepseek_metrics) / len(deepseek_metrics),
                "avg_compliance": sum(m.constitutional_compliance for m in deepseek_metrics) / len(deepseek_metrics),
                "avg_cost_per_request": sum(m.cost_per_request for m in deepseek_metrics) / len(deepseek_metrics),
                "success_rate": sum(m.success_rate for m in deepseek_metrics) / len(deepseek_metrics),
            }
        
        if control_metrics:
            summary["control_performance"] = {
                "avg_response_time_ms": sum(m.response_time_ms for m in control_metrics) / len(control_metrics),
                "avg_compliance": sum(m.constitutional_compliance for m in control_metrics) / len(control_metrics),
                "avg_cost_per_request": sum(m.cost_per_request for m in control_metrics) / len(control_metrics),
                "success_rate": sum(m.success_rate for m in control_metrics) / len(control_metrics),
            }
        
        # Calculate cost savings
        if deepseek_metrics and control_metrics:
            deepseek_avg_cost = sum(m.cost_per_request for m in deepseek_metrics) / len(deepseek_metrics)
            control_avg_cost = sum(m.cost_per_request for m in control_metrics) / len(control_metrics)
            cost_reduction_percent = ((control_avg_cost - deepseek_avg_cost) / control_avg_cost) * 100
            
            summary["cost_analysis"] = {
                "cost_reduction_percent": cost_reduction_percent,
                "projected_annual_savings": (control_avg_cost - deepseek_avg_cost) * 1000000,  # Assuming 1M requests/year
            }
        
        return summary


class ConstitutionalComplianceValidator:
    """Validates constitutional compliance for AI responses."""
    
    async def validate_response(self, response: Dict[str, Any], 
                              constitutional_hash: str) -> ConstitutionalValidationResult:
        """
        Validate AI response against constitutional requirements.
        
        Maintains constitutional hash integrity and compliance thresholds.
        """
        start_time = time.time()
        
        # Extract response content
        content = ""
        if "choices" in response and response["choices"]:
            content = response["choices"][0].get("message", {}).get("content", "")
        
        # Basic constitutional compliance checks
        violations = []
        compliance_score = 1.0
        
        # Check for harmful content patterns
        harmful_patterns = [
            "violence", "discrimination", "illegal", "harmful",
            "unethical", "dangerous", "inappropriate"
        ]
        
        for pattern in harmful_patterns:
            if pattern.lower() in content.lower():
                violations.append(f"Potential {pattern} content detected")
                compliance_score -= 0.1
        
        # Ensure minimum compliance threshold
        compliance_score = max(0.0, min(1.0, compliance_score))
        
        validation_time_ms = (time.time() - start_time) * 1000
        
        return ConstitutionalValidationResult(
            compliant=compliance_score >= 0.95,
            confidence_score=compliance_score,
            constitutional_hash=constitutional_hash,
            validation_time_ms=validation_time_ms,
            reasoning=f"Constitutional validation completed with {len(violations)} violations",
            violations=violations
        )
