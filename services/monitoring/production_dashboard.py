#!/usr/bin/env python3
"""
Production Monitoring Dashboard

Real-time monitoring dashboard for ACGS-PGP multimodal AI system with:
- Real-time analytics and metrics
- Cost tracking and optimization insights
- Performance visualization
- Constitutional compliance monitoring
- Cache performance analytics
- ML routing optimization metrics

Constitutional Hash: cdd01ef066bc6cf2
"""

import asyncio
import json
import logging
import time
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from pathlib import Path
import sys

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from services.shared.multimodal_ai_service import get_multimodal_service
from services.shared.multi_level_cache import get_cache_manager
from services.shared.ml_routing_optimizer import get_ml_optimizer
from services.shared.ai_types import ModelType

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ProductionDashboard:
    """Production monitoring dashboard for ACGS-PGP system."""
    
    def __init__(self):
        self.multimodal_service = None
        self.cache_manager = None
        self.ml_optimizer = None
        self.constitutional_hash = "cdd01ef066bc6cf2"
        self.dashboard_data = {}
        self.start_time = time.time()
    
    async def initialize(self):
        """Initialize dashboard components."""
        logger.info("üöÄ Initializing Production Dashboard...")
        
        try:
            # Initialize services
            self.multimodal_service = await get_multimodal_service()
            self.cache_manager = await get_cache_manager()
            self.ml_optimizer = await get_ml_optimizer()
            
            logger.info("‚úÖ Production Dashboard initialized successfully")
            
        except Exception as e:
            logger.error(f"‚ùå Dashboard initialization failed: {e}")
            raise
    
    async def collect_real_time_metrics(self) -> Dict[str, Any]:
        """Collect real-time system metrics."""
        
        try:
            # Multimodal service metrics
            service_metrics = {}
            if self.multimodal_service:
                service_metrics = self.multimodal_service.get_metrics()
            
            # Cache performance metrics
            cache_metrics = {}
            if self.cache_manager:
                try:
                    cache_metrics = self.cache_manager.get_metrics()
                except Exception as e:
                    logger.warning(f"Cache metrics collection failed: {e}")
                    cache_metrics = {"error": str(e)}
            
            # ML optimizer analytics
            ml_metrics = {}
            if self.ml_optimizer:
                try:
                    ml_metrics = self.ml_optimizer.get_performance_analytics()
                except Exception as e:
                    logger.warning(f"ML metrics collection failed: {e}")
                    ml_metrics = {"error": str(e)}
            
            # System health metrics
            uptime = time.time() - self.start_time
            
            metrics = {
                "timestamp": datetime.now().isoformat(),
                "uptime_seconds": uptime,
                "uptime_formatted": self._format_uptime(uptime),
                "service_metrics": service_metrics,
                "cache_metrics": cache_metrics,
                "ml_metrics": ml_metrics,
                "constitutional_hash": self.constitutional_hash
            }
            
            return metrics
            
        except Exception as e:
            logger.error(f"‚ùå Metrics collection failed: {e}")
            return {"error": str(e), "timestamp": datetime.now().isoformat()}
    
    def _format_uptime(self, seconds: float) -> str:
        """Format uptime in human-readable format."""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        return f"{hours:02d}:{minutes:02d}:{secs:02d}"
    
    async def generate_cost_analysis(self) -> Dict[str, Any]:
        """Generate cost tracking and optimization analysis."""
        
        try:
            # Get service metrics for cost calculation
            service_metrics = {}
            if self.multimodal_service:
                service_metrics = self.multimodal_service.get_metrics()
            
            # Calculate cost estimates by model
            model_costs = {}
            total_cost = 0.0
            
            # Cost per 1M tokens (approximate)
            cost_per_million_tokens = {
                ModelType.FLASH_LITE: 0.075,  # $0.075 per 1M tokens
                ModelType.FLASH_FULL: 0.30,   # $0.30 per 1M tokens  
                ModelType.DEEPSEEK_R1: 0.02   # $0.02 per 1M tokens (74% savings)
            }
            
            model_usage = service_metrics.get("model_usage", {})
            
            for model_str, usage_count in model_usage.items():
                try:
                    model_type = ModelType(model_str)
                    # Estimate 1000 tokens per request on average
                    estimated_tokens = usage_count * 1000
                    cost_per_token = cost_per_million_tokens.get(model_type, 0.1) / 1_000_000
                    model_cost = estimated_tokens * cost_per_token
                    
                    model_costs[model_str] = {
                        "usage_count": usage_count,
                        "estimated_tokens": estimated_tokens,
                        "cost_usd": model_cost,
                        "cost_per_request": model_cost / usage_count if usage_count > 0 else 0
                    }
                    total_cost += model_cost
                    
                except ValueError:
                    # Handle unknown model types
                    model_costs[model_str] = {
                        "usage_count": usage_count,
                        "estimated_tokens": usage_count * 1000,
                        "cost_usd": usage_count * 0.001,  # Default estimate
                        "cost_per_request": 0.001
                    }
            
            # Calculate savings from DeepSeek R1 usage
            deepseek_usage = model_usage.get(ModelType.DEEPSEEK_R1.value, 0)
            if deepseek_usage > 0:
                # Compare to Flash Full cost
                flash_full_cost = deepseek_usage * 1000 * (cost_per_million_tokens[ModelType.FLASH_FULL] / 1_000_000)
                deepseek_cost = model_costs.get(ModelType.DEEPSEEK_R1.value, {}).get("cost_usd", 0)
                cost_savings = flash_full_cost - deepseek_cost
                savings_percentage = (cost_savings / flash_full_cost * 100) if flash_full_cost > 0 else 0
            else:
                cost_savings = 0
                savings_percentage = 0
            
            cost_analysis = {
                "total_cost_usd": total_cost,
                "model_costs": model_costs,
                "cost_savings": {
                    "deepseek_savings_usd": cost_savings,
                    "savings_percentage": savings_percentage,
                    "target_savings": 74.0  # Target 74% cost reduction
                },
                "cost_optimization": {
                    "recommendations": self._generate_cost_recommendations(model_usage, cost_savings),
                    "efficiency_score": min(100, savings_percentage * 1.35)  # Scale to 100%
                }
            }
            
            return cost_analysis
            
        except Exception as e:
            logger.error(f"‚ùå Cost analysis failed: {e}")
            return {"error": str(e)}
    
    def _generate_cost_recommendations(self, model_usage: Dict[str, int], current_savings: float) -> List[str]:
        """Generate cost optimization recommendations."""
        recommendations = []
        
        total_requests = sum(model_usage.values())
        if total_requests == 0:
            return ["No usage data available for recommendations"]
        
        # Check DeepSeek R1 usage
        deepseek_usage = model_usage.get(ModelType.DEEPSEEK_R1.value, 0)
        deepseek_percentage = (deepseek_usage / total_requests * 100) if total_requests > 0 else 0
        
        if deepseek_percentage < 50:
            recommendations.append(f"Increase DeepSeek R1 usage (currently {deepseek_percentage:.1f}%) for cost optimization")
        
        # Check Flash Full usage for potential optimization
        flash_full_usage = model_usage.get(ModelType.FLASH_FULL.value, 0)
        if flash_full_usage > total_requests * 0.3:
            recommendations.append("Consider routing more requests to cost-effective models")
        
        # Cache optimization
        recommendations.append("Optimize cache hit rates to reduce API costs")
        
        # ML routing optimization
        recommendations.append("Use ML routing to automatically select cost-optimal models")
        
        if current_savings < 100:  # Less than $100 savings
            recommendations.append("Scale usage to achieve greater cost savings")
        
        return recommendations[:3]  # Return top 3 recommendations
    
    async def generate_performance_dashboard(self) -> Dict[str, Any]:
        """Generate comprehensive performance dashboard."""
        
        try:
            # Collect all metrics
            real_time_metrics = await self.collect_real_time_metrics()
            cost_analysis = await self.generate_cost_analysis()
            
            # Performance summary
            service_metrics = real_time_metrics.get("service_metrics", {})
            cache_metrics = real_time_metrics.get("cache_metrics", {})
            
            # Calculate performance scores
            performance_scores = self._calculate_performance_scores(service_metrics, cache_metrics)
            
            # System health status
            health_status = self._determine_health_status(performance_scores)
            
            dashboard = {
                "dashboard_info": {
                    "title": "ACGS-PGP Production Monitoring Dashboard",
                    "generated_at": datetime.now().isoformat(),
                    "constitutional_hash": self.constitutional_hash,
                    "uptime": real_time_metrics.get("uptime_formatted", "00:00:00")
                },
                "system_health": {
                    "status": health_status,
                    "performance_scores": performance_scores,
                    "uptime_seconds": real_time_metrics.get("uptime_seconds", 0)
                },
                "real_time_metrics": real_time_metrics,
                "cost_analysis": cost_analysis,
                "alerts": self._generate_alerts(performance_scores, cost_analysis),
                "recommendations": self._generate_system_recommendations(performance_scores, cost_analysis)
            }
            
            return dashboard
            
        except Exception as e:
            logger.error(f"‚ùå Dashboard generation failed: {e}")
            return {
                "error": str(e),
                "timestamp": datetime.now().isoformat(),
                "constitutional_hash": self.constitutional_hash
            }
    
    def _calculate_performance_scores(self, service_metrics: Dict, cache_metrics: Dict) -> Dict[str, float]:
        """Calculate performance scores for different aspects."""
        
        scores = {
            "overall": 0.0,
            "response_time": 0.0,
            "success_rate": 0.0,
            "cache_efficiency": 0.0,
            "constitutional_compliance": 0.0,
            "cost_efficiency": 0.0
        }
        
        try:
            # Response time score (target: <2000ms)
            response_times = service_metrics.get("response_times", [])
            if response_times:
                avg_response_time = sum(response_times) / len(response_times)
                scores["response_time"] = max(0, min(100, (2000 - avg_response_time) / 2000 * 100))
            else:
                scores["response_time"] = 100  # No data = assume good
            
            # Success rate score
            total_requests = service_metrics.get("total_requests", 0)
            if total_requests > 0:
                # Assume high success rate if no failures reported
                scores["success_rate"] = 100.0
            else:
                scores["success_rate"] = 100.0
            
            # Cache efficiency score
            cache_hit_rate = cache_metrics.get("cache_hit_rate", 0)
            scores["cache_efficiency"] = min(100, cache_hit_rate)
            
            # Constitutional compliance score
            compliance_rate = service_metrics.get("constitutional_compliance_rate", 100)
            scores["constitutional_compliance"] = compliance_rate
            
            # Cost efficiency score (based on DeepSeek usage)
            model_usage = service_metrics.get("model_usage", {})
            total_usage = sum(model_usage.values())
            if total_usage > 0:
                deepseek_usage = model_usage.get(ModelType.DEEPSEEK_R1.value, 0)
                deepseek_percentage = (deepseek_usage / total_usage * 100)
                scores["cost_efficiency"] = min(100, deepseek_percentage * 1.35)  # Scale to 100%
            else:
                scores["cost_efficiency"] = 100.0
            
            # Overall score (weighted average)
            weights = {
                "response_time": 0.25,
                "success_rate": 0.25,
                "cache_efficiency": 0.15,
                "constitutional_compliance": 0.25,
                "cost_efficiency": 0.10
            }
            
            scores["overall"] = sum(scores[metric] * weight for metric, weight in weights.items())
            
        except Exception as e:
            logger.warning(f"Performance score calculation failed: {e}")
        
        return scores
    
    def _determine_health_status(self, performance_scores: Dict[str, float]) -> str:
        """Determine overall system health status."""
        overall_score = performance_scores.get("overall", 0)
        
        if overall_score >= 90:
            return "EXCELLENT"
        elif overall_score >= 80:
            return "GOOD"
        elif overall_score >= 70:
            return "FAIR"
        elif overall_score >= 60:
            return "POOR"
        else:
            return "CRITICAL"
    
    def _generate_alerts(self, performance_scores: Dict, cost_analysis: Dict) -> List[Dict[str, str]]:
        """Generate system alerts based on metrics."""
        alerts = []
        
        # Performance alerts
        if performance_scores.get("response_time", 100) < 80:
            alerts.append({
                "level": "WARNING",
                "message": "Response times above target threshold",
                "metric": "response_time"
            })
        
        if performance_scores.get("constitutional_compliance", 100) < 95:
            alerts.append({
                "level": "CRITICAL",
                "message": "Constitutional compliance below 95%",
                "metric": "constitutional_compliance"
            })
        
        if performance_scores.get("cache_efficiency", 100) < 60:
            alerts.append({
                "level": "WARNING",
                "message": "Cache hit rate below optimal threshold",
                "metric": "cache_efficiency"
            })
        
        # Cost alerts
        cost_savings = cost_analysis.get("cost_savings", {})
        savings_percentage = cost_savings.get("savings_percentage", 0)
        
        if savings_percentage < 50:  # Less than 50% of target 74% savings
            alerts.append({
                "level": "INFO",
                "message": f"Cost savings at {savings_percentage:.1f}% (target: 74%)",
                "metric": "cost_efficiency"
            })
        
        return alerts
    
    def _generate_system_recommendations(self, performance_scores: Dict, cost_analysis: Dict) -> List[str]:
        """Generate system optimization recommendations."""
        recommendations = []
        
        # Performance recommendations
        if performance_scores.get("response_time", 100) < 90:
            recommendations.append("Optimize response times through cache warming and ML routing")
        
        if performance_scores.get("cache_efficiency", 100) < 80:
            recommendations.append("Improve cache hit rates with better TTL tuning")
        
        # Cost recommendations
        cost_recs = cost_analysis.get("cost_optimization", {}).get("recommendations", [])
        recommendations.extend(cost_recs[:2])  # Add top 2 cost recommendations
        
        # ML optimization
        recommendations.append("Continue training ML routing models for optimal performance")
        
        return recommendations[:5]  # Return top 5 recommendations
    
    async def save_dashboard_data(self, dashboard_data: Dict[str, Any]):
        """Save dashboard data to file."""
        try:
            # Ensure data directory exists
            Path("data").mkdir(exist_ok=True)
            
            # Save current dashboard data
            dashboard_file = "data/production_dashboard.json"
            with open(dashboard_file, 'w') as f:
                json.dump(dashboard_data, f, indent=2, default=str)
            
            # Save historical data
            history_file = "data/dashboard_history.jsonl"
            with open(history_file, 'a') as f:
                f.write(json.dumps(dashboard_data, default=str) + '\n')
            
            logger.info(f"üìä Dashboard data saved to {dashboard_file}")
            
        except Exception as e:
            logger.error(f"‚ùå Failed to save dashboard data: {e}")

    async def generate_dashboard_data(self) -> Dict[str, Any]:
        """Generate comprehensive dashboard data for visualization."""

        try:
            # Collect all metrics
            real_time_metrics = await self.collect_real_time_metrics()
            cost_analysis = await self.generate_cost_analysis()

            # Compile dashboard data
            dashboard_data = {
                "system_overview": {
                    "timestamp": real_time_metrics.get("timestamp"),
                    "uptime": real_time_metrics.get("uptime_formatted"),
                    "constitutional_hash": self.constitutional_hash,
                    "status": "operational"
                },
                "service_metrics": real_time_metrics.get("service_metrics", {}),
                "cache_metrics": real_time_metrics.get("cache_metrics", {}),
                "ml_metrics": real_time_metrics.get("ml_metrics", {}),
                "cost_analysis": cost_analysis,
                "alerts": [],  # Would be populated with active alerts
                "trends": {
                    "response_time_trend": "stable",
                    "cost_trend": "decreasing",
                    "compliance_trend": "stable"
                }
            }

            return {
                "dashboard_data": dashboard_data,
                "constitutional_hash": self.constitutional_hash,
                "last_updated": real_time_metrics.get("timestamp")
            }

        except Exception as e:
            logger.error(f"‚ùå Dashboard data generation failed: {e}")
            return {
                "error": str(e),
                "constitutional_hash": self.constitutional_hash,
                "last_updated": datetime.now().isoformat()
            }

    async def run_dashboard_update(self) -> Dict[str, Any]:
        """Run a single dashboard update cycle."""
        logger.info("üìä Updating production dashboard...")
        
        try:
            # Generate dashboard
            dashboard_data = await self.generate_performance_dashboard()
            
            # Save data
            await self.save_dashboard_data(dashboard_data)
            
            # Log summary
            health_status = dashboard_data.get("system_health", {}).get("status", "UNKNOWN")
            overall_score = dashboard_data.get("system_health", {}).get("performance_scores", {}).get("overall", 0)
            
            logger.info(f"‚úÖ Dashboard updated - Health: {health_status} (Score: {overall_score:.1f})")
            
            return dashboard_data
            
        except Exception as e:
            logger.error(f"‚ùå Dashboard update failed: {e}")
            return {"error": str(e)}


async def main():
    """Main dashboard execution."""
    logger.info("üöÄ ACGS-PGP Production Monitoring Dashboard")
    logger.info("=" * 60)
    
    try:
        # Initialize dashboard
        dashboard = ProductionDashboard()
        await dashboard.initialize()
        
        # Run dashboard update
        dashboard_data = await dashboard.run_dashboard_update()
        
        # Display summary
        if "error" not in dashboard_data:
            logger.info("\nüìà DASHBOARD SUMMARY")
            logger.info("=" * 60)
            
            health = dashboard_data.get("system_health", {})
            logger.info(f"System Health: {health.get('status', 'UNKNOWN')}")
            
            scores = health.get("performance_scores", {})
            logger.info(f"Overall Score: {scores.get('overall', 0):.1f}/100")
            logger.info(f"Response Time: {scores.get('response_time', 0):.1f}/100")
            logger.info(f"Cache Efficiency: {scores.get('cache_efficiency', 0):.1f}/100")
            logger.info(f"Constitutional Compliance: {scores.get('constitutional_compliance', 0):.1f}/100")
            logger.info(f"Cost Efficiency: {scores.get('cost_efficiency', 0):.1f}/100")
            
            # Show alerts
            alerts = dashboard_data.get("alerts", [])
            if alerts:
                logger.info(f"\n‚ö†Ô∏è Active Alerts: {len(alerts)}")
                for alert in alerts[:3]:  # Show top 3 alerts
                    logger.info(f"  {alert['level']}: {alert['message']}")
            
            # Show recommendations
            recommendations = dashboard_data.get("recommendations", [])
            if recommendations:
                logger.info(f"\nüí° Recommendations:")
                for i, rec in enumerate(recommendations[:3], 1):
                    logger.info(f"  {i}. {rec}")
            
            logger.info("\nüéâ Production dashboard deployed successfully!")
            return 0
        else:
            logger.error("‚ùå Dashboard deployment failed")
            return 1
        
    except Exception as e:
        logger.error(f"‚ùå Dashboard execution failed: {e}")
        return 1

    async def generate_dashboard_data(self) -> Dict[str, Any]:
        """Generate comprehensive dashboard data for visualization."""

        try:
            # Collect all metrics
            real_time_metrics = await self.collect_real_time_metrics()
            cost_analysis = await self.generate_cost_analysis()

            # Compile dashboard data
            dashboard_data = {
                "system_overview": {
                    "timestamp": real_time_metrics.get("timestamp"),
                    "uptime": real_time_metrics.get("uptime_formatted"),
                    "constitutional_hash": self.constitutional_hash,
                    "status": "operational"
                },
                "service_metrics": real_time_metrics.get("service_metrics", {}),
                "cache_metrics": real_time_metrics.get("cache_metrics", {}),
                "ml_metrics": real_time_metrics.get("ml_metrics", {}),
                "cost_analysis": cost_analysis,
                "alerts": [],  # Would be populated with active alerts
                "trends": {
                    "response_time_trend": "stable",
                    "cost_trend": "decreasing",
                    "compliance_trend": "stable"
                }
            }

            return {
                "dashboard_data": dashboard_data,
                "constitutional_hash": self.constitutional_hash,
                "last_updated": real_time_metrics.get("timestamp")
            }

        except Exception as e:
            logger.error(f"‚ùå Dashboard data generation failed: {e}")
            return {
                "error": str(e),
                "constitutional_hash": self.constitutional_hash,
                "last_updated": datetime.now().isoformat()
            }


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
