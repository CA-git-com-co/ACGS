# Constitutional Trainer Integration Tests CI Job
#
# This GitHub Actions job configuration can be added to existing CI workflows
# to run comprehensive integration tests for the Constitutional Trainer Service.

name: Constitutional Trainer Integration Tests

on:
  push:
    branches: [main, master, develop]
    paths:
      - 'services/core/constitutional-trainer/**'
      - 'services/core/policy-engine/**'
      - 'services/core/audit-engine/**'
      - 'infrastructure/kubernetes/acgs-lite/**'
      - 'tests/integration/test_constitutional_trainer_integration.py'
  pull_request:
    branches: [main, master]
    paths:
      - 'services/core/constitutional-trainer/**'
      - 'services/core/policy-engine/**'
      - 'services/core/audit-engine/**'
  workflow_dispatch:
    inputs:
      test_environment:
        description: 'Test environment to use'
        required: false
        default: 'staging'
        type: choice
        options:
          - staging
          - development
          - local
      skip_deployment:
        description: 'Skip service deployment (use existing services)'
        required: false
        default: false
        type: boolean

env:
  PYTHON_VERSION: '3.11'
  KUBECTL_VERSION: 'v1.28.0'
  TEST_NAMESPACE: 'acgs-integration-test'
  INTEGRATION_TEST_TIMEOUT: '1800' # 30 minutes

jobs:
  constitutional-trainer-integration:
    name: Constitutional Trainer Integration Tests
    runs-on: ubuntu-latest
    timeout-minutes: 45

    strategy:
      matrix:
        test-scenario:
          - happy-path
          - policy-violations
          - performance-validation
          - cache-behavior

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r config/requirements-test.txt

      - name: Set up kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: ${{ env.KUBECTL_VERSION }}

      - name: Configure Kubernetes Context
        run: |
          # Configure kubectl for test cluster
          # This would be configured based on your specific K8s setup
          echo "Configuring kubectl context for integration tests..."

      - name: Create Test Namespace
        run: |
          kubectl create namespace ${{ env.TEST_NAMESPACE }} --dry-run=client -o yaml | kubectl apply -f -
          kubectl label namespace ${{ env.TEST_NAMESPACE }} acgs-lite.io/test-environment=true

      - name: Deploy Test Services
        if: ${{ !inputs.skip_deployment }}
        run: |
          echo "ðŸš€ Deploying test services..."

          # Deploy Redis
          kubectl apply -f infrastructure/kubernetes/acgs-lite/redis.yaml -n ${{ env.TEST_NAMESPACE }}

          # Deploy Policy Engine
          kubectl apply -f infrastructure/kubernetes/acgs-lite/policy-engine.yaml -n ${{ env.TEST_NAMESPACE }}

          # Deploy Audit Engine  
          kubectl apply -f infrastructure/kubernetes/acgs-lite/audit-engine.yaml -n ${{ env.TEST_NAMESPACE }}

          # Deploy Constitutional Trainer
          kubectl apply -f infrastructure/kubernetes/acgs-lite/constitutional-trainer.yaml -n ${{ env.TEST_NAMESPACE }}

      - name: Wait for Services Ready
        run: |
          echo "â³ Waiting for services to be ready..."

          # Wait for all pods to be running
          kubectl wait --for=condition=Ready pods --all -n ${{ env.TEST_NAMESPACE }} --timeout=600s

          # Verify service endpoints
          kubectl get services -n ${{ env.TEST_NAMESPACE }}
          kubectl get pods -n ${{ env.TEST_NAMESPACE }}

      - name: Port Forward Services
        run: |
          echo "ðŸ”— Setting up port forwarding for tests..."

          # Port forward services for local testing
          kubectl port-forward -n ${{ env.TEST_NAMESPACE }} svc/constitutional-trainer 8000:8000 &
          kubectl port-forward -n ${{ env.TEST_NAMESPACE }} svc/policy-engine 8001:8001 &
          kubectl port-forward -n ${{ env.TEST_NAMESPACE }} svc/audit-engine 8003:8003 &
          kubectl port-forward -n ${{ env.TEST_NAMESPACE }} svc/redis 6379:6379 &

          # Wait for port forwards to be established
          sleep 10

      - name: Run Health Checks
        run: |
          echo "ðŸ¥ Running service health checks..."

          # Check service health endpoints
          curl -f http://localhost:8000/health || exit 1
          curl -f http://localhost:8001/health || exit 1
          curl -f http://localhost:8003/health || exit 1

          echo "âœ… All services are healthy"

      - name: Run Integration Tests
        env:
          CONSTITUTIONAL_TRAINER_URL: 'http://localhost:8000'
          POLICY_ENGINE_URL: 'http://localhost:8001'
          AUDIT_ENGINE_URL: 'http://localhost:8003'
          REDIS_URL: 'redis://localhost:6379/0'
          TEST_SCENARIO: ${{ matrix.test-scenario }}
        run: |
          echo "ðŸ§ª Running Constitutional Trainer integration tests..."

          # Run specific test scenario
          case "$TEST_SCENARIO" in
            "happy-path")
              pytest tests/integration/test_constitutional_trainer_integration.py::test_constitutional_trainer_integration -v --tb=short
              ;;
            "policy-violations")
              pytest tests/integration/test_constitutional_trainer_integration.py -k "policy_violation" -v --tb=short
              ;;
            "performance-validation")
              pytest tests/integration/test_constitutional_trainer_integration.py -k "performance" -v --tb=short
              ;;
            "cache-behavior")
              pytest tests/integration/test_constitutional_trainer_integration.py -k "cache" -v --tb=short
              ;;
            *)
              pytest tests/integration/test_constitutional_trainer_integration.py -v --tb=short
              ;;
          esac

      - name: Collect Test Metrics
        if: always()
        run: |
          echo "ðŸ“Š Collecting test metrics..."

          # Collect Prometheus metrics
          curl -s http://localhost:8000/metrics > constitutional-trainer-metrics.txt || true
          curl -s http://localhost:8001/metrics > policy-engine-metrics.txt || true

          # Collect Kubernetes metrics
          kubectl top pods -n ${{ env.TEST_NAMESPACE }} > pod-metrics.txt || true
          kubectl describe pods -n ${{ env.TEST_NAMESPACE }} > pod-descriptions.txt || true

      - name: Generate Test Report
        if: always()
        run: |
          echo "ðŸ“„ Generating test report..."

          # Run standalone test report generation
          python tests/integration/test_constitutional_trainer_integration.py > integration-test-report.txt || true

      - name: Upload Test Artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: constitutional-trainer-integration-test-results-${{ matrix.test-scenario }}
          path: |
            constitutional-trainer-metrics.txt
            policy-engine-metrics.txt
            pod-metrics.txt
            pod-descriptions.txt
            integration-test-report.txt
            constitutional_trainer_integration_report_*.json
          retention-days: 30

      - name: Cleanup Test Environment
        if: always()
        run: |
          echo "ðŸ§¹ Cleaning up test environment..."

          # Kill port forward processes
          pkill -f "kubectl port-forward" || true

          # Delete test namespace
          kubectl delete namespace ${{ env.TEST_NAMESPACE }} --ignore-not-found=true

      - name: Post Test Results to PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');

            // Read test report if it exists
            let reportContent = 'Integration test results not available';
            try {
              reportContent = fs.readFileSync('integration-test-report.txt', 'utf8');
            } catch (error) {
              console.log('Could not read test report:', error.message);
            }

            // Post comment on PR
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## Constitutional Trainer Integration Test Results\n\n**Test Scenario:** ${{ matrix.test-scenario }}\n\n\`\`\`\n${reportContent}\n\`\`\``
            });

  integration-test-summary:
    name: Integration Test Summary
    runs-on: ubuntu-latest
    needs: constitutional-trainer-integration
    if: always()

    steps:
      - name: Download All Artifacts
        uses: actions/download-artifact@v4

      - name: Generate Summary Report
        run: |
          echo "# Constitutional Trainer Integration Test Summary" > summary.md
          echo "" >> summary.md
          echo "## Test Results by Scenario" >> summary.md
          echo "" >> summary.md

          for scenario in happy-path policy-violations performance-validation cache-behavior; do
            echo "### $scenario" >> summary.md
            if [ -f "constitutional-trainer-integration-test-results-$scenario/integration-test-report.txt" ]; then
              echo "\`\`\`" >> summary.md
              cat "constitutional-trainer-integration-test-results-$scenario/integration-test-report.txt" >> summary.md
              echo "\`\`\`" >> summary.md
            else
              echo "âŒ Test results not available" >> summary.md
            fi
            echo "" >> summary.md
          done

      - name: Upload Summary
        uses: actions/upload-artifact@v4
        with:
          name: integration-test-summary
          path: summary.md
          retention-days: 30
