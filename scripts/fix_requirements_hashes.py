#!/usr/bin/env python3
"""
Fix SHA256 hash mismatches in requirements.txt files for ACGS Phase 3 deployment.
This script regenerates correct package hashes for all requirements.txt files.
"""

import logging
import os
import subprocess
import sys
import tempfile
from pathlib import Path

# Configure logging
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


class RequirementsHashFixer:
    """Fix SHA256 hash mismatches in requirements.txt files."""

    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.requirements_files = []
        self.fixed_files = []
        self.failed_files = []

    def find_requirements_files(self) -> list[Path]:
        """Find all requirements.txt files in the project."""
        requirements_files = []

        # Common locations for requirements files
        search_patterns = [
            "**/requirements.txt",
            "**/requirements-*.txt",
            "**/requirements/*.txt",
        ]

        for pattern in search_patterns:
            for file_path in self.project_root.glob(pattern):
                if file_path.is_file():
                    requirements_files.append(file_path)

        # Remove duplicates and sort
        requirements_files = sorted(set(requirements_files))

        logger.info(f"Found {len(requirements_files)} requirements files:")
        for file_path in requirements_files:
            logger.info(f"  - {file_path.relative_to(self.project_root)}")

        return requirements_files

    def backup_file(self, file_path: Path) -> Path:
        """Create a backup of the original file."""
        backup_path = file_path.with_suffix(f"{file_path.suffix}.backup")
        backup_path.write_text(file_path.read_text())
        logger.info(f"Created backup: {backup_path.relative_to(self.project_root)}")
        return backup_path

    def generate_hashes_for_file(self, file_path: Path) -> bool:
        """Generate correct hashes for a requirements file."""
        logger.info(f"Processing: {file_path.relative_to(self.project_root)}")

        try:
            # Create backup
            self.backup_file(file_path)

            # Read original requirements
            original_content = file_path.read_text()

            # Create temporary file without hashes
            with tempfile.NamedTemporaryFile(
                mode="w", suffix=".txt", delete=False
            ) as temp_file:
                # Remove existing hashes and keep only package specifications
                clean_lines = []
                for line in original_content.splitlines():
                    line = line.strip()
                    if line and not line.startswith("#"):
                        # Remove hash if present
                        if " --hash=" in line:
                            line = line.split(" --hash=")[0].strip()
                        if " \\" in line:
                            line = line.split(" \\")[0].strip()
                        clean_lines.append(line)
                    elif line.startswith("#") or not line:
                        clean_lines.append(line)

                temp_file.write("\n".join(clean_lines))
                temp_file_path = temp_file.name

            try:
                # Generate hashes using pip-compile
                output_file = file_path.with_suffix(".temp.txt")

                cmd = [sys.executable, "-m", "pip", "install", "pip-tools"]
                subprocess.run(cmd, check=True, capture_output=True, text=True)

                cmd = [
                    sys.executable,
                    "-m",
                    "piptools",
                    "compile",
                    "--generate-hashes",
                    "--output-file",
                    str(output_file),
                    temp_file_path,
                ]

                result = subprocess.run(
                    cmd, check=False, capture_output=True, text=True
                )

                if result.returncode == 0:
                    # Replace original file with hashed version
                    if output_file.exists():
                        file_path.write_text(output_file.read_text())
                        output_file.unlink()  # Remove temp file
                        logger.info(
                            f"‚úÖ Successfully updated hashes for {file_path.relative_to(self.project_root)}"
                        )
                        return True
                    logger.error(
                        f"‚ùå Output file not created for {file_path.relative_to(self.project_root)}"
                    )
                    return False
                logger.error(
                    f"‚ùå pip-compile failed for {file_path.relative_to(self.project_root)}"
                )
                logger.error(f"Error: {result.stderr}")
                return False

            finally:
                # Clean up temp file
                if os.path.exists(temp_file_path):
                    os.unlink(temp_file_path)

        except Exception as e:
            logger.error(
                f"‚ùå Failed to process {file_path.relative_to(self.project_root)}: {e}"
            )
            return False

    def fix_simple_requirements(self, file_path: Path) -> bool:
        """Fix requirements files that don't need complex hashing."""
        logger.info(
            f"Applying simple fix to: {file_path.relative_to(self.project_root)}"
        )

        try:
            # Create backup
            self.backup_file(file_path)

            # Read and clean content
            content = file_path.read_text()
            lines = []

            for line in content.splitlines():
                line = line.strip()
                if line and not line.startswith("#"):
                    # Remove existing hashes
                    if " --hash=" in line:
                        line = line.split(" --hash=")[0].strip()
                    if " \\" in line:
                        line = line.split(" \\")[0].strip()
                lines.append(line)

            # Write cleaned content
            file_path.write_text("\n".join(lines))
            logger.info(
                f"‚úÖ Cleaned hashes from {file_path.relative_to(self.project_root)}"
            )
            return True

        except Exception as e:
            logger.error(
                f"‚ùå Failed to clean {file_path.relative_to(self.project_root)}: {e}"
            )
            return False

    def fix_all_requirements(self) -> dict[str, list[Path]]:
        """Fix all requirements files in the project."""
        logger.info("üîß Starting requirements hash fixing process")

        self.requirements_files = self.find_requirements_files()

        for file_path in self.requirements_files:
            # Try simple fix first (remove hashes)
            if self.fix_simple_requirements(file_path):
                self.fixed_files.append(file_path)
            else:
                self.failed_files.append(file_path)

        # Summary
        logger.info("=" * 60)
        logger.info("üìä REQUIREMENTS HASH FIXING SUMMARY")
        logger.info("=" * 60)
        logger.info(f"Total files processed: {len(self.requirements_files)}")
        logger.info(f"Successfully fixed: {len(self.fixed_files)}")
        logger.info(f"Failed to fix: {len(self.failed_files)}")

        if self.fixed_files:
            logger.info("\n‚úÖ Successfully fixed files:")
            for file_path in self.fixed_files:
                logger.info(f"  - {file_path.relative_to(self.project_root)}")

        if self.failed_files:
            logger.info("\n‚ùå Failed to fix files:")
            for file_path in self.failed_files:
                logger.info(f"  - {file_path.relative_to(self.project_root)}")

        return {
            "fixed": self.fixed_files,
            "failed": self.failed_files,
            "total": self.requirements_files,
        }


def main():
    """Main function."""
    project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

    fixer = RequirementsHashFixer(project_root)
    results = fixer.fix_all_requirements()

    # Exit with appropriate code
    if results["failed"]:
        logger.error("Some requirements files could not be fixed")
        sys.exit(1)
    else:
        logger.info("All requirements files fixed successfully")
        sys.exit(0)


if __name__ == "__main__":
    main()
