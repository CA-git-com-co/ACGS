[tool:pytest]
# ACGS E2E Test Configuration

# Test discovery
testpaths = tests/e2e/tests
python_files = test_*.py *_test.py
python_classes = Test* *Test
python_functions = test_*

# Test execution options
addopts = 
    -v
    --tb=short
    --strict-markers
    --strict-config
    --disable-warnings
    --color=yes
    --durations=10
    --maxfail=10

# Markers for test categorization
markers =
    smoke: Quick smoke tests for basic validation
    constitutional: Constitutional compliance and validation tests
    hitl: Human-in-the-loop decision processing tests
    performance: Performance, latency, and load tests
    security: Security, authentication, and compliance tests
    integration: Service integration and communication tests
    governance: Multi-agent governance and coordination tests
    infrastructure: Infrastructure component and connectivity tests
    slow: Slow running tests (>30 seconds)
    critical: Critical tests that block deployment
    regression: Regression tests for performance validation
    
# Test filtering
filterwarnings =
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning
    ignore::UserWarning:asyncio
    ignore::UserWarning:httpx

# Asyncio configuration
asyncio_mode = auto

# Timeout configuration
timeout = 300
timeout_method = thread

# Coverage configuration
addopts = --cov=tests/e2e --cov-report=term-missing --cov-report=html --cov-report=xml

# Minimum coverage threshold
# addopts = --cov-fail-under=80

# Test output configuration
junit_family = xunit2
junit_logging = all
junit_log_passing_tests = true

# Logging configuration
log_cli = true
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(name)s: %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

# File logging
log_file = reports/pytest.log
log_file_level = DEBUG
log_file_format = %(asctime)s [%(levelname)8s] %(filename)s:%(lineno)d: %(message)s
log_file_date_format = %Y-%m-%d %H:%M:%S

# Performance testing
benchmark_json = reports/benchmark.json
benchmark_sort = mean
benchmark_compare_fail = mean:10%

# Parallel execution
# addopts = -n auto
