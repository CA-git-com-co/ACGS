# 2203.04291_Learning-from-Few-Examples-A-Summary-of-Approaches
**Constitutional Hash: cdd01ef066bc6cf2**


**Original PDF**: 2203.04291_Learning-from-Few-Examples-A-Summary-of-Approaches.pdf
**Conversion Method**: PyMuPDF
**Constitutional Hash**: cdd01ef066bc6cf2



## Implementation Status

- ‚úÖ **Constitutional Hash Validation**: Active enforcement of `cdd01ef066bc6cf2`
- üîÑ **Performance Monitoring**: Continuous validation of targets
- ‚úÖ **Documentation Standards**: Compliant with ACGS-2 requirements
- üîÑ **Cross-Reference Validation**: Ongoing link integrity maintenance

**Overall Status**: üîÑ IN PROGRESS - Systematic enhancement implementation

## Performance Targets

This component maintains the following performance requirements:

- **P99 Latency**: <5ms (constitutional requirement)
- **Throughput**: >100 RPS (minimum operational standard)
- **Cache Hit Rate**: >85% (efficiency requirement)
- **Constitutional Compliance**: 100% (hash: cdd01ef066bc6cf2)

These targets are validated continuously and must be maintained across all operations.

---

## Page 1

## Learning From Few Examples:

## A Summary Of Approaches To Few-Shot Learning

Archit Parnami and Minwoo Lee

Department of Computer Science

The University of North Carolina at Charlotte

Charlotte, NC, USA

{aparnami, minwoo.lee}@uncc.edu

## Abstract

Few-Shot Learning refers to the problem of learning the underlying pattern in the data just from

a few training samples. Requiring a large number of data samples, many deep learning solutions

suffer from data hunger and extensively high computation time and resources. Furthermore, data is

often not available due to not only the nature of the problem or privacy concerns but also the cost of

data preparation. Data collection, preprocessing, and labeling are strenuous human tasks. Therefore,

few-shot learning that could drastically reduce the turnaround time of building machine learning

applications emerges as a low-cost solution. This survey paper comprises a representative list of

recently1 proposed few-shot learning algorithms. Given the learning dynamics and characteristics,

the approaches to few-shot learning problems are discussed in the perspectives of meta-learning,

transfer learning, and hybrid approaches (i.e., different variations of the few-shot learning problem).

1Until January 2020.

arXiv:2203.04291v1  [cs.LG]  7 Mar 2022

## Page 2

Parnami & Lee

Contents

1

Introduction

3

2

Background

3

2.1

Meta-Learning

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3

2.1.1

Problem DeÔ¨Ånition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

4

2.1.2

Nomenclature . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

5

3

Few-Shot Learning

5

3.1

The Few-Shot ClassiÔ¨Åcation Problem

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

5

3.2

Meta-Learning-based Few-Shot Learning

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

7

3.2.1

Main Approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

7

3.2.1.1

Metric-based Meta-Learning

. . . . . . . . . . . . . . . . . . . . . . . . . . . . .

8

3.2.1.2

Optimization-based Meta-Learning . . . . . . . . . . . . . . . . . . . . . . . . . .

14

3.2.1.3

Model-based Meta-Learning

. . . . . . . . . . . . . . . . . . . . . . . . . . . . .

20

3.2.2

Hybrid Approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

24

3.3

Non-Meta-Learning based Few-Shot Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

25

3.3.1

Transfer Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

25

3.3.2

Miscellaneous: Autoencoders

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

26

4

Progress in Few-Shot Learning

27

5

Challenges and Open Problems

27

List of Tables

1

Nomenclature . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

5

2

Symbols . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

6

3

Common datasets used for Few-Shot Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

7

4

Meta-Learning Approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

7

5

Metric-based Meta-Learning Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

9

6

Optimization-based Meta-Learning Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

15

7

Model-based Meta-Learning Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

20

8

Hybrid Approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

24

9

Accuracy of 5-way classiÔ¨Åcation task on miniImageNet . . . . . . . . . . . . . . . . . . . . . . . . .

28

2

## Page 3

Parnami & Lee

1

Introduction

The Ô¨Åeld of ArtiÔ¨Åcial Intelligence (AI) has been through ups and downs since its inception in the 1950s. Yet, the last

few years have been marked by exceptional progress in the Ô¨Åeld of AI. Much of this progress can be attributed to

recent advances in ‚Äúdeep learning‚Äù characterized by learning large neural network-style models with multiple layers

of representation. These models have shown great performance in a variety of tasks with large amounts of labeled

data in image classiÔ¨Åcation [1], machine translation [2] and speech modeling [3]. However, these achievements have

relied on the fact that the optimization of these deep, high-capacity models requires many iterative updates across many

labeled examples. This type of optimization breaks down in the small data regime where we want to learn from very

few labeled examples. In contrast, humans can quickly learn to solve a new problem just from a few examples. For

instance, given a few photos of a stranger, one can easily identify the same person from a large number of photos. This

is not only due to the human mind‚Äôs computational power but also to its ability to synthesize and learn new information

from previously learned information. For example, if a person has a skill for riding a bicycle, that skill can prove helpful

when learning to ride a motorcycle.

Recent years have seen a rise of research attempting to bridge this gap between human-like learning and machine

learning, which has given birth to this new sub-Ô¨Åeld of Machine Learning known as Few-Shot Learning (FSL) i.e., the

ability of machine learning models to generalize from few training examples. When there is only one example to

learn from, FSL is also referred to as One-Shot Learning. The motivation for FSL lies in the fact that models excelling at

this task would have many useful applications. First, we would not be required to collect thousands of labeled examples

to attain a reasonable performance on a new task which would help alleviate the data-gathering effort and reduce the

computation costs and time spent in training a model. Furthermore, in many Ô¨Åelds, data is hard or impossible to acquire

due to reasons such as privacy and safety. Models that generalize from a few examples would be able to capture this

type of data effectively. Therefore in this survey, we study various approaches that have been recently proposed in an

attempt to solve the problem of Few-Shot Learning. We categorize the FSL approaches as seen in Figure 1.

Much of the work in this survey is inspired from prior works that attempted to summarize the Ô¨Åeld of few-shot learning.

Wang et al. [4] deÔ¨Ånes the core issue of FSL as an unreliable empirical risk minimizer that makes it a hard problem.

Chen et al. [5] present a comparative analysis of several representative few-shot classiÔ¨Åcation algorithms. Similar

to ours, Weng [6] discusses meta-learning approaches to FSL. In addition, we discuss non-meta-learning and hybrid

meta-learning approaches to FSL. We also extend the discussion of main meta-learning approaches by including the

recent state-of-the-art methods.

The rest of the survey is organized as follows. Section 2 covers meta-learning which is a prerequisite to understand

recent FSL methods. Section 3 deÔ¨Ånes the few-shot classiÔ¨Åcation problem, introduces the available datasets, and divides

the approaches to FSL into two sub-sections: Meta-Learning-based FSL (Section 3.2 and Non-Meta-Learning-based

FSL (Section 3.3). Next, we list the performance of various FSL methods and progress made so far in Section 4. Finally,

we conclude with a discussion on challenges involved in Section 5.

2

Background

In this section, we discuss the necessary background required for understanding the recent few-shot learning algorithms.

2.1

Meta-Learning

Meta-Learning [7, 8] or Learning to Learn [9] has been the basic technique which most few-shot learning algorithms

employ. Motivated by human development theory, meta-learning, a sub-Ô¨Åeld of machine learning, focuses on learning

priors from previous experiences that can lead to efÔ¨Åcient downstream learning of new tasks. For instance, a simple

learner learns a single classiÔ¨Åcation task, but a meta-learner gains an understanding of learning to solve a classiÔ¨Åcation

task by exposing itself to multiple similar classiÔ¨Åcation tasks. Hence when presented with a similar but new task, the

meta-learner could solve it quickly and better than a simple learner which has no prior experience in solving the task. A

meta-learning procedure generally involves learning at two levels, within and across tasks. First, rapid learning occurs

within a task, for example, learning to accurately classify within a particular dataset. Next, this learning is guided by

knowledge accrued more gradually across tasks, which captures the way task structure varies across target domains.

Meta-Learning can be different from similar approaches such as transfer learning, multi-task learning, or ensemble

learning. In Transfer Learning [10], a model is trained on a single task known as the source task in the source domain

where the sufÔ¨Åcient training data is available. This trained model is then again retrained or Ô¨Ånetuned on another single

task known as the target task in the target domain. The transfer of knowledge occurs from the source task to the target

task. Thus more similar the two domains are the better it performs . Multi-Task Learning [11], involves learning

3

## Page 4

Parnami & Lee

Figure 1: Approaches to FSL are categorized into Meta-Learning-based FSL and Non-Meta-Learning-based FSL.

The three main meta-learning approaches are: metric-based, optimization-based and model-based meta-learning.

Furthermore, variations of the FSL problem which use meta-learning are categorized as hybrid approaches.

multiple tasks simultaneously. It starts from no prior experience and attempts to optimize over solving multiple tasks at

the same time. On the other hand, Ensemble Learning [12] is the process by which multiple models, such as classiÔ¨Åers

or experts, are strategically generated and combined to solve a particular task. In contrast, meta-learner Ô¨Årst gathers

experience across multiple similar tasks and then use that experience to solve new tasks. Nonetheless, these techniques

can be and often are meaningfully combined with meta-learning systems. We provide the formal deÔ¨Ånition for the

meta-learning problem and explain it with the help of an example.

2.1.1

Problem DeÔ¨Ånition

In a typical supervised learning setting, we are interested in a task T with a dataset D = {(xk, yk)}n

k=1 with n data

samples. We usually split D into Dtrain and Dtest such that:

Dtrain = {(xk, yk)}t

k=1

(1)

and

Dtest = {(xk, yk)}n

k=t+1,

(2)

where t denotes the number of training samples. We optimize parameters Œ∏ on the training set Dtrain and evaluate its

generalization performance on the test set Dtest. Thus the learning problem here is to approximate the function f with

parameters Œ∏ as 2:

y ‚âàf(x; Œ∏) where (x, y) ‚ààDtest

(3)

and

Œ∏ = arg min

Œ∏

## X

(x,y)‚ààDtrain

L(f(x, Œ∏), y)

(4)

2We omit sample subscript k for simplicity in the following discussion

4

## Page 5

Parnami & Lee

where L is any loss function measuring the error between the prediction f(x, Œ∏) and the true label y.

In meta-learning, we have a distribution p(T ) of task T . A meta-learner learns from a set of training tasks Ti

train

‚àº

p(T )

and is evaluated on a set of testing tasks Ti

test

‚àºp(T ). Each of these task has its own dataset Di where Di =

{Dtrain

i

, Dtest

i

}.

Let us denote the set of training tasks as Tmeta‚àítrain = {T1, T2, ....., Tn} and the set of testing tasks as Tmeta‚àítest =

{Tn+1, Tn+2, ....., Tn+k}.

Correspondingly, the training dataset for the meta-learner will be Dmeta‚àítrain =

{D1, D2, ....., Dn} and the testing dataset will be Dmeta‚àítest = {Dn+1, Dn+2, ....., Dn+k}.

The parameters Œ∏ of the meta-learner are optimized on Dmeta‚àítrain and its generalization performance is tested on

Dmeta‚àítest. Then, the meta-learning problem is to approximate the function f with parameters Œ∏ as:

y ‚âàf(Dtrain

i

, x; Œ∏) where (x, y) ‚ààDtest

i

(5)

and

Di = {Dtrain

i

, Dtest

i

} where Di ‚ààDmeta‚àítest

i.e., Di is the dataset for a test task Ti sampled from Tmeta‚àítest. Then the optimal model parameters are obtained as:

Œ∏ = arg min

Œ∏

## X

Di‚ààDmeta‚àítrain

## X

(x,y)‚ààDtest

i

L(f(Dtrain

i

, x; Œ∏), y).

(6)

That is the meta-learner learns parameters Œ∏ such that given a task Ti ‚àºp(T ), its performance on its test data Dtest

i

given its training data Dtrain

i

would be optimal. Figure 2 demonstrates a setup for example meta-learning problem.

2.1.2

Nomenclature

In meta-learning and few-shot learning literature, certain notations and terms are used interchangeably. Table 1 lists

these terms and their equivalent usage. Notation A is more commonly used in optimization-based meta-learning

literature (Section 3.2.1.2) while notation B is used when discussing metric-based meta-learning methods (Section

3.2.1.1). Additionally, Table 2 lists the commonly used symbols in this survey.

Notation A

Term A

Notation B

Term B

Dtrain

i

Training set for task Ti

Si

Support Set for task Ti

Dtest

i

Test set for task Ti

Qi

Query Set for task Ti

Dmeta‚àítrain

Meta-training set

Dtrain

Training Set

Dmeta‚àítest

Meta-testing set

Dtest

Test Set

Table 1: Nomenclature

3

Few-Shot Learning

Much of the recent progress in FSL has come through meta-learning. Therefore we Ô¨Årst divide the approaches to FSL

into two categories: meta-learning-based FSL and non-meta-learning-based FSL. Also, most of these approaches that

we are about to discuss were developed with the perspective of solving the few-shot image classiÔ¨Åcation problem.

However, they are still applicable for solving other problems such as regression, object detection, segmentation, online

recommendation, reinforcement learning, etc. We discuss the approaches to the few-shot image classiÔ¨Åcation problem

in this section and the applications to other domains in Section 4 .

3.1

The Few-Shot ClassiÔ¨Åcation Problem

Consider the task T (deÔ¨Åned in Section 2.1.1) as a classiÔ¨Åcation task where x is input and y is the output label. The

objective is to approximate the function f (Eqn. 3) with parameters Œ∏ (Eqn. 4) . This is generally possible when we

have sufÔ¨Åcient training data Dtrain (Eqn. 1) i.e., t is a large number. However, when t is small, it becomes difÔ¨Åcult to

approximate the function f so that it has good generalization performance over Dtest (Eqn. 2). This can be referred to

as a few-shot classiÔ¨Åcation problem as the number of examples (shots) are too few to learn a good model.

5

## Page 6

Parnami & Lee

Figure 2: Meta-Learning Example Setup. Each task Ti is a binary classiÔ¨Åcation task with a training set Dtrain

i

and

test set Dtest

i

. During meta-training, the labels for samples in Dtest

i

is known and the goal of meta-learner is to Ô¨Ånd

optimal Œ∏ as per equation 6. During meta-testing, new task with unseen categories is presented and the labels are

predicted as per equation 5 .

Symbol

Meaning

Context

Ti

Task i

## L

Loss function

(xk, yk)

Input-Output pair

fŒ∏

Model (function) with parameters Œ∏

gŒ∏1

Embedding function

Sec. 3.2.1.1

dŒ∏2 or d

Distance function

Sec. 3.2.1.1

gœÜ

Meta-Learning model with parameters œÜ

Sec. 3.2.1.2

PŒ∏(y|x)

Output probability of y for input x using model parameters Œ∏

kŒ∏(x1, x2)

Kernel function measuring similarity between two vectors x1 and x2

Table 4

œÉ

Softmax function

Œ±, Œ≤

Learning rates

w

Weights

vc

Prototype of class c

Eq. 9

## C

Set of classes present in S

Sc

Subset of S containing all elements (xk, yk) such that yk = c

‚äï

Concatenation operator

Table 5

## B

Number of batches (Xb, Yb) sampled in inner-loop for a randomly sampled task Ti

Table 6

## I

Number of tasks Ti sampled in inner-loop

Table 6

## J

Number of outer-loop iterations

Table 6

Table 2: Symbols

6

## Page 7

Parnami & Lee

Usually people deÔ¨Åne few-shot classiÔ¨Åcation task as a standard M-way-K-shot task [13, 14], where M is the number of

classes and K is the number of examples per class present in Dtrain. Usually K is a small number (ex., 1,5,10) and

|Dtrain| = M √ó K. The performance is measured by a loss function L(ÀÜy, y) deÔ¨Åned over the prediction ÀÜy = f(x, Œ∏)

and the ground truth y.

The M-way-K-shot tasks are usually sampled from a larger dataset with classes much higher in number than M. Table

3 lists such commonly used datasets for conducting experiments for few-shot classiÔ¨Åcation.

Dataset

Number of classes

Samples per class

Description

Omniglot [15]

1623

20

Handwritten characters from different languages.

miniImageNet [13]

100

600

100 classes randomly sampled from ImageNet.

## Fc100 [16]

100

600

Derived from CIFAR100 for FSL.

tieredImageNet [17]

608

1280 (avg.)

Like miniImageNet but ensures that there is a

wider degree of separation between training, val-

idation and test classes.

Table 3: Common datasets used for Few-Shot Learning

3.2

Meta-Learning-based Few-Shot Learning

The objective of meta-learning is to approximate the function f with parameters Œ∏ such that the performance on any task

Ti randomly sampled from the task distribution p(T ) is optimal (equation 5). We use this strategy for FSL such that the

distribution p(T ) is now a distribution of few-shot tasks and each task Ti is a few-shot task. For example, consider

the M-way-K-shot few-shot classiÔ¨Åcation (FSC) task. During training, we meta-learn a prior Œ∏ over a distribution of

M-way-K-shot FSC tasks so that at test time we can solve for a new M-way-K-shot FSC task.

Meta-Learning-based FSL can be classiÔ¨Åed into three approaches [18]: metric-based, optimization-based and model-

based. Further, various meta-learning-based hybrid approaches were proposed to handle FSL problems such as

cross-domain FSL, generalized FSL, etc. We discuss the three main approaches in Section 3.2.1 and hybrid approaches

in Section 3.2.2.

3.2.1

Main Approaches

Consider a task T with support set S and query set Q. Let f be a few-shot classiÔ¨Åcation model with parameters Œ∏. Then

for (x, y) ‚ààQ, the meta-learning approaches to FSL can be differentiated in the way they model the output probability

PŒ∏(y|x) [18] (Table 4).

Metric-based

Optimization-based

Model-based

Key idea

Metric Learning [19]

Gradient Descent

Memory; RNN

How PŒ∏(y|x)

is modeled?

## X

(xk,yk)‚ààS

kŒ∏(x, xk)yk,

PŒ∏‚Ä≤(y|x),

where Œ∏

‚Ä≤ = gœÜ(Œ∏, S)

fŒ∏(x, S).

Advantages

Faster Inference.

Offers Ô¨Çexibility to optimize

in dynamic environments.

Faster inference with mem-

ory models.

Easy to deploy.

S can be discarded post-

optimization.

Eliminates the need for deÔ¨Ån-

ing a metric or optimizing at

test.

Disadvantages Less adaptive to optimization

in dynamic environments.

Optimization at inference is

undesirable for real-world

deployment.

Less efÔ¨Åcient to hold data in

memory as S grows.

Computational complexity

grows linearly with size of

S at test.

Prone to overÔ¨Åtting.

Hard to design.

Table 4: Meta-Learning Approaches

7

## Page 8

Parnami & Lee

3.2.1.1

Metric-based Meta-Learning

Metric Learning [19] is the task of learning a distance function over data samples. Consider two image-label pair

(x1, y1) and (x2, y2) and a distance function d to measure the distance between two images. If we were to assign a label

to a query image x3, we could compute the two distances d(x1, x3) and d(x2, x3)) and assign the label corresponding

to the image with a shorter distance, which is also the key idea in nearest neighbors algorithms (k-NN). However, with

high dimensional inputs such as images, we typically use an embedding function g to transform the input to a lower

dimension before computing the distances:

g: Rn ‚ÜíRm where n > m.

Therefore, the core idea behind metric-based few-shot learning is to leverage meta-learning architecture to either learn

an embedding function g(; Œ∏1) (parameterized by a neural network with parameters Œ∏1) given a distance function d

(such as euclidean distance) or to learn both the embedding function g(; Œ∏1) (with parameters Œ∏1) and the distance

function d(; Œ∏2) (usually parameterized by another neural network with parameters Œ∏2). This is illustrated in Figure 3 .

Figure 3: Example metric-based meta-learning setup for a 4-way-1-shot classiÔ¨Åcation task. The embedding function gŒ∏1

outputs the embedding vectors for support images (labeled) and the query image (unlabeled, denoted by ‚Äô?‚Äô). Distance

function dŒ∏2 measures the distance between support and query vectors to output a similarity score.

Training proceeds by randomly sampling M-way-K-shot episodes from the training set. Each episode has a support set

and a query set. The average error computed on query sets across multiple training few-shot episodes is used to update

the parameters of the embedding function and the distance function (if any). Finally, new M-way-K-shot episodes are

sampled from the testing set to evaluate the performance of the network. This episodic training paradigm is explained

in Algorithm 1 .

Table 5 compares the recent metric-based meta-learning methods based on their characteristics like embedding function,

distance measure, prediction method, loss function and if the embedding function is Ô¨Åxed for all tasks i.e., task-

independent (T.I) or is adaptive (task-dependent). In the following paragraphs we discuss each of these methods in

further detail.

8

## Page 9

Parnami & Lee

Algorithm 1: Episodic Training in Metric-based Meta-Learning Methods

Given: In dataset D, n is the number of examples, N is the set of classes, Ntrain is the set of classes used for

training, Ntest is the set of classes used for testing, M < Ntrain is the number of classes per episode, K is the

number of support examples per class, Q is the number of query examples per class. RandomSample(A, B)

denotes a set of B elements chosen uniformly at random from set A, |Ntrain| + |Ntest| = |N| and

Ntrain ‚à©Ntest = ‚àÖ.

Input: D = {(x1, y1), ..., (xn, yn)} where yi ‚àà{1, ..., N}. Dc denotes the subset of D containing all elements

(xi, yi) such that yi = c.

Training:

‚ñ∑M-way K-shot training episodes

while True do

‚ñ∑1.

Constructing Task

C ‚ÜêRandomSample(Ntrain, M)

‚ñ∑Sample M classes

## S ‚Üê{}

‚ñ∑Support set

## Q ‚Üê{}

‚ñ∑Query set

for c in C do

Sc ‚ÜêRandomSample(Dc, K)

‚ñ∑Sample K support

Qc ‚ÜêRandomSample(Dc \ Sc, Q)

‚ñ∑Sample Q query

S ‚ÜêS ‚à™Sc

Q ‚ÜêQ ‚à™Qc

end

‚ñ∑2.

Learning Metric

for i ‚Üê1 to |S| do

(xs, ys) ‚ÜêS[i]

for j ‚Üê1 to |Q| do

(xq, yq) ‚ÜêQ[j]

dij ‚ÜêdŒ∏2(gŒ∏1(xs), gŒ∏1(xq)))

‚ñ∑Compute distances

end

end

Compute total loss L based on dij‚Äôs such that dij is minimum when yi = yj and maximum otherwise.

Update parameters Œ∏1 and Œ∏2 on L.

end

Testing: Sample a random M-way K-shot episode but this time using the classes from Ntest and evaluate its

performance.

Method

## T.I

gŒ∏1

dŒ∏2

Prediction

Loss

Siamese Net-

works [20]

Yes

## Cnn

## L1

v = w ¬∑ d(gŒ∏1(x1), gŒ∏2(x2))

p = sigmoid(P

j vj)

‚àí(y log(p)

+

(1 ‚àíy)(log(1 ‚àí

p))

Matching Net-

works [13]

Yes

## Cnn

+

LSTM w/

attention

Cosine

Similarity

ÀÜy

=

Pt

k=1 œÉ(d(fŒ∏(ÀÜx), gŒ∏1(xk))yk

P(y = c|ÀÜx) = ÀÜyc

‚àílog P

Prototypical

Networks [21]

Yes

## Cnn

Euclidean

P(y

=

c|x)

=

œÉ(‚àíd(gŒ∏1(x), vc))

‚àílog P

Relation Net-

works [22]

Yes

## Cnn

Learned

by CNN

rc = dŒ∏2(gŒ∏1(x) ‚äïvc))

## P

c‚ààC

(rc

‚àí

1(y == c))2

## Tadam [16]

No

ResNet-

12

Cosine

/

Euclidean

PŒª(y

=

c|x)

=

œÉ(‚àíŒªd(gŒ∏1(x, Œì), vc))

‚àílog P

TapNet [23]

No

Resnet-12

Euclidean

P(y

=

c|x)

=

œÉ(‚àíd(M(gŒ∏1(x)), M(Œ¶c)))

‚àílog P

## Ctm [24]

No

Any

Any

-

-

Table 5: Metric-based Meta-Learning Methods

9

## Page 10

Parnami & Lee

Convolutional Siamese Networks

Siamese Neural Networks [25] are a pair of identical neural networks with shared weights originally proposed for

signature veriÔ¨Åcation. The two networks are joined at their output, where the joining neurons measures the distance

between the feature vector output of each network. In 2015, Koch et al. [20] used a pair of identical convolutional

neural networks (CNNs) [26] with shared weights as done in Siamese Networks for image veriÔ¨Åcation. The network

was trained to recognize if the two images belong to the same class or not. The network outputs a probability score

(similarity) of the two images belonging to the same class. This idea was further extended to perform one-shot

recognition by comparing the similarity score between a query image and support images from different classes. This is

illustrated in Figure 4 . Here the embedding function gŒ∏1 is a CNN and the distance between two embedding vectors

is simply the L1 distance i.e., |gŒ∏1(x1) ‚àígŒ∏1(x2)|. The distance is converted to the probability of similarity by a

linear feed-forward layer and a sigmoid function. The network is then trained on binary cross-entropy loss. Similar to

Convolutional Siamese Networks, Mehrotra et al. [27] proposed Skip Residual Pairwise Networks (SRPNs) where

they used a Wide Residual Network [28] as the embedding function gŒ∏1 and a network of residual blocks to act as the

distance function dŒ∏2.

Figure 4: Convolutional Siamese Network

Matching Networks

Given a support set S = {xi, yi}K

k=1 and a query ÀÜx, Matching Networks [13] (Figure 5) deÔ¨Åne a probability distribution

over the output labels y using an attention kernel a(ÀÜx, xk) . The attention kernel basically computes the cosine similarity

between the embeddings of support and query examples and then normalize the similarity score by taking a softmax:

a(ÀÜx, xk) = ecos(f(ÀÜx),g(xk))/

t

## X

k=1

ecos(f(ÀÜx),g(xk)).

(7)

The classiÔ¨Åer‚Äôs output is then deÔ¨Åned as a sum of the labels (one-hot encoded) of support samples weighted by the

attention kernel a(ÀÜx, xk) :

P(y|ÀÜx, S) =

## K

## X

k=1

a(ÀÜx, xk)yk

(8)

In a simple case, the embedding function for query (fŒ∏) and the embedding function for examples in the support set

(gŒ∏1) are same i.e., f = g. Alternatively, Matching Networks propose using Full Context Embeddings where embedding

functions contextually embeds images i.e for a given support image x and support set S, the embedding of x is obtained

by gŒ∏1 in the presence of S as gŒ∏1(x; S) . Similarly for a query ÀÜx, its embedding would be fŒ∏(ÀÜx; S). i.e., S should be

able to modify how we embed ÀÜx through f. Using contextual embedding showed in improvement in the performance of

few-shot classiÔ¨Åcation on miniImageNet but no difference was observed on the simpler omniglot dataset.

10

## Page 11

Parnami & Lee

Figure 5: Matching Networks (Figure adapted from [13]).

Prototypical Networks

Prototypical Networks [21] use a 4-layer-CNN as an embedding function gŒ∏1. A prototype for each class is deÔ¨Åned by

taking an average of embedding vectors obtained from the support images belonging to that class (Eqn. 9):

vc =

1

|Sc|

## X

(xk,yk)‚ààSc

gŒ∏1(xk).

(9)

The similarity is measured by calculating the squared euclidean distance between the query‚Äôs embedding and each class

prototype. The output probability over classes is calculated by taking a softmax over the negative distances (Eqn. 10):

P(y = c|ÀÜx) = softmax(‚àíd(gŒ∏1(ÀÜx), vc)) =

e(‚àíd(gŒ∏1(ÀÜx),vc))

## P

ÀÜc‚ààC e(‚àíd(gŒ∏1(ÀÜx),vÀÜc)) .

(10)

The loss L is given by the negative log-likelihood of the correct class (Eqn. 11):

L(Œ∏1) = ‚àílog PŒ∏1(y = c|ÀÜx).

(11)

Furthermore, to generate more discriminative embeddings, Zhang et al. [29] proposed using a multi-way contrastive

loss function with margin to pull the examples belonging to the same class together and push the others away in the

embedding space.

Figure 6: Few-shot prototypes vc are computed as the mean of embedded support examples for each class. The

embedded query points are classiÔ¨Åed via a softmax over distances to the class prototypes.

11

## Page 12

Parnami & Lee

Relation Networks

Relation Networks [22] get rid of manually constructing a similarity metric and instead just employs another CNN to

output a similarity score. The representations of the support and query examples (obtained from g) are concatenated

together and fed into d to obtain a relation score between each query and a support class (Figure 3). When the number

of support examples per class are more than one, the relation score is calculated between a query and a prototype of a

class vc, which is an element wise sum of embeddings of support examples of that class. The relation score for a match

should be 1 and 0 for a no-match. The network is then trained to minimize the mean squared error of relation scores.

Relation score of query ÀÜx with class c :

rc = dŒ∏2(gŒ∏1(ÀÜx) ‚äïvc)

Optimization Objective:

Œ∏1, Œ∏2 ‚Üêarg min

Œ∏1,Œ∏2

## X

c‚ààC

(rc ‚àí1(y == c))2

Figure 7: Relation Network (Source: [22])

Task-Dependent Adaptive Metric (TADAM)

In the approaches discussed previously, the embedding function gŒ∏1 was task-independent, meaning given any task

T ‚àºp(T ), its samples will be embedded using a Ô¨Åxed embedding function gŒ∏1. Moreover, the choice of distance

metric function (i.e. cosine or euclidean) was also something to be experimented with depending upon the task at hand.

Oreshkin et al. [16] proposed using 1) a learnable softmax temperature [30] with a scaling factor Œ± to bridge the gap

between the performance of cosine and euclidean distance metric and 2) a Task Embedding Network (TEN) factored

into the embedding network gŒ∏1 to output task adaptive representations. These contributions combined with using a

deeper embedding network (Resnet-12 [1]) as the feature extractor resulted in 8.5% absolute accuracy improvement

over Prototypical Networks [21] on the miniImageNet [13] 5-way 5-shot classiÔ¨Åcation task.

1. Metric Scaling: It was observed that Prototypical Networks [21] which used euclidean distance performed

better on few-shot image classiÔ¨Åcation when compared to Matching Networks [13] which used cosine distance.

Oreshkin et al. [16] suggested that the difference in performance could be directly attributed to the interaction

of the different scaling of the metrics with the softmax. Hence they propose to scale the distance metric by a

learnable temperature, Œª, and observed that both distances produced equivalent performance when scaled with

learned parameter Œª (Eqn. 12):

PŒª(y = c|x) = softmax(‚àíŒªd(gŒ∏1(x), vc)).

(12)

2. Task Conditioning: Previously, Matching Networks used contextual embeddings i.e, embedding for an input

image x was obtained in presence of its support set S, gŒ∏1(x; S). This was achieved with a bidirectional

LSTM as a post-processing of a Ô¨Åxed feature extractor. Differently, TADAM explicitly deÔ¨Åne a dynamic

feature extractor gŒ∏1(x, Œì) where Œì is the set of parameters predicted from a task representation such that the

performance of gŒ∏1(x, Œì) is optimized given the task sample set S.

12

## Page 13

Parnami & Lee

Task-Adaptive Projection (TapNet)

In addition to the embedding function gŒ∏1 and the distance function d, TapNet [23] proposed a concept of per-class

reference vectors Œ¶ and a task dependent projection space or mapping M. Unlike class prototypes in Prototypical

Networks, reference vectors Œ¶ for each class are learned. The projection space M is non-parametric and is built speciÔ¨Åc

to each task. The input query x is then classiÔ¨Åed by measuring its distance to different reference vectors Œ¶ in the

projection space M (Eqn. 13):

P(y = c|x) = softmax(‚àíd(M(gŒ∏1(x)), M(Œ¶c))).

(13)

The motivation is to Ô¨Ånd a projection space M which could remove the misalignment between the task-embedded

features and the references and thus resulting in better classiÔ¨Åcation performance.

Task-Relevant Features (CTM)

Similar to Matching Networks, Li et al. [24] propose using a plugable component called Category Traversal Module

(CTM) parameterized by œÜ to Ô¨Ånd contextual embeddings of the images in the support set S and the query set Q. The

parameters œÜ are learned during the training along with parameters Œ∏1 of the embedding function g.

CTM(gŒ∏1(S); œÜ) ‚ÜíI(S)

CTM(gŒ∏1(Q); œÜ) ‚ÜíI(Q)

The CTM takes support set features gŒ∏1(S) as an input and produces a mask p via a concentrator and projector that

make use of intra and inter-class views respectively. The mask p is applied to reduced-dimension features of both the

support and query, producing improved features I with dimensions relevant for the current task. These improved feature

embeddings are Ô¨Ånally fed into a metric learner. This is illustrated in Figure 8.

Figure 8: Category Traversal Module (CTM) (Figure adapted from [24])

3.2.1.1.1

Attention-based methods

Much like Matching Networks and CTM, few others have proposed integrating attention [31] modules in existing

methods for learning more discriminative feature embeddings. Hou et al. [32] proposed Cross Attention Networks

(CAN) with a Cross Attention Module (CAM) to transform the class prototypes P and query Q to more discriminative

prototypes ¬ØP and query ¬ØQ. Furthermore, Hao et al. [33] propose Semantic Alignment Metric Learning (SAML) method

to align semantically relevant local regions on support and query images using attention maps.

13

## Page 14

Parnami & Lee

3.2.1.2

Optimization-based Meta-Learning

Earlier in Section 3.1, we discussed that for a few-shot classiÔ¨Åcation task T with training data Dtrain (Eqn. 1) where

the number of training examples t is small, it is difÔ¨Åcult to approximate f (Eqn. 3) with parameters Œ∏ (Eqn. 4) from

scratch using gradient-based optimization as its not designed to cope with small number of training samples and thus

will lead to overÔ¨Åtting. This ponders the question, "is there any way to optimize on limited training data and still achieve

good generalization performance?" Optimization-based meta-learning for FSL answers to this question. Basically,

leveraging the meta-learning architecture (Figure 2) and episodic training (Algorithm 1), optimization-based methods

enables an optimization procedure to work on limited training examples.

Learner and Meta-Learner

Optimization-based methods generally involves learning in two stages:

1. Learner: A learner model fŒ∏ is task-speciÔ¨Åc and trained for a given task. For a given few-shot task, a

stand-alone learner model trained from scratch using gradient descent (Eqn. 4) will not be able to generalize

(Eqn. 3).

2. Meta-Learner: A meta-learner model gœÜ is not task speciÔ¨Åc and is trained on a distribution of tasks T ‚àºp(T )

(Figure 2). Using episodic training, the meta-learner learns (œÜ) to update the learner model‚Äôs parameters (Œ∏)

via training set Dtrain,

Œ∏‚àó= gœÜ(Œ∏, Dtrain).

(14)

The objective of the meta-learner model is to produce updated learner model parameters Œ∏‚àósuch that they are

better than stand-alone learner model parameters Œ∏.

During meta-training (notation A in Table 1), the optimization process involves updating œÜ for the meta-learner and Œ∏

for individual training tasks. Once the meta-training Ô¨Ånishes, the prior knowledge is encompassed into œÜ and only Œ∏ is

updated for a test task (Eqn. 14).

Table 6 compares different optimization-based meta-learning methods based on how they update learner‚Äôs parameters

Œ∏ and meta-learner parameters œÜ. In all the listed methods, learning happens in two-stages. Initially, in the outer-

loop, the meta-learner‚Äôs parameters œÜ are randomly initialized. Next, in the inner-loop the learner parameters (Œ∏)

are updated/proposed by meta-learner (Eqn. 14). The learners‚Äô training loss Ltrain is further used to obtain optimal

parameters Œ∏‚àó. Finally, in the outer loop the cumulative test loss of learner obtained using Œ∏‚àóis used for updating œÜ. In

some cases learner‚Äôs initial parameters Œ∏ are also meta-learned along with œÜ.

In the following paragraphs, we discuss the the recent optimization based meta-learning approaches in more detail.

LSTM Meta-Learner

Normally when given a task T , we try to learn function f(Œ∏) on its training data Dtrain. The parameters Œ∏ of the neural

network f are updated using some form of gradient descent as such:

Œ∏i+1 = Œ∏i ‚àíŒ±‚àáf(Œ∏i).

(15)

Instead of using an hand designed optimizer such as SGD and a Ô¨Åxed learning rate Œ±, Andrychowicz et al. [34] learn an

optimizer function gœÜ such that:

Œ∏i+1 = Œ∏i + gi(‚àáf(Œ∏i); œÜ).

(16)

Similarly, Ravi & Larochelle [35] modeled an LSTM [36] as a meta-learner gœÜ to propose parameters for the learner f:

Œ∏i+1 = gi(‚àáf(Œ∏i), Œ∏i; œÜ).

(17)

Optimizer g is trained to produce parameters Œ∏ in just few steps for the few-shot learning task T . It follows the episodic

training paradigm and mimics the testing scenario. This training procedure is described in Algorithm 2 and depicted in

Figure 9.

14

## Page 15

Parnami & Lee

Method

Learner

Meta-Learner

Repeat ‚àÄb ‚àà[1..B]

Repeat ‚àÄj ‚àà[1..J]

LSTM Meta-Learner [35]

Lb ‚ÜêL(f(Xb; Œ∏b‚àí1), Yb)

Œ∏b ‚Üêg((‚àáŒ∏b‚àí1Lb, Lb); œÜj‚àí1)

Ltest

j

‚ÜêL(f(X; Œ∏B), Y )

œÜj ‚ÜêœÜj‚àí1 ‚àíŒ±‚àáœÜj‚àí1Ltest

j

Repeat ‚àÄi ‚àà[1..I]

Repeat ‚àÄj ‚àà[1..J]

## Maml [14]

Ltrain

i

‚ÜêL(f(Dtrain

i

; Œ∏j‚àí1))

Œ∏‚àó

i ‚ÜêŒ∏j‚àí1 ‚àíŒ±‚àáŒ∏j‚àí1Ltrain

t

Ltest

i

‚ÜêL(f(Dtest

i

; Œ∏‚àó

t ))

Œ∏j ‚ÜêŒ∏j‚àí1 ‚àíŒ≤‚àáŒ∏j‚àí1

## I

## X

i=1

Ltest

i

## Mtl [37]

Ltrain

i

‚ÜêL(f(Dtrain

i

; [Œ∏j‚àí1, œÜj‚àí1, Œò]))

Œ∏‚àó

i ‚ÜêŒ∏j‚àí1 ‚àíŒ±‚àáŒ∏j‚àí1Ltrain

i

Ltest

i

‚ÜêL(f(Dtest

i

; Œ∏‚àó

i ))

Œ∏j ‚ÜêŒ∏j‚àí1 ‚àíŒ≤‚àáŒ∏j‚àí1

## I

## X

i=1

Ltest

i

œÜj ‚ÜêœÜj‚àí1 ‚àíŒ≤‚àáœÜj‚àí1

## I

## X

i=1

Ltest

i

## Leo [38]

œÜj‚àí1 = {œÜe, œÜr, œÜd, Œ±}

zi ‚Üêg(Dtrain

i

; [œÜe, œÜr, Œò])

Œ∏i ‚Üêg(zi; œÜd)

Ltrain

i

‚ÜêL(f(Dtrain

i

; Œ∏i))

z‚àó

i ‚Üêzi ‚àíŒ±‚àáziLtrain

i

Œ∏‚àó

i ‚Üêg(z‚àó

i ; œÜd)

Ltest

i

‚ÜêL(f(Dtest

i

; Œ∏‚àó

i ))

œÜj ‚ÜêœÜj‚àí1 ‚àíŒ≤‚àáœÜj‚àí1

## I

## X

i=1

Ltest

i

Table 6: Optimization-based Meta-Learning Methods

15

## Page 16

Parnami & Lee

Algorithm 2: Train Meta-Learner

Input: Meta-training set Dmeta‚àítrain, Learner f with parameters Œ∏, Meta-Learner g with parameters œÜ

œÜ0 ‚Üêrandom initialization

for j ‚Üê1 to J do

Dtrain, Dtest ‚Üêrandom dataset from Dmeta‚àítrain

Œ∏0 ‚Üêc0

for b ‚Üê1 to B do

Xb, Yb ‚Üêrandom batch from Dtrain

Lb ‚ÜêL(f(Xb; Œ∏b‚àí1), Yb)

‚ñ∑Get loss of learner on train batch

cb ‚Üêg((‚àáŒ∏b‚àí1Lb, Lb); œÜj‚àí1)

‚ñ∑Get output of meta-learner

Œ∏b ‚Üêcb

‚ñ∑Update learner parameters

end

X, Y ‚ÜêDtest

Ltest ‚ÜêL(f(X; Œ∏b), Y)

‚ñ∑Get loss of learner on test batch

Update œÜj using ‚àáœÜj‚àí1Ltest

‚ñ∑Update meta-learner parameters

end

Figure 9: Computational graph for the forward pass of the meta-learner (Figure adapted from [35]).

Model-Agnostic Meta-Learning (MAML)

They key idea in MAML or Model-Agnostic Meta-Learning [14] is to achieve good initialization parameters Œ∏ such

that new tasks can optimize quickly from Œ∏ through one or more gradient descent steps computed with a small amount

of data (Figure 10). These initial parameters Œ∏ are meta-learned over a distribution of tasks p(T ). Unlike LSTM

meta-learner which has two separate models, a meta-learner model gœÜ and a task learner model fŒ∏, MAML has a single

model with parameters Œ∏. Individual tasks use the model parameters Œ∏ as initialization to arrive at optimal parameters

Œ∏‚àófor the task at hand (Algorithm 3).

Proto-MAML [39] extends MAML by combining ideas from Prototypical Networks [21] and MAML [14]. During

training, the former focuses on learning a good embedding function gŒ∏ and does not perform any task adaptation

whereas later approach focuses on learning a good initialization parameters Œ∏ which are then Ô¨Åne-tuned to adapt to

each task. In Proto-MAML, the initial weights of the classiÔ¨Åer are obtained from prototypical networks which are then

subsequently Ô¨Åne-tuned to the individual task.

Task Agnostic Meta-Learning (TAML) [40] argues that the initial model of the meta-learner could be too biased toward

existing tasks to adapt to new tasks, especially in the case of few-shot learning with discrepancy between new tasks from

those in the training tasks. In such case, we wish to avoid an initial model over-performing on some tasks. Therefore,

16

## Page 17

Parnami & Lee

Algorithm 3: MAML

Require: p(T ) : distribution over tasks

Require: Œ±, Œ≤ : step size hyperparameters

Œ∏0 ‚Üêrandom initialization

for j ‚Üê1 to J do

Sample a batch of I tasks randomly from p(T )

for i ‚Üê1 to I do

Dtrain

i

, Dtest

i

‚Üêdataset for task Ti from Dmeta‚àítrain

Ltrain

i

‚ÜêL(f(Dtrain

i

; Œ∏j‚àí1))

‚ñ∑Get loss of learner on training data

Œ∏‚àó

i ‚ÜêŒ∏j‚àí1 ‚àíŒ±‚àáŒ∏j‚àí1Ltrain

i

‚ñ∑Adapt to learner‚Äôs training loss

Ltest

i

‚ÜêL(f(Dtest

i

; Œ∏‚àó

i ))

‚ñ∑Get test loss of learner on adapted parameters

end

Œ∏j ‚ÜêŒ∏j‚àí1 ‚àíŒ≤‚àáŒ∏j‚àí1

## Ip

i=1

Ltest

i

‚ñ∑Update parameters on total test loss of learners

end

Figure 10: Diagram of MAML, which optimizes for a representation Œ∏ that can quickly adapt to new tasks (Figure

adapted from [14]).

TAML aims to meta-train an unbiased initial model by preventing it from over-performing on some tasks or directly

minimizing the inequality of performance across different tasks, in hope to make it more generalizable to unseen tasks.

Antoniou et al. [41] argue that even though MAML is a simple yet elegant meta-learning framework, it suffers from a

variety of problems which can cause 1) instability during training, 2) restricted generalization performance, 3) reduction

in the framework‚Äôs Ô¨Çexibility, 4) increase in the system‚Äôs computational overhead and 5) a costly hyperparameter

tuning before it can work robustly on a new task. Hence they proposed MAML++ [41], an improved meta-learning

framework that offers the Ô¨Çexibility of MAML along with stability, computational efÔ¨Åciency and improved generalization

performance.

Hierarchically Structured Meta-Learning (HSML) [42] attempts to address the challenge of task uncertainty and

heterogeneity in meta-learning, which can not be handled by globally sharing knowledge among tasks or to learn a

single initialization for all kinds of tasks as done in MAML. Therefore, HSML explicitly tailor transferable knowledge

to different clusters of tasks by learning task representations where each cluster of tasks has its own initial parameters

(Figure 11).

Fast Context Adaptation Via Meta-Learning (CAVIA) [43] is a simple extension to MAML that is more interpretable

and less prone to overÔ¨Åtting. CAVIA partitions the model parameters Œ∏ into two parts: context parameters Œ∏context

that serve as additional input to the model and are adapted on individual tasks, and shared parameters Œ∏shared that are

meta-trained and shared across the tasks. At test time, only context parameters are updated, leading to a low dimensional

task representation.

17

## Page 18

Parnami & Lee

Figure 11: MAML vs HSML (Figure adapted from [42])

Meta-Transfer Learning (MTL)

In MAML [14], the meta-learned model parameters Œ∏ are adapted as Œ∏‚àóto an individual task. The effectiveness of this

strategy is limited to shallow networks, as the adaptation in deep networks can lead to overÔ¨Åtting. Therefore, Sun et al.

[37] propose a technique called Meta-Transfer Learning (MTL) (Figure 12). The key idea is to use a pretrained DNN as

a feature extractor (Œò) and meta-learn only the last layer classiÔ¨Åer parameters Œ∏. In addition, MTL also meta-learns

scale (œÜS1) and shift (œÜS2) parameters to adapt the Œò to individual tasks. The scale and shift parameters are few in

number when compared to Œò.

Figure 12: Difference between learning strategies. Meta-Task Learning (MTL) adopts transfer learning strategy for

Meta-Learning. A pre-trained model‚Äôs weights are shift and scaled on task basis. The shift and scale (SS) parameters

are learned through meta-learning across tasks (Source: [22]).

18

## Page 19

Parnami & Lee

Latent Embedding Optimization

Latent Embedding Optimization(LEO) [38] learns a low-dimensional latent embedding of model parameters and

performs optimization-based meta-learning in this space. Learning low-dimensional latent representation is motivated

by the fact that it is difÔ¨Åcult to optimize in high-dimensional spaces in extreme low-data regimes. The following steps

explain the optimization process of LEO:

1. Pretraining: Like MTL, input feature embeddings are not learned, but are pretrained on a deep network

(WRN [28]). Using the meta-training dataset, a ResNet classiÔ¨Åer is trained to distinguish between training

classes. Features from an intermediate layer of this trained classiÔ¨Åer is used for getting input embeddings.

2. Inner Loop Training: Each task‚Äôs dataset Dtrain is used to obtain the initial parameters Œ∏ of the classiÔ¨Åer f.

‚Ä¢ The pre-trained embeddings for examples Dtrain are fed into a Encoder-Relation network which outputs

latent representation z for each class (like a prototype).

‚Ä¢ The low dimensional latent representation generates task classiÔ¨Åer parameters Œ∏ through a decoder.

‚Ä¢ The training loss Ltrain of fŒ∏ is used to update the latent representations z.

3. Outer Loop Training: The loss Ltest calculated on each task‚Äôs test examples Dtest with fŒ∏ is used to update

the parameters of encoder, relation network and decoder.

Intuitively, this provides two advantages. First, the initial parameters for a new task are conditioned on the training data,

which enables a task-speciÔ¨Åc starting point for adaptation. Second, by optimizing in the lower-dimensional latent space,

the approach can adapt the behavior of the model more effectively (Figure 13).

Figure 13: Overview of the architecture of LEO (Source: [38])

19

## Page 20

Parnami & Lee

3.2.1.3

Model-based Meta-Learning

Metric-based methods for FSL learn a function gŒ∏ to generate discriminative embeddings based on a metric where as

optimization-based methods learn a priors œÜ, Œ∏ to optimize quickly from. Different from these approaches, model-based

meta-learning methods makes no assumption on the form of PŒ∏(y|x). Rather it involves model architectures speciÔ¨Åcally

tailored for fast learning. Table 7 summarizes the methods in this category. Based on the kind of model architecture

(fŒ∏), these methods are further categorized into memory-based, rapid-adaptation-based and miscellaneous models.

Method

Type

Key Idea

## Mann [44]

Memory

Using NTM [45] for sequence prediction

MM-Net [46]

Memory

Key-Value Memory Networks [47] combined with Matching Networks [13]

MetaNets [48]

Rapid Adaptation

Fast-Weights stored in memory

## Csn [49]

Rapid Adaptation

Task speciÔ¨Åc conditioning of activation values stored in memory

## Snail [50]

Miscellaneous

Temporal Convolutions and Causal Attention layers for sequence prediction

Table 7: Model-based Meta-Learning Methods

3.2.1.3.1

Memory as a component

A family of model architectures integrates an external memory component to facilitate their learning process. This

external memory component is usually a 2D matrix called the memory bank, memory matrix or just plain memory.

The memory acts as a storage buffer to which neural networks can write new information and retrieve previously

stored information. Note that this memory component is different than internal memory found in vanilla RNNs or

LSTMs. Neural Turing Machines (NTM) [45] and Memory Networks [51], [52, 47] are the examples of two such

model architectures which incorporates external memory in their learning process. In the context of FSL, memory as an

external component can relieve the burden of training in low data regime and can allow for faster generalization. Next,

we discuss such model architectures which integrates memory into their design and use meta-learning for learning from

few-examples.

Memory Augmented Neural Networks

Memory Augmented Neural Networks (MANN) [44] use a modiÔ¨Åed NTM to rapidly assimilate new data into memory

and leverage this data to make accurate predictions after only a few samples.

‚Ä¢ Neural Turing Machine

A Neural Turing Machine (NTM) couples a controller neural network with external memory storage (Figure

14). Like most neural networks, the controller interacts with the external world via input and output vectors.

Unlike standard networks, the controller also learns to read and write memory rows by soft attention, while the

memory serves as a knowledge repository. The attention weights are generated by its addressing mechanism.

Figure 14: The architecture of NTM. The memory at time t, Mt is a matrix of size N √ó M, containing N vector rows

and each has M dimensions (Source: [6]).

‚Ä¢ Addressing Mechanism in MANN

The controllers in MANN are either LSTMS or feed-forward networks. Given some input xt at time t, the

20

## Page 21

Parnami & Lee

controller produces a key feature vector kt, which is then either stored in a row of a memory matrix Mt, or

used to retrieve a particular memory, i, from a row; i.e. Mt(i). A memory, rt, is retrieved using the weighting

vector wr

t (i) as:

rt ‚Üê

## X

i

wr

t (i)Mt(i) where wr

t (i) = softmax(

kt ¬∑ Mt(i)

||kt|| ¬∑ ||Mt(i)||).

Writing to memory in MANN model involves the use of Least Recently Used Access (LRUA) module. The

LRUA module is a pure content-based memory writer that writes memories to either the least used memory

location or the most recently used memory location.

‚Ä¢ Meta-Learning Setup for MANN

Memory encoding and retrieval in a NTM external memory is rapid, with vector representations being replaced

into or taken out of memory potentially every time-step. This ability makes the NTM a perfect candidate for

meta-learning and low-shot prediction, as it is capable of both long-term storage via slow update of weights,

and short term storage via its external memory module. Training in MANN follows the same episodic paradigm

discussed earlier, except the truth label yt is presented with one step offset i.e {(xt, yt‚àí1), (xt+1, yt), ...}.

The network is tasked to output the appropriate label for xt(i.e., yt) at the given timestep. This prevents the

network from slowly learning sample-class bindings in its weights. Instead, it must learn to hold data samples

in memory until the appropriate labels are presented at the next time-step, after which sample-class information

can be bound and stored for later use (Figure 15).

Figure 15: Task Structure. (a) Images xt are presented with time-offset labels, (b) External memory stored the bounded

sample representation-class label information (Source: [44]).

Memory Matching Networks

Memory Matching Networks (MM-Net) [46] integrates the memory module from Key-Value Memory Networks [47]

into Matching Networks [13]. It extends the idea of metric-based meta-learning with a memory module to encode

and generalize the whole support set into memory slots. Given the support set S, the memory module encodes the

sequence of N support images into M memory slots with the write controller. For each support image x and its

embedded representation z in memory key space, the read controller measures the dot product similarity between the

input support image and the memory slots to retrieve a conditioned representation g(x|M). Meanwhile, a contextual

learner is devised to predict the parameters of CNNs for embedding unlabeled image in the query set.

3.2.1.3.2

Rapid Adaptation

The following model-based approaches uses techniques like "fast-weights" to rapidly adapt the parameters of a model

for a given task. Normally weights in the neural networks are updated by stochastic gradient descent in an objective

function and this process is known to be slow. One faster way to learn is to utilize one neural network to predict the

parameters of another neural network and the generated weights are called fast weights. In comparison, the ordinary

SGD-based weights are named slow weights.

Meta Networks

Meta Networks (MetaNet) [48] is a meta-learning model with architecture and training process designed for rapid

generalization across tasks. It consists of two main learning components, a base learner and a meta-learner, and is

equipped with an external memory. The rapid generalization of MetaNet relies on fast-weights. The external memory is

used to store these fast weights and the input representations.

21

## Page 22

Parnami & Lee

Figure 16: Architecture of Memory Matching Networks (Source: [46])

In MetaNet, loss gradients are used as meta information to populate models that learn fast weights. Slow and fast

weights are combined to make predictions in neural networks.

Figure 17: Combining slow and fast weights in a MLP. L is element-wise sum (Source: [48]).

Conditionally Shifted Neurons

Conditionally Shifted Neurons (CSNs) [49] modify their activation values with task-speciÔ¨Åc shifts retrieved from a

memory module, which is populated rapidly based on a limited task experience. Building upon Meta-Networks, CSNs

also have a base learner, a meta-learner and a memory module. The learning happens in the following manner:

‚Ä¢ A base learner works on individual tasks. Using its current weights it makes predictions on the examples in

the support set (description phase).

‚Ä¢ The loss incurred from each prediction from support set is stored in the form of conditioning information

I in the key-value memory where keys are the embeddings of inputs and the values are the conditioning

information.

‚Ä¢ To classify a query (prediction phase), its embeddings are compared with the embeddings of the keys in the

memory using cosine similarity and the similarity score is then weighted using a softmax. The conditioning

information for each key is weighted by its similarity score and summed together to obtain joint conditioning

information.

22

## Page 23

Parnami & Lee

‚Ä¢ The base network is updated with this joint conditioning information and the prediction for the query is made

with these updated weights.

‚Ä¢ The loss obtained on the query is then used to update the key embeddings network f, the value network g and

the prediction network (the initial base network).

Figure 18: Rapid Adaptation with Conditionally Shifted Neurons. In the description phase, the meta learner populates

working memory with keys and values, based on the base learner‚Äôs performance on the task description; in the prediction

phase, the meta learner retrieves task-speciÔ¨Åc shifts from memory through key-based attention and feeds them to the

base learner to adapt it to the task (Source: [49]).

3.2.1.3.3

Miscellaneous Models: SNAIL

Each episode in SNAIL [50] receives as input a sequence of example-label pairs (x1, y1), ..., (xt‚àí1, yt‚àí1) for timesteps

1, ..., t ‚àí1, followed by an unlabeled example (xt, _) (Figure 19). It is then tasked to output prediction for xt based on

the previous labeled examples it has seen. Formalizing meta-learning as a sequence-to-sequence problem, it argues

that meta-learner should be able to internalize and refer to past experience. It proposes use of embedding networks

with interleaved temporal convolutions and causal attention layers; the former to aggregate information from past

experience and the latter to pinpoint speciÔ¨Åc pieces of information. The temporal convolution layers in SNAIL provides

high-bandwidth access over its past experience without constraints on the amount of experience it can effectively

use. SNAIL architectures are easier to train than traditional RNNs such as LSTM or GRUs and can be efÔ¨Åciently

implemented so that an entire sequence can be processed in a single forward pass.

Figure 19: Overview of SNAIL; in this example, two blocks of temporal convolution layers (orange) are interleaved

with two causal attention layers (green) (Source: [50]).

23

## Page 24

Parnami & Lee

3.2.2

Hybrid Approaches

This section discusses the variations of the few-shot learning problem and the hybrid meta-learning based approach

towards them. Table 8 list the hybrid approaches and summarizes the key idea behind them.

Approach

Key Idea

Cross-Modal FSL

Leverage semantic data from a different modality.

Semi-Supervised FSL

Using few training examples, label the given unlabeled examples and

improve the few-shot classiÔ¨Åer.

Generalized FSL

Classify query into either one of the meta-training classes or a class

from the support set.

Generative FSL

Learning to generate more samples from the given few.

Cross Domain FSL

Training in one domain and testing in another.

Transductive FSL

Jointly predict all the query examples.

Unsupervised FSL

Support examples are unlabeled.

Zero-Shot Learning

No support examples present.

Table 8: Hybrid Approaches

Cross-Modal Few-Shot Learning

The recent progress in few-shot image classiÔ¨Åcation has primarily been made in the context of unimodal learning. In

order to alleviate the problem of limited data in image domain, some approaches [53, 54] employ data from different

modality (eg., text). This is referred to as Cross-Modal Few-Shot Learning. For example, Xing et al. [54] propose

an Adaptive Modality Mixture Mechanism (AM3) that combines information from an image and its label‚Äôs word

embedding to develop a better prototype of its class.

Semi-Supervised Few-Shot Learning

Semi-Supervised FSL considers the scenario when there is limited labeled data but sufÔ¨Åcient unlabeled data is available

during the training. For example in approaches which use meta-learning for few-shot classiÔ¨Åcation, a weakly supervised

classiÔ¨Åer trained on support set (labeled) learns to label unlabeled data and then use it to improve its performance on the

classiÔ¨Åcation task. Using metric-based meta-learning approach, Ren et al. [17] propose three semi-supervised variants

of Prototypical Networks [21], basically using Soft k-Means method to tune clustering centers with unlabeled data.

Alternatively, Sun et al. [55] use an optimization-based meta-learning approach for learning to initialize a classiÔ¨Åcation

model for semi-supervised FSL.

Generalized Few-Shot Learning

In general, FSL approaches involve meta-training on base (seen) classes and meta-testing on novel (unseen) classes.

Given a novel task sampled from the meta-testing set, the few-shot classiÔ¨Åer will classify a query into one of the classes

present in the novel task‚Äôs support set (task‚Äôs training set) and will not be able to recognize if the query example is from

a base class. Generalized Few-Shot Learning (GFSL) focuses on the joint classiÔ¨Åcation of both the base classes and

novel classes. In particular, the goal is, for the model trained on the seen categories to be capable of incorporating the

limited unseen class instances and make predictions for test/query instances in the both set of classes. Recent work of

Gidaris & Komodakis [56], Ye et al. [57] and Ren et al. [58] attempts to address this problem.

Generative Few-Shot Learning

One usual way one may think to alleviate the problem of learning from low data samples is to augment them with

synthesized samples. To this end, Wang et al. [59] propose a meta-learning approach for generating samples from

limited data. This generative model is referred to as hallucinator, a model that maps real examples to hallucinated

examples. The few-shot training set is Ô¨Årst fed to the hallucinator, and it produces an expanded training set, which is

then used by the learner. We refer to approaches of this kind as Generative Few-Shot Learning.

Cross Domain Few-Shot Learning

The FSL approaches discussed so far in the context of few-shot classiÔ¨Åcation aimed to recognize novel categories with

only few labeled examples in each class. One assumption that was followed was that all few-shot tasks belong to the

same distribution or domain. For example, most approaches sampled tasks from miniImageNet during training and

as well as testing. While promising results were observed following this assumption, the existing methods often fail

to generalize to unseen domains due to large discrepancy of the feature distribution across domains. This problem of

few-shot learning under domain shifts is referred to as Cross Domain FSL. To this end, the early works of Tseng et al.

[60] attempt to address this problem by simulating various feature distributions under different domains in the training

stage.

24

## Page 25

Parnami & Lee

Transductive Few-Shot Learning

Although, meta-learning is an effective strategy for few-shot learning as it aims at generalizing to unseen classiÔ¨Åcation

tasks, the fundamental difÔ¨Åculty with learning with scarce data remains for a novel classiÔ¨Åcation task. One way to

achieve larger improvements with limited amount of training data is to consider relationships between instances in the

test set and thus predicting them as whole, which is referred to as transduction or transductive inference [61]. Therefore,

transductive few-shot learning techniques [32, 62, 63] utilize the information present in unlabeled examples in the

query set as whole to make prediction about individual queries. For example Liu et al. [62] proposed Transductive

Propagation Networks, where the examples in the support and query sets are modeled as nodes of a graph. The labels of

the support set nodes are known and the task is to predict the labels of the query set nodes which is achieved using their

label propagation algorithm.

Unsupervised Few-Shot Learning

In supervised few-shot learning, the labels of the examples in the support set are available during the training and the

label of the examples in the query set have to be estimated. In contrast, in unsupervised few-shot learning, the examples

in the support set are also unlabeled. Huang et al. [64] proposed a strategy for unsupervised few-shot classiÔ¨Åcation task

which involves Ô¨Årst performing clustering on the examples in the support set and then assigning the query to one of the

clusters.

Zero-Shot Learning

Zero-Shot Learning (ZSL) [65] attempts to solve a task without the presence of any training examples for that task.

For an image classiÔ¨Åcation task, ZSL methods rely mostly on visual-auxiliary modality alignment. Often times, the

auxiliary data is image‚Äôs label i.e., samples for the same class from two modalities are mapped together so that two

modalities obtain the same semantic structure. Because ZSL does not have access to any visual information when

learning new concepts, ZSL models have no choice but to align the two modalities. This way, during test the image

query can be directly compared to auxiliary information for performing classiÔ¨Åcation [66].

3.3

Non-Meta-Learning based Few-Shot Learning

In this section, we discuss strategies other than meta-learning that can aid learning in limited data regime.

3.3.1

Transfer Learning

Transfer Learning [67] is the improvement of learning in a new task through the transfer of knowledge from a related

task that has already been learned. In few-shot learning scenario where the data is too limited to train a deep network

from scratch, transferring knowledge from another network can be a viable option. For a classiÔ¨Åcation task, this

knowledge transfer is achieved by pretraining a deep network on large amounts of training data on base classes (seen)

and then Ô¨Åne-tuning it on a new few-shot classes (unseen). However, naive Ô¨Åne-tuning using just few example can lead

to overÔ¨Åtting and thus poor generalization performance on the few-shot task. Therefore, in this section, we discuss

approaches which attempts to address this problem.

Distance Metric ClassiÔ¨Åcation Using Embeddings from a Pretrained Network

In section 3.2.1.1, we discussed approaches that used meta-learning to extract feature embeddings and perform

classiÔ¨Åcation using a nearest neighbour classiÔ¨Åer with a distance metric. SimpleShot [68] instead uses a pretrained

deep network to get feature embeddings for the input and query images, perform centering & L2 normalization on the

obtained features and use euclidean distance as the distance measure for nearest neighbour classiÔ¨Åcation. This simple

approach has shown considerable improvement in accuracy in comparison to meta-learning approaches. Similarly chen

et al. [69], shows comparable results from using cosine metric for nearest neighbour classiÔ¨Åcation on embeddings

obtained from a network trained on base classes.

Training a New ClassiÔ¨Åer Using Embeddings from a Pretrained Network

Training a classiÔ¨Åer from scratch isn‚Äôt possible when the number of training samples are limited, due to the poor

resulting representations. However one could still obtain the representations from a pre-trained network and then train a

new classiÔ¨Åer using them. Tian et al. [70], demonstrate this exactly. Along with using representations from a pre-trained

network, they also L2 normalize them before training a new classiÔ¨Åer for each few-shot task. They also show that this

approach outperforms the simple nearest neighbour classiÔ¨Åcation using pretrained embeddings.

Transductive Inference Using Embeddings from a Pretrained Network

Certain approaches attempt to exploit the structure of information present in the query set and collectively classify

the examples in the query set. This is know as transductive inference. For example, in section 3.2.2, we mentioned

Transductive Propagation Networks [62] which utilized meta-learning to transductively assign labels to the examples

in the query set. Alternatively, instead of using meta-learning, Dhillon et al. [71] choose to transductively Ô¨Åne-tune a

25

## Page 26

Parnami & Lee

pretrained network on a given few-shot task. That means along with the support examples (labeled), query samples are

also utilized in the Ô¨Åne-tuning process. The proposed transductive Ô¨Åne-tuning phase solves for:

Œ∏‚àó= arg min

Œ∏

1

## |S|

## X

(x,y)‚ààS

‚àílog pŒ∏(y|x) + 1

## |Q|

## X

(x,y)‚ààQ

H(pŒ∏(.|x)).

(18)

The Ô¨Årst term in the equation is the data Ô¨Åtting term using labeled support samples whereas the second term, the

regularizer, uses the unlabeled query samples to minimize the entropy of predictions.

Similarly, Ziko et al. [72], propose a transductive laplacian-regularized inference for few-shot tasks. Using the feature

embeddings learned from the base classes (pretrained), they minimize a quadratic binary-assignment function containing

two terms:

E(Y) = N(Y) + Œª

## 2 L(Y),

(19)

where

## N(Y) =

## N

## X

q=1

## C

## X

c=1

yq,cd(xq ‚àímc)

and

## L(Y) = 1

2

## X

q,p

w(xq, xp)||yq ‚àíyp||2

‚Ä¢ N(Y), a unary term, is minimized globally when each query point is assigned to the class of the nearest

prototype mc (obtained from the support set) using a distance metric d(xq, mc).

‚Ä¢ L(Y), a pairwise Laplacian term, encourages nearby points (xp, xq) in the label space to the same latent label

assignment (w is any similarity metric).

These transfer learning based methods have often come to exhibit better or equivalent performance on FSL tasks when

compared to the complex meta-learning methods discussed earlier.

3.3.2

Miscellaneous: Autoencoders

Mocanu [73] proposes a one-shot learning method, dubbed MoVAE (Mixture of Variational Autoencoders), to perform

classiÔ¨Åcation. A Variational Autoencoder (VAE) [74] provides a probabilistic manner for describing an observation in

latent space. Thus, rather than building an encoder which outputs a single value to describe each latent state attribute, a

VAE encoder to describe a probability distribution for each latent attribute. Given C classes, C VAEs are trained, one

for each class. Then the reconstruction loss from the VAEs are measured to perform classiÔ¨Åcation on the unlabeled data

sample. A downside of this approach is that requires constructing and training new Autoencoders for each new task

even at test. In contrast, most meta-learning methods work out-of-the-box at test time.

26

## Page 27

Parnami & Lee

4

Progress in Few-Shot Learning

Early few-shot research focused on computer vision applications and mainly image classiÔ¨Åcation [13, 21, 16, 14].

This is because visual information is easy to acquire and has been extensively examined in machine learning. Other

computer vision problems such as Object Detection [75, 76, 77, 78] and Segmentation [79] have also received recent

attention from the few-shot learning community. Apart from computer vision applications, FSL has been used for fault

diagnosis [80], text classiÔ¨Åcation [81, 82], image colorization [83] and cold-start item recommendation [84, 85]. In

graph modeling, FSL has been used for node classiÔ¨Åcation [86], edge labelling [87] and relation classiÔ¨Åcation [88]. In

audio, its used for few-shot speaker recognition [89, 90] and sound recognition [91]. Finally, imitation learning [92] in

robotics and control [14] in reinforcement learning [93].

Since its emergence in 2016, the Ô¨Åeld of few-shot learning has shown promising improvement in learning from limited

data. Figure 20 shows the trend of improvement in accuracy for 5-way 1-shot classiÔ¨Åcation task on miniImageNet

[13]. Beginning with Matching Networks [13] at 43% accuracy, various optimization, metric, model-based and hybrid

approaches were proposed in past four years, pushing the accuracy to 80% (as of Jan 2020). Although model-based

approaches have seen less progress, there is no clear consensus if any one particular approach is the best way forward.

Table 9 lists the accuracy of methods discussed in this survey (sorted by 1-shot accuracy and color coded by type).

Metric-based, Optimization-based, Hybrid Meta-Learning and even Non-Meta-Learning approaches, all seem to be

leading the race.

Figure 20: Progress in FSL3

5

Challenges and Open Problems

Recent years witnessed a great deal of interest from the machine learning community in solving the problem of learning

from few examples. Consequently, many approaches were proposed, and each of them involved some kind of knowledge

transfer, either though meta-learning or transfer learning. The success of these approaches relied on certain assumptions,

which might become challenging to uphold in real-world settings. Therefore, in this section we discuss the challenges

involved in the nitty-gritty of FSL approaches.

Training the Same Way as Testing

Most meta-learning methods employ M-way K-shot episodic training paradigm

(Algorithm 1), i.e, we train the few-shot learning model to distinguish between M classes each with exactly K training

examples. This makes the trained few-shot classiÔ¨Åer very rigid to be deployed in real world scenarios as one cannot

expect to know beforehand the number of classes (M) and the number of training examples (K) available for an unseen

task. Moreover, the model will suffer performance degradation if the number of examples present are less than K [94].

3https://paperswithcode.com/sota/few-shot-image-classiÔ¨Åcation-on-mini-2

27

## Page 28

Parnami & Lee

Model

1-shot

5-shot

Type

Matching Networks [13]

43.56

55.31

Metric

## Maml [14]

48.7

63.15

Optimization

ProtoNet [21]

49.42

68.2

Metric

Relation Net [22]

50.44

65.32

Metric

ProtoNet + Margin [29]

51.62

70.24

Metric

## Cavia [43]

51.82

65.85

Optimization

## Snail [50]

55.71

68.88

Model

## Tpn [62]

55.51

69.86

Hybrid

Dynamic FSL [56]

56.2

73

Hybrid

## Csn [49]

56.88

71.94

Model

## Saml [33]

57.69

73.03

Metric

## Tadam [16]

58.5

76.7

Metric

## Mtl [37]

61.2

75.5

Optimization

TapNet [23]

61.65

76.36

Metric

## Leo [38]

61.76

77.59

Optimization

## Ctm [24]

62.05

78.63

Metric

## Sca [63]

62.86

77.64

Optimization

## Can [32]

63.85

79.44

Metric

SimpleShot [68]

64.29

81.5

Non-Meta-Learning

## Am3 [54]

65.3

78.1

Hybrid

## Lst [55]

70.1

78.7

Hybrid

Table 9: Accuracy of 5-way classiÔ¨Åcation task on miniImageNet

Learning Constrained to a Single Distribution of Tasks

In few-shot learning experiments, training and testing tasks are sampled from the same distribution p(T ), which

constraints the learning to a single domain. For example, a FSL model trained for character classiÔ¨Åcation tasks on

Omniglot [15] may not work well with digit classiÔ¨Åcation on MNIST [95]. Similarly a general few-shot image classiÔ¨Åer

built on miniImagenNet [13] may not work well for Ô¨Åne-grained classiÔ¨Åcation of Birds [96] or Cars [97]. This problem

is also referred to as Cross Domain FSL.

Performing Joint ClassiÔ¨Åcation from Seen and Unseen Classes

The classes used in the training phase are not retained by the few-shot classiÔ¨Åer, i.e. once the training Ô¨Ånishes, the model

can only classify the incoming query into one of the classes present in the support set of the given task. In real-world

usage, it would be desirable to jointly classify the incoming query from training classes (seen) and the new classes

(unseen) present in the support set of the task. This challenge is also referred to as Generalized Few-Shot Learning.

Few-Shot Learning in Data Domains Other than Images

Availability of large amount of image datasets have resulted in considerable progress in few-shot image classiÔ¨Åcation.

Besides the availability, image datasets can be constructed to have uniformly sized images easily categorized into

different classes. Contrary to images, data domains like audio and wireless signals have limited large-scale datasets

that are uniformly curated. Since uniformity of a dataset is essential to meta-learning, it is a challenge to deploy FSL

methods from images to domains like signals.

References

[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In

Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770‚Äì778, 2016.

[2] Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V. Le, Mohammad Norouzi, Wolfgang Macherey, Maxim

Krikun, Yuan Cao, Qin Gao, Klaus Macherey, Jeff Klingner, Apurva Shah, Melvin Johnson, Xiaobing Liu, Lukasz

Kaiser, Stephan Gouws, Yoshikiyo Kato, Taku Kudo, Hideto Kazawa, Keith Stevens, George Kurian, Nishant

Patil, Wei Wang, Cliff Young, Jason Smith, Jason Riesa, Alex Rudnick, Oriol Vinyals, Greg Corrado, Macduff

Hughes, and Jeffrey Dean. Google‚Äôs neural machine translation system: Bridging the gap between human and

machine translation. CoRR, abs/1609.08144, 2016.

[3] Aaron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals, Alex Graves, Nal Kalch-

brenner, Andrew Senior, and Koray Kavukcuoglu. Wavenet: A generative model for raw audio. arXiv preprint

arXiv:1609.03499, 2016.

28

## Page 29

Parnami & Lee

[4] Yaqing Wang, Quanming Yao, James T. Kwok, and Lionel M. Ni. Generalizing from a few examples: A survey

on few-shot learning. 2019.

[5] Wei-Yu Chen, Yen-Cheng Liu, Zsolt Kira, Yu-Chiang Frank Wang, and Jia-Bin Huang. A closer look at few-shot

classiÔ¨Åcation. ArXiv, abs/1904.04232, 2019.

[6] Lilian Weng. Meta-learning: Learning to learn fast. 2018.

[7] Jurgen Schmidhuber. Evolutionary principles in self-referential learning. on learning now to learn: The meta-

meta-meta...-hook. Diploma thesis, Technische Universitat Munchen, Germany, 14 May 1987.

[8] T. Schaul and J. Schmidhuber. Metalearning. Scholarpedia, 5(6):4650, 2010. revision #91489.

[9] Sebastian Thrun and Lorien Pratt, editors. Learning to Learn. Kluwer Academic Publishers, USA, 1998.

[10] Sinno Jialin Pan and Qiang Yang. A survey on transfer learning. IEEE Transactions on knowledge and data

engineering, 22(10):1345‚Äì1359, 2009.

[11] Rich Caruana. Multitask Learning, pages 95‚Äì133. Springer US, Boston, MA, 1998.

[12] R. Polikar. Ensemble learning. Scholarpedia, 4(1):2776, 2009. revision #186077.

[13] Oriol Vinyals, Charles Blundell, Timothy P. Lillicrap, Koray Kavukcuoglu, and Daan Wierstra. Matching networks

for one shot learning. CoRR, abs/1606.04080, 2016.

[14] Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation of deep

networks. CoRR, abs/1703.03400, 2017.

[15] Brenden M. Lake, Ruslan Salakhutdinov, and Joshua B. Tenenbaum. Human-level concept learning through

probabilistic program induction. Science, 350(6266):1332‚Äì1338, 2015.

[16] Boris N. Oreshkin, Pau Rodr√≠guez L√≥pez, and Alexandre Lacoste. Tadam: Task dependent adaptive metric for

improved few-shot learning. In NeurIPS, 2018.

[17] Mengye Ren, Eleni TriantaÔ¨Ållou, Sachin Ravi, Jake Snell, Kevin Swersky, Joshua B. Tenenbaum, Hugo Larochelle,

and Richard S. Zemel. Meta-learning for semi-supervised few-shot classiÔ¨Åcation. ArXiv, abs/1803.00676, 2018.

[18] Oriol Vinyals. Model vs optimization meta learning. Meta-Learning Symposium at NIPS, 2017.

[19] Brian Kulis. Metric learning: A survey. Foundations and Trends¬Æ in Machine Learning, 5(4):287‚Äì364, 2013.

[20] Gregory R. Koch. Siamese neural networks for one-shot image recognition. 2015.

[21] Jake Snell, Kevin Swersky, and Richard S. Zemel. Prototypical networks for few-shot learning. In NIPS, 2017.

[22] Flood Sung, Yongxin Yang, Li Zhang, Tao Xiang, Philip H. S. Torr, and Timothy M. Hospedales. Learning to

compare: Relation network for few-shot learning. 2018 IEEE/CVF Conference on Computer Vision and Pattern

Recognition, pages 1199‚Äì1208, 2018.

[23] Sung Whan Yoon, Jun Seo, and Jaekyun Moon. Tapnet: Neural network augmented with task-adaptive projection

for few-shot learning. In ICML, 2019.

[24] Hongyang Li, David Eigen, Samuel F. Dodge, Matthew D. Zeiler, and Xiaogang Wang. Finding task-relevant

features for few-shot learning by category traversal. 2019 IEEE/CVF Conference on Computer Vision and Pattern

Recognition (CVPR), pages 1‚Äì10, 2019.

[25] Jane Bromley, James W. Bentz, L√©on Bottou, Isabelle Guyon, Yann LeCun, Cliff Moore, Eduard S√§ckinger, and

Roopak Shah. Signature veriÔ¨Åcation using a "siamese" time delay neural network. In IJPRAI, 1993.

[26] Yann Lecun, L√©on Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to document

recognition. In Proceedings of the IEEE, pages 2278‚Äì2324, 1998.

[27] Akshay Mehrotra and Ambedkar Dukkipati. Skip residual pairwise networks with learnable comparative functions

for few-shot learning. In IEEE Winter Conference on Applications of Computer Vision, WACV 2019, Waikoloa

Village, HI, USA, January 7-11, 2019, pages 886‚Äì894. IEEE, 2019.

[28] Sergey Zagoruyko and Nikos Komodakis. Wide residual networks. In Edwin R. Hancock Richard C. Wilson and

William A. P. Smith, editors, Proceedings of the British Machine Vision Conference (BMVC), pages 87.1‚Äì87.12.

BMVA Press, September 2016.

[29] Xianchao Zhang, Jinlong Nie, Linlin Zong, Hong Yu, and Wenxin Liang. One shot learning with margin. In

## Pakdd, 2019.

[30] Geoffrey E. Hinton, Oriol Vinyals, and Jeffrey Dean. Distilling the knowledge in a neural network. ArXiv,

abs/1503.02531, 2015.

29

## Page 30

Parnami & Lee

[31] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and

Illia Polosukhin. Attention is all you need. In NIPS, 2017.

[32] Ruibing Hou, Hong Chang, Bingpeng Ma, Shiguang Shan, and Xilin Chen. Cross attention network for few-shot

classiÔ¨Åcation. In NeurIPS, 2019.

[33] Fusheng Hao, Fengxiang He, Jun Cheng, Lei Wang, Jian zhong Cao, and Dacheng Tao. Collect and select:

Semantic alignment metric learning for few-shot learning. 2019 IEEE/CVF International Conference on Computer

Vision (ICCV), pages 8459‚Äì8468, 2019.

[34] Marcin Andrychowicz, Misha Denil, Sergio Gomez Colmenarejo, Matthew W. Hoffman, David Pfau, Tom Schaul,

and Nando de Freitas. Learning to learn by gradient descent by gradient descent. In NIPS, 2016.

[35] Sachin Ravi and Hugo Larochelle. Optimization as a model for few-shot learning. In ICLR, 2017.

[36] Sepp Hochreiter and J√ºrgen Schmidhuber. Long short-term memory. Neural Computation, 9:1735‚Äì1780, 1997.

[37] Qianru Sun, Yaoyao Liu, Tat-Seng Chua, and Bernt Schiele. Meta-transfer learning for few-shot learning. 2019

IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 403‚Äì412, 2018.

[38] Andrei A. Rusu, Dushyant Rao, Jakub Sygnowski, Oriol Vinyals, Razvan Pascanu, Simon Osindero, and Raia

Hadsell. Meta-learning with latent embedding optimization. ArXiv, abs/1807.05960, 2018.

[39] Eleni TriantaÔ¨Ållou, Tyler Zhu, Vincent Dumoulin, Pascal Lamblin, Kelvin Xu, Ross Goroshin, Carles Gelada,

Kevin Swersky, Pierre-Antoine Manzagol, and Hugo Larochelle. Meta-dataset: A dataset of datasets for learning

to learn from few examples. ArXiv, abs/1903.03096, 2020.

[40] Muhammad Abdullah Jamal, Guo-Jun Qi, and Mubarak Shah. Task agnostic meta-learning for few-shot learning.

2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 11711‚Äì11719, 2018.

[41] Antreas Antoniou, Harrison A Edwards, and Amos J. Storkey. How to train your maml. ArXiv, abs/1810.09502,

2018.

[42] Huaxiu Yao, Ying Wei, Junzhou Huang, and Zhenhui Li. Hierarchically structured meta-learning. In ICML, 2019.

[43] Luisa M. Zintgraf, Kyriacos Shiarlis, Vitaly Kurin, Katja Hofmann, and Shimon Whiteson. Fast context adaptation

via meta-learning. In ICML, 2019.

[44] Adam Santoro, Sergey Bartunov, Matthew M Botvinick, Daan Wierstra, and Timothy P. Lillicrap. One-shot

learning with memory-augmented neural networks. ArXiv, abs/1605.06065, 2016.

[45] Alex Graves, Greg Wayne, and Ivo Danihelka. Neural turing machines. ArXiv, abs/1410.5401, 2014.

[46] Qi Cai, Yingwei Pan, Ting Yao, Chenggang Clarence Yan, and Tao Mei. Memory matching networks for one-shot

image recognition. 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 4080‚Äì4088,

2018.

[47] Alexander H. Miller, Adam Fisch, Jesse Dodge, Amir-Hossein Karimi, Antoine Bordes, and Jason Weston.

Key-value memory networks for directly reading documents. ArXiv, abs/1606.03126, 2016.

[48] Tsendsuren Munkhdalai and Hong Yu. Meta networks. Proceedings of machine learning research, 70:2554‚Äì2563,

2017.

[49] Tsendsuren Munkhdalai, Xingdi Yuan, Soroush Mehri, and Adam Trischler. Rapid adaptation with conditionally

shifted neurons. In ICML, 2017.

[50] Nikhil Mishra, Mostafa Rohaninejad, Xi Chen, and Pieter Abbeel. A simple neural attentive meta-learner. In

## Iclr, 2017.

[51] Jason Weston, Sumit Chopra, and Antoine Bordes. Memory networks. CoRR, abs/1410.3916, 2015.

[52] Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, and Rob Fergus. End-to-end memory networks. In NIPS,

2015.

[53] Peng Wang, Lingqiao Liu, Chunhua Shen, Zi Huang, Anton van den Hengel, and Heng Tao Shen. Multi-attention

network for one shot learning. 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR),

pages 6212‚Äì6220, 2017.

[54] Chen Xing, Negar Rostamzadeh, Boris N. Oreshkin, and Pedro H. O. Pinheiro. Adaptive cross-modal few-shot

learning. In NeurIPS, 2019.

[55] Qianru Sun, Xinzhe Li, Yaoyao Liu, Shibao Zheng, Tat-Seng Chua, and Bernt Schiele. Learning to self-train for

semi-supervised few-shot classiÔ¨Åcation. In NeurIPS, 2019.

[56] Spyros Gidaris and Nikos Komodakis. Dynamic few-shot visual learning without forgetting. 2018 IEEE/CVF

Conference on Computer Vision and Pattern Recognition, pages 4367‚Äì4375, 2018.

30

## Page 31

Parnami & Lee

[57] Han-Jia Ye, Hexiang Hu, De-Chuan Zhan, and Fei Sha. Learning classiÔ¨Åer synthesis for generalized few-shot

learning. ArXiv, abs/1906.02944, 2019.

[58] Mengye Ren, Renjie Liao, Ethan Fetaya, and Richard S. Zemel. Incremental few-shot learning with attention

attractor networks. In NeurIPS, 2019.

[59] Yu-Xiong Wang, Ross B. Girshick, Martial Hebert, and Bharath Hariharan. Low-shot learning from imaginary

data. 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 7278‚Äì7286, 2018.

[60] Hung-Yu Tseng, Hsin-Ying Lee, Jia-Bin Huang, and Ming-Hsuan Yang. Cross-domain few-shot classiÔ¨Åcation via

learned feature-wise transformation. ArXiv, abs/2001.08735, 2020.

[61] Vladimir N. Vapnik. Transductive inference and semi-supervised learning. In Semi-Supervised Learning, 2006.

[62] Yanbin Liu, Juho Lee, Minseop Park, Saehoon Kim, Eunho Yang, SungJu Hwang, and Yang Yang. Learning to

propagate labels: Transductive propagation network for few-shot learning. In ICLR, 2019.

[63] Antreas Antoniou and Amos J. Storkey. Learning to learn via self-critique. ArXiv, abs/1905.10295, 2019.

[64] Gabriel Huang, Hugo Larochelle, and Simon Lacoste-Julien. Centroid networks for few-shot clustering and

unsupervised few-shot classiÔ¨Åcation. ArXiv, abs/1902.08605, 2019.

[65] Yongqin Xian, Bernt Schiele, and Zeynep Akata. Zero-shot learning - the good, the bad and the ugly. CoRR,

abs/1703.04394, 2017.

[66] Li Zhang, Tao Xiang, and Shaogang Gong. Learning a deep embedding model for zero-shot learning. 2017 IEEE

Conference on Computer Vision and Pattern Recognition (CVPR), pages 3010‚Äì3019, 2017.

[67] Lisa Torrey and Jude Shavlik. Transfer learning. In Handbook of research on machine learning applications and

trends: algorithms, methods, and techniques, pages 242‚Äì264. IGI Global, 2010.

[68] Yan Wang, Wei-Lun Chao, Kilian Q. Weinberger, and Laurens van der Maaten. Simpleshot: Revisiting nearest-

neighbor classiÔ¨Åcation for few-shot learning. ArXiv, abs/1911.04623, 2019.

[69] Yinbo Chen, Xiaolong Wang, Zhuang Liu, Huijuan Xu, and Trevor Darrell. A new meta-baseline for few-shot

learning. ArXiv, abs/2003.04390, 2020.

[70] Yonglong Tian, Yue Wang, Dilip Krishnan, Joshua B. Tenenbaum, and Phillip Isola. Rethinking few-shot image

classiÔ¨Åcation: a good embedding is all you need?, 2020.

[71] Guneet S. Dhillon, P. Chaudhari, Avinash Ravichandran, and Stefano Soatto. A baseline for few-shot image

classiÔ¨Åcation. ArXiv, abs/1909.02729, 2019.

[72] Imtiaz Masud Ziko, Jose Dolz, √âric Granger, and Ismail Ben Ayed. Laplacian regularized few-shot learning.

ArXiv, abs/2006.15486, 2020.

[73] Decebal Constantin Mocanu and Elena Mocanu. One-shot learning using mixture of variational autoencoders: a

generalization learning approach. ArXiv, abs/1804.07645, 2018.

[74] Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114, 2013.

[75] Hao Chen, Yali Wang, Guoyou Wang, and Yu Qiao. Lstd: A low-shot transfer detector for object detection. ArXiv,

abs/1803.01529, 2018.

[76] Bingyi Kang, Zhuang Liu, Xin Wang, Fisher Yu, Jiashi Feng, and Trevor Darrell. Few-shot object detection via

feature reweighting. 2019 IEEE/CVF International Conference on Computer Vision (ICCV), pages 8419‚Äì8428,

2018.

[77] Qi Fan, Wei Zhuo, and Yu-Wing Tai. Few-shot object detection with attention-rpn and multi-relation detector.

ArXiv, abs/1908.01998, 2019.

[78] Eli Schwartz, Leonid Karlinsky, Joseph Shtok, Sivan Harary, Mattias Marder, Sharath Pankanti, Rog√©rio Schmidt

Feris, Abhishek Kumar, Raja Giryes, and Alexander M. Bronstein. Repmet: Representative-based metric learning

for classiÔ¨Åcation and few-shot object detection. 2019 IEEE/CVF Conference on Computer Vision and Pattern

Recognition (CVPR), pages 5192‚Äì5201, 2018.

[79] Claudio Michaelis, Ivan Ustyuzhaninov, Matthias Bethge, and Alexander S. Ecker. One-shot instance segmentation.

ArXiv, abs/1811.11507, 2018.

[80] Ansi Zhang, Shaobo Li, Yuxin Cui, Wanli Yang, Rongzhi Dong, and Jianjun Hu. Limited data rolling bearing

fault diagnosis with few-shot learning. IEEE Access, 7:110895‚Äì110904, 2019.

[81] Mo Yu, Xiaoxiao Guo, Jinfeng Yi, Shiyu Chang, Saloni Potdar, Yu Cheng, Gerald Tesauro, Haoyu Wang, and

Bowen Zhou. Diverse few-shot text classiÔ¨Åcation with multiple metrics. arXiv preprint arXiv:1805.07513, 2018.

31

## Page 32

Parnami & Lee

[82] Shumin Deng, Ningyu Zhang, Zhanlin Sun, Jiaoyan Chen, and Huajun Chen. When low resource nlp meets

unsupervised language model: Meta-pretraining then meta-learning for few-shot text classiÔ¨Åcation. arXiv, pages

arXiv‚Äì1908, 2019.

[83] Seungjoo Yoo, Hyojin Bahng, Sunghyo Chung, Junsoo Lee, Jaehyuk Chang, and Jaegul Choo. Coloring with

limited data: Few-shot colorization via memory augmented networks. In Proceedings of the IEEE Conference on

Computer Vision and Pattern Recognition, pages 11283‚Äì11292, 2019.

[84] Manasi Vartak, Arvind Thiagarajan, Conrado Miranda, Jeshua Bratman, and Hugo Larochelle. A meta-learning

perspective on cold-start recommendations for items. In NIPS, 2017.

[85] Zhengxiao Du, Xiaowei Wang, Hongxia Yang, Jingren Zhou, and Jie Tang. Sequential scenario-speciÔ¨Åc meta

learner for online recommendation. Proceedings of the 25th ACM SIGKDD International Conference on Knowl-

edge Discovery & Data Mining, 2019.

[86] Fan Zhou, Chengtai Cao, Kunpeng Zhang, Goce Trajcevski, Ting Zhong, and Ji Geng. Meta-gnn: On few-

shot node classiÔ¨Åcation in graph meta-learning. In Proceedings of the 28th ACM International Conference on

Information and Knowledge Management, pages 2357‚Äì2360, 2019.

[87] Jongmin Kim, Taesup Kim, Sungwoong Kim, and Chang D Yoo. Edge-labeling graph neural network for few-shot

learning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 11‚Äì20,

2019.

[88] Xu Han, Hao Zhu, Pengfei Yu, Ziyun Wang, Yuan Yao, Zhiyuan Liu, and Maosong Sun. Fewrel: A large-scale

supervised few-shot relation classiÔ¨Åcation dataset with state-of-the-art evaluation. In EMNLP, 2018.

[89] Prashant Anand, Ajeet Kumar Singh, Siddharth Srivastava, and Brejesh Lall. Few shot speaker recognition using

deep neural networks. arXiv preprint arXiv:1904.08775, 2019.

[90] Archit Parnami and Minwoo Lee. Few-shot keyword spotting with prototypical networks. arXiv preprint

arXiv:2007.14463, 2020.

[91] Szu-Yu Chou, Kai-Hsiang Cheng, Jyh-Shing Roger Jang, and Yi-Hsuan Yang. Learning to match transient sound

events using attentional similarity for few-shot sound recognition. In ICASSP 2019-2019 IEEE International

Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 26‚Äì30. IEEE, 2019.

[92] Yan Duan, Marcin Andrychowicz, Bradly Stadie, OpenAI Jonathan Ho, Jonas Schneider, Ilya Sutskever, Pieter

Abbeel, and Wojciech Zaremba. One-shot imitation learning. In Advances in neural information processing

systems, pages 1087‚Äì1098, 2017.

[93] Richard S Sutton and Andrew G Barto. Reinforcement learning: An introduction. MIT press, 2018.

[94] Tianshi Cao, Marc Teva Law, and Sanja Fidler. A theoretical analysis of the number of shots in few-shot learning.

ArXiv, abs/1909.11722, 2020.

[95] Yann LeCun and Corinna Cortes. MNIST handwritten digit database. 2010.

[96] P. Welinder, S. Branson, T. Mita, C. Wah, F. Schroff, S. Belongie, and P. Perona. Caltech-UCSD Birds 200.

Technical Report CNS-TR-2010-001, California Institute of Technology, 2010.

[97] J. Krause, M. Stark, J. Deng, and L. Fei-Fei. 3d object representations for Ô¨Åne-grained categorization. In 2013

IEEE International Conference on Computer Vision Workshops, pages 554‚Äì561, 2013.

32
