@misc{han2015learnweightsconnect,
	Author = {Song Han and Jeff Pool and John Tran and William J. Dally},
	Title = {Learning both Weights and Connections for Efficient Neural Networks},
	Year = {2015},
	Eprint = {arXiv:1506.02626},
}

@misc{wen2016learnstructsparse,
	Author = {Wei Wen and Chunpeng Wu and Yandan Wang and Yiran Chen and Hai Li},
	Title = {Learning Structured Sparsity in Deep Neural Networks},
	Year = {2016},
	Eprint = {arXiv:1608.03665},
}

@misc{touvron2023llama,
	title={LLaMA 2: Open Foundation and Fine-Tuned Chat Models}, 
	author={Hugo Touvron and Thibaut Lavril and Gautier Izacard and Timothy Lacroix and Baptiste Rozière and Naman Goyal and Eric Hambro and Faisal Azhar and Aurelien Rodriguez and Armand Joulin and Edouard Grave and Guillaume Lample},
	year={2023},
	eprint={2307.09288},
	archivePrefix={arXiv},
	primaryClass={cs.CL}
}

@article{abdin2024phi,
	title={Phi-4 technical report},
	author={Abdin, Marah and Aneja, Jyoti and Behl, Harkirat and Bubeck, S{\'e}bastien and Eldan, Ronen and Gunasekar, Suriya and Harrison, Michael and Hewett, Russell J and Javaheripi, Mojan and Kauffmann, Piero and others},
	journal={arXiv preprint arXiv:2412.08905},
	year={2024}
}

@misc{cobbe2021training,
	title={Training Verifiers to Solve Math Word Problems},
	author={Karl Cobbe and Vineet Kosaraju and Mohammad Bavarian and Mark Chen and Heewoo Jun and Lukasz Kaiser and Matthias Plappert and Jerry Tworek and Jacob Hilton and Reiichiro Nakano and Christopher Hesse and John Schulman},
	year={2021},
	eprint={2110.14168},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/2110.14168}
}

@misc{touvron2024llama3,
	title={LLaMA 3 Technical Report},
	author={Hugo Touvron and Amanpreet Singh and Xian Li and Shuohui Chen and Nicolas Usunier and Gabriel Synnaeve and Edouard Grave and Armand Joulin},
	year={2024},
	url={https://llama.meta.com/llama3/}
}

@misc{chen2024phi,
	title={Phi-2: The Surprising Power of Small Language Models},
	author={Shuyan Dong and Xiang Lisa Li and Yao Fu and Tianyi Zhang and Ce Zhang and Mu Li and Xia Song and Jianfeng Gao and Yelong Shen and Lidong Zhou},
	year={2024},
	eprint={2404.14219},
	archivePrefix={arXiv},
	primaryClass={cs.CL}
}

@misc{qwen2024qwen25,
	title={Qwen2: Scaling up Language Models with Data Mixture of Expert Quality},
	author={Yuxiao Dong and Zihan Liu and Yitao Xu and Yiming Cui and Wanxiang Che and Tianxiang Sun and Ting Liu},
	year={2024},
	url={https://huggingface.co/Qwen/Qwen2-7B}
}


@misc{deepseeek2024,
	Author = { DeepSeek-AI and  : and Xiao Bi and Deli Chen and Guanting Chen and Shanhuang Chen and Damai Dai and Chengqi Deng and Honghui Ding and Kai Dong and Qiushi Du and Zhe Fu and Huazuo Gao and Kaige Gao and Wenjun Gao and Ruiqi Ge and Kang Guan and Daya Guo and Jianzhong Guo and Guangbo Hao and Zhewen Hao and Ying He and Wenjie Hu and Panpan Huang and Erhang Li and Guowei Li and Jiashi Li and Yao Li and Y. K. Li and Wenfeng Liang and Fangyun Lin and A. X. Liu and Bo Liu and Wen Liu and Xiaodong Liu and Xin Liu and Yiyuan Liu and Haoyu Lu and Shanghao Lu and Fuli Luo and Shirong Ma and Xiaotao Nie and Tian Pei and Yishi Piao and Junjie Qiu and Hui Qu and Tongzheng Ren and Zehui Ren and Chong Ruan and Zhangli Sha and Zhihong Shao and Junxiao Song and Xuecheng Su and Jingxiang Sun and Yaofeng Sun and Minghui Tang and Bingxuan Wang and Peiyi Wang and Shiyu Wang and Yaohui Wang and Yongji Wang and Tong Wu and Y. Wu and Xin Xie and Zhenda Xie and Ziwei Xie and Yiliang Xiong and Hanwei Xu and R. X. Xu and Yanhong Xu and Dejian Yang and Yuxiang You and Shuiping Yu and Xingkai Yu and B. Zhang and Haowei Zhang and Lecong Zhang and Liyue Zhang and Mingchuan Zhang and Minghua Zhang and Wentao Zhang and Yichao Zhang and Chenggang Zhao and Yao Zhao and Shangyan Zhou and Shunfeng Zhou and Qihao Zhu and Yuheng Zou},
	Title = {DeepSeek LLM: Scaling Open-Source Language Models with Longtermism},
	Year = {2024},
	Eprint = {arXiv:2401.02954},
}

@misc{bai2023qwen,
	Author = {Jinze Bai and Shuai Bai and Yunfei Chu and Zeyu Cui and Kai Dang and Xiaodong Deng and Yang Fan and Wenbin Ge and Yu Han and Fei Huang and Binyuan Hui and Luo Ji and Mei Li and Junyang Lin and Runji Lin and Dayiheng Liu and Gao Liu and Chengqiang Lu and Keming Lu and Jianxin Ma and Rui Men and Xingzhang Ren and Xuancheng Ren and Chuanqi Tan and Sinan Tan and Jianhong Tu and Peng Wang and Shijie Wang and Wei Wang and Shengguang Wu and Benfeng Xu and Jin Xu and An Yang and Hao Yang and Jian Yang and Shusheng Yang and Yang Yao and Bowen Yu and Hongyi Yuan and Zheng Yuan and Jianwei Zhang and Xingxuan Zhang and Yichang Zhang and Zhenru Zhang and Chang Zhou and Jingren Zhou and Xiaohuan Zhou and Tianhang Zhu},
	Title = {Qwen Technical Report},
	Year = {2023},
	Eprint = {arXiv:2309.16609},
}

@misc{wei2024skyworkMOE,
	Author = {Tianwen Wei and Bo Zhu and Liang Zhao and Cheng Cheng and Biye Li and Weiwei Lü and Peng Cheng and Jianhao Zhang and Xiaoyu Zhang and Liang Zeng and Xiaokun Wang and Yutuan Ma and Rui Hu and Shuicheng Yan and Han Fang and Yahui Zhou},
	Title = {Skywork-MoE: A Deep Dive into Training Techniques for Mixture-of-Experts Language Models},
	Year = {2024},
	Eprint = {arXiv:2406.06563},
}

@misc{zewin2022expertcollapse,
	Author = {Zewen Chi and Li Dong and Shaohan Huang and Damai Dai and Shuming Ma and Barun Patra and Saksham Singhal and Payal Bajaj and Xia Song and Xian-Ling Mao and Heyan Huang and Furu Wei},
	Title = {On the Representation Collapse of Sparse Mixture of Experts},
	Year = {2022},
	Eprint = {arXiv:2204.09179},
}

@misc{upcycle,
	Author = {Aran Komatsuzaki and Joan Puigcerver and James Lee-Thorp and Carlos Riquelme Ruiz and Basil Mustafa and Joshua Ainslie and Yi Tay and Mostafa Dehghani and Neil Houlsby},
	Title = {Sparse Upcycling: Training Mixture-of-Experts from Dense Checkpoints},
	Year = {2022},
	Eprint = {arXiv:2212.05055},
}

@article{achiam2023gpt,
	title={Gpt-4 technical report},
	author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
	journal={arXiv preprint arXiv:2303.08774},
	year={2023}
}

@misc{liu2024trainingfreeactivationsparsitylarge,
	title={Training-Free Activation Sparsity in Large Language Models}, 
	author={James Liu and Pragaash Ponnusamy and Tianle Cai and Han Guo and Yoon Kim and Ben Athiwaratkun},
	year={2024},
	eprint={2408.14690},
	archivePrefix={arXiv},
	primaryClass={cs.CL},
	url={https://arxiv.org/abs/2408.14690}, 
}

@misc{lee2024catscontextuallyawarethresholdingsparsity,
	title={CATS: Contextually-Aware Thresholding for Sparsity in Large Language Models}, 
	author={Donghyun Lee and Je-Yong Lee and Genghan Zhang and Mo Tiwari and Azalia Mirhoseini},
	year={2024},
	eprint={2404.08763},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/2404.08763}, 
}

@article{jiang2023mistral,
	title={Mistral 7B},
	author={Jiang, Albert Q and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and others},
	journal={arXiv preprint arXiv:2310.06825},
	year={2023}
}

@article{zhao2025robustness,
	title={On the robustness of gui grounding models against image attacks},
	author={Zhao, Haoren and Chen, Tianyi and Wang, Zhen},
	journal={arXiv preprint arXiv:2504.04716},
	year={2025}
}

@article{tschannen2025siglip,
	title={Siglip 2: Multilingual vision-language encoders with improved semantic understanding, localization, and dense features},
	author={Tschannen, Michael and Gritsenko, Alexey and Wang, Xiao and Naeem, Muhammad Ferjad and Alabdulmohsin, Ibrahim and Parthasarathy, Nikhil and Evans, Talfan and Beyer, Lucas and Xia, Ye and Mustafa, Basil and others},
	journal={arXiv preprint arXiv:2502.14786},
	year={2025}
}

@article{seamless2025joint,
	title={Joint speech and text machine translation for up to 100 languages},
	journal={Nature},
	volume={637},
	number={8046},
	pages={587--593},
	year={2025},
	publisher={Nature Publishing Group UK London}
}

@article{cheng2025dehumanizing,
	title={Dehumanizing Machines: Mitigating Anthropomorphic Behaviors in Text Generation Systems},
	author={Cheng, Myra and Blodgett, Su Lin and DeVrio, Alicia and Egede, Lisa and Olteanu, Alexandra},
	journal={arXiv preprint arXiv:2502.14019},
	year={2025}
}

@article{hui2025winclick,
	title={WinClick: GUI Grounding with Multimodal Large Language Models},
	author={Hui, Zheng and Li, Yinheng and Chen, Tianyi and Banbury, Colby and Koishida, Kazuhito and others},
	journal={arXiv preprint arXiv:2503.04730},
	year={2025}
}

@article{chen2024hesso,
	title={HESSO: Towards Automatic Efficient and User Friendly Any Neural Network Training and Pruning},
	author={Chen, Tianyi and Qu, Xiaoyi and Aponte, David and Banbury, Colby and Ko, Jongwoo and Ding, Tianyu and Ma, Yong and Lyapunov, Vladimir and Zharkov, Ilya and Liang, Luming},
	journal={arXiv preprint arXiv:2409.09085},
	year={2024}
}

@article{ko2025distillm,
	title={DistiLLM-2: A Contrastive Approach Boosts the Distillation of LLMs},
	author={Ko, Jongwoo and Chen, Tianyi and Kim, Sungnyun and Ding, Tianyu and Liang, Luming and Zharkov, Ilya and Yun, Se-Young},
	journal={arXiv preprint arXiv:2503.07067},
	year={2025}
}

@article{devlin2018bert,
	title={Bert: Pre-training of deep bidirectional transformers for language understanding},
	author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	journal={arXiv preprint arXiv:1810.04805},
	year={2018}
}

@article{taori2023alpaca,
	title={Alpaca: A strong, replicable instruction-following model},
	author={Taori, Rohan and Gulrajani, Ishaan and Zhang, Tianyi and Dubois, Yann and Li, Xuechen and Guestrin, Carlos and Liang, Percy and Hashimoto, Tatsunori B},
	journal={Stanford Center for Research on Foundation Models. https://crfm. stanford. edu/2023/03/13/alpaca. html},
	volume={3},
	number={6},
	pages={7},
	year={2023}
}

@misc{OpenOrca,
	title = {OpenOrca: An Open Dataset of GPT Augmented FLAN Reasoning Traces},
	author = {Wing Lian and Bleys Goodson and Eugene Pentland and Austin Cook and Chanvichet Vong and "Teknium"},
	year = {2023},
	publisher = {HuggingFace},
	journal = {HuggingFace repository},
	howpublished = {\url{https://https://huggingface.co/Open-Orca/OpenOrca}},
}

@misc{ashkboos2024slicegptcompresslargelanguage,
	title={SliceGPT: Compress Large Language Models by Deleting Rows and Columns}, 
	author={Saleh Ashkboos and Maximilian L. Croci and Marcelo Gennari do Nascimento and Torsten Hoefler and James Hensman},
	year={2024},
	eprint={2401.15024},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/2401.15024}, 
}

@misc{zhang2024loraprunestructuredpruningmeets,
	title={LoRAPrune: Structured Pruning Meets Low-Rank Parameter-Efficient Fine-Tuning}, 
	author={Mingyang Zhang and Hao Chen and Chunhua Shen and Zhen Yang and Linlin Ou and Xinyi Yu and Bohan Zhuang},
	year={2024},
	eprint={2305.18403},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/2305.18403}, 
}

@misc{song2024prosparseintroducingenhancingintrinsic,
	title={ProSparse: Introducing and Enhancing Intrinsic Activation Sparsity within Large Language Models}, 
	author={Chenyang Song and Xu Han and Zhengyan Zhang and Shengding Hu and Xiyu Shi and Kuai Li and Chen Chen and Zhiyuan Liu and Guangli Li and Tao Yang and Maosong Sun},
	year={2024},
	eprint={2402.13516},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/2402.13516}, 
}

@misc{song2024turbosparseachievingllm,
	title={Turbo Sparse: Achieving LLM SOTA Performance with Minimal Activated Parameters}, 
	author={Yixin Song and Haotong Xie and Zhengyan Zhang and Bo Wen and Li Ma and Zeyu Mi and Haibo Chen},
	year={2024},
	eprint={2406.05955},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/2406.05955}, 
}

@misc{dong2024promptpromptedadaptivestructuredpruning,
	title={Prompt-prompted Adaptive Structured Pruning for Efficient LLM Generation}, 
	author={Harry Dong and Beidi Chen and Yuejie Chi},
	year={2024},
	eprint={2404.01365},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/2404.01365}, 
}

@misc{lee2024catscontextuallyawarethresholdingsparsity,
	title={CATS: Contextually-Aware Thresholding for Sparsity in Large Language Models}, 
	author={Donghyun Lee and Je-Yong Lee and Genghan Zhang and Mo Tiwari and Azalia Mirhoseini},
	year={2024},
	eprint={2404.08763},
	archivePrefix={arXiv},
	primaryClass={cs.LG},
	url={https://arxiv.org/abs/2404.08763}, 
}

@misc{liu2024trainingfreeactivationsparsitylarge,
	title={Training-Free Activation Sparsity in Large Language Models}, 
	author={James Liu and Pragaash Ponnusamy and Tianle Cai and Han Guo and Yoon Kim and Ben Athiwaratkun},
	year={2024},
	eprint={2408.14690},
	archivePrefix={arXiv},
	primaryClass={cs.CL},
	url={https://arxiv.org/abs/2408.14690}, 
}

@misc{zheng2024learnefficientbuildstructured,
	title={Learn To be Efficient: Build Structured Sparsity in Large Language Models}, 
	author={Haizhong Zheng and Xiaoyan Bai and Xueshen Liu and Z. Morley Mao and Beidi Chen and Fan Lai and Atul Prakash},
	year={2024},
	eprint={2402.06126},
	archivePrefix={arXiv},
	primaryClass={cs.CL},
	url={https://arxiv.org/abs/2402.06126}, 
}

@article{devlin2018bert,
	title={Bert: Pre-training of deep bidirectional transformers for language understanding},
	author={Devlin, Jacob},
	journal={arXiv preprint arXiv:1810.04805},
	year={2018}
}

@article{dubey2024llama,
	title={The llama 3 herd of models},
	author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
	journal={arXiv preprint arXiv:2407.21783},
	year={2024}
}

@misc{eval-harness,
	author       = {Gao, Leo and Tow, Jonathan and Abbasi, Baber and Biderman, Stella and Black, Sid and DiPofi, Anthony and Foster, Charles and Golding, Laurence and Hsu, Jeffrey and Le Noac'h, Alain and Li, Haonan and McDonell, Kyle and Muennighoff, Niklas and Ociepa, Chris and Phang, Jason and Reynolds, Laria and Schoelkopf, Hailey and Skowron, Aviya and Sutawika, Lintang and Tang, Eric and Thite, Anish and Wang, Ben and Wang, Kevin and Zou, Andy},
	title        = {A framework for few-shot language model evaluation},
	month        = 12,
	year         = 2023,
	publisher    = {Zenodo},
	version      = {v0.4.0},
	doi          = {10.5281/zenodo.10256836},
	url          = {https://zenodo.org/records/10256836}
}

@article{allenai:arc,
	author    = {Peter Clark  and Isaac Cowhey and Oren Etzioni and Tushar Khot and
	Ashish Sabharwal and Carissa Schoenick and Oyvind Tafjord},
	title     = {Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge},
	journal   = {arXiv:1803.05457v1},
	year      = {2018},
}

@inproceedings{bisk2020piqa,
	title={Piqa: Reasoning about physical commonsense in natural language},
	author={Bisk, Yonatan and Zellers, Rowan and Gao, Jianfeng and Choi, Yejin and others},
	booktitle={Proceedings of the AAAI conference on artificial intelligence},
	volume={34},
	number={05},
	pages={7432--7439},
	year={2020}
}

@article{sakaguchi2019winogrande,
	title={WinoGrande: An Adversarial Winograd Schema Challenge at Scale},
	author={Sakaguchi, Keisuke and Bras, Ronan Le and Bhagavatula, Chandra and Choi, Yejin},
	journal={arXiv preprint arXiv:1907.10641},
	year={2019}
}

@inproceedings{zellers2019hellaswag,
	title={HellaSwag: Can a Machine Really Finish Your Sentence?},
	author={Zellers, Rowan and Holtzman, Ari and Bisk, Yonatan and Farhadi, Ali and Choi, Yejin},
	booktitle ={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
	year={2019}
}

@misc{open-llm-leaderboard-v2,
	author = {Clémentine Fourrier and Nathan Habib and Alina Lozovskaya and Konrad Szafer and Thomas Wolf},
	title = {Open LLM Leaderboard v2},
	year = {2024},
	publisher = {Hugging Face},
	howpublished = "\url{https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard}",
}

@misc{hendy2023goodgptmodelsmachine,
	title={How Good Are GPT Models at Machine Translation? A Comprehensive Evaluation}, 
	author={Amr Hendy and Mohamed Abdelrehim and Amr Sharaf and Vikas Raunak and Mohamed Gabr and Hitokazu Matsushita and Young Jin Kim and Mohamed Afify and Hany Hassan Awadalla},
	year={2023},
	eprint={2302.09210},
	archivePrefix={arXiv},
	primaryClass={cs.CL},
	url={https://arxiv.org/abs/2302.09210}, 
}

@article{hendrycks2020measuring,
	title={Measuring massive multitask language understanding},
	author={Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob},
	journal={arXiv preprint arXiv:2009.03300},
	year={2020}
}

@article{li2024pre,
	title={Pre-trained language models for text generation: A survey},
	author={Li, Junyi and Tang, Tianyi and Zhao, Wayne Xin and Nie, Jian-Yun and Wen, Ji-Rong},
	journal={ACM Computing Surveys},
	volume={56},
	number={9},
	pages={1--39},
	year={2024},
	publisher={ACM New York, NY}
}

@article{chang2024survey,
	title={A survey on evaluation of large language models},
	author={Chang, Yupeng and Wang, Xu and Wang, Jindong and Wu, Yuan and Yang, Linyi and Zhu, Kaijie and Chen, Hao and Yi, Xiaoyuan and Wang, Cunxiang and Wang, Yidong and others},
	journal={ACM Transactions on Intelligent Systems and Technology},
	volume={15},
	number={3},
	pages={1--45},
	year={2024},
	publisher={ACM New York, NY}
}

@article{jacobs1991adaptive,
	title={Adaptive mixtures of local experts},
	author={Jacobs, Robert A and Jordan, Michael I and Nowlan, Steven J and Hinton, Geoffrey E},
	journal={Neural computation},
	volume={3},
	number={1},
	pages={79--87},
	year={1991},
	publisher={MIT Press}
}

@article{chen2023lorashear,
	title={Lorashear: Efficient large language model structured pruning and knowledge recovery},
	author={Chen, Tianyi and Ding, Tianyu and Yadav, Badal and Zharkov, Ilya and Liang, Luming},
	journal={arXiv preprint arXiv:2310.18356},
	year={2023}
}

@article{pan2024dense,
	title={Dense Training, Sparse Inference: Rethinking Training of Mixture-of-Experts Language Models},
	author={Pan, Bowen and Shen, Yikang and Liu, Haokun and Mishra, Mayank and Zhang, Gaoyuan and Oliva, Aude and Raffel, Colin and Panda, Rameswar},
	journal={arXiv preprint arXiv:2404.05567},
	year={2024}
}

@article{shazeer2017outrageously,
	title={Outrageously large neural networks: The sparsely-gated mixture-of-experts layer},
	author={Shazeer, Noam and Mirhoseini, Azalia and Maziarz, Krzysztof and Davis, Andy and Le, Quoc and Hinton, Geoffrey and Dean, Jeff},
	journal={arXiv preprint arXiv:1701.06538},
	year={2017}
}

@inproceedings{xue2022go,
	title={Go wider instead of deeper},
	author={Xue, Fuzhao and Shi, Ziji and Wei, Futao and Lou, Yuxuan and Liu, Yong and You, Yang},
	booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
	volume={36},
	number={8},
	pages={8779--8787},
	year={2022}
}

@article{raffel2020exploring,
	title={Exploring the limits of transfer learning with a unified text-to-text transformer},
	author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
	journal={Journal of machine learning research},
	volume={21},
	number={140},
	pages={1--67},
	year={2020}
}

@article{alizadeh2023llm,
	title={Llm in a flash: Efficient large language model inference with limited memory},
	author={Alizadeh, Keivan and Mirzadeh, Iman and Belenko, Dmitry and Khatamifard, Karen and Cho, Minsik and Del Mundo, Carlo C and Rastegari, Mohammad and Farajtabar, Mehrdad},
	journal={arXiv preprint arXiv:2312.11514},
	year={2023}
}

@article{frankle2018lottery,
	title={The lottery ticket hypothesis: Finding sparse, trainable neural networks},
	author={Frankle, Jonathan and Carbin, Michael},
	journal={arXiv preprint arXiv:1803.03635},
	year={2018}
}

@article{sanh2020movement,
	title={Movement pruning: Adaptive sparsity by fine-tuning},
	author={Sanh, Victor and Wolf, Thomas and Rush, Alexander},
	journal={Advances in neural information processing systems},
	volume={33},
	pages={20378--20389},
	year={2020}
}

@article{kurtic2024ziplm,
	title={Ziplm: Inference-aware structured pruning of language models},
	author={Kurti{\'c}, Eldar and Frantar, Elias and Alistarh, Dan},
	journal={Advances in Neural Information Processing Systems},
	volume={36},
	year={2024}
}

@article{chen2021only,
	title={Only train once: A one-shot neural network training and pruning framework},
	author={Chen, Tianyi and Ji, Bo and Ding, Tianyu and Fang, Biyi and Wang, Guanyi and Zhu, Zhihui and Liang, Luming and Shi, Yixin and Yi, Sheng and Tu, Xiao},
	journal={Advances in Neural Information Processing Systems},
	volume={34},
	pages={19637--19651},
	year={2021}
}

@inproceedings{fang2023depgraph,
	title={Depgraph: Towards any structural pruning},
	author={Fang, Gongfan and Ma, Xinyin and Song, Mingli and Mi, Michael Bi and Wang, Xinchao},
	booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
	pages={16091--16101},
	year={2023}
}

@inproceedings{frantar2023sparsegpt,
	title={Sparsegpt: Massive language models can be accurately pruned in one-shot},
	author={Frantar, Elias and Alistarh, Dan},
	booktitle={International Conference on Machine Learning},
	pages={10323--10337},
	year={2023},
	organization={PMLR}
}

@article{xia2023sheared,
	title={Sheared llama: Accelerating language model pre-training via structured pruning},
	author={Xia, Mengzhou and Gao, Tianyu and Zeng, Zhiyuan and Chen, Danqi},
	journal={arXiv preprint arXiv:2310.06694},
	year={2023}
}

@article{chen2023otov2,
	title={Otov2: Automatic, generic, user-friendly},
	author={Chen, Tianyi and Liang, Luming and Ding, Tianyu and Zhu, Zhihui and Zharkov, Ilya},
	journal={arXiv preprint arXiv:2303.06862},
	year={2023}
}

@article{chen2023otov3,
	title={OTOv3: Automatic Architecture-Agnostic Neural Network Training and Compression from Structured Pruning to Erasing Operators},
	author={Chen, Tianyi and Ding, Tianyu and Zhu, Zhihui and Chen, Zeyu and Wu, HsiangTao and Zharkov, Ilya and Liang, Luming},
	journal={arXiv preprint arXiv:2312.09411},
	year={2023}
}

@article{ma2023llm,
	title={Llm-pruner: On the structural pruning of large language models},
	author={Ma, Xinyin and Fang, Gongfan and Wang, Xinchao},
	journal={Advances in neural information processing systems},
	volume={36},
	pages={21702--21720},
	year={2023}
}

@article{lecun2015deep,
	title={Deep learning},
	author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	journal={nature},
	volume={521},
	number={7553},
	pages={436--444},
	year={2015},
	publisher={Nature Publishing Group}
}

@book{goodfellow2016deep,
	title={Deep learning},
	author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
	volume={1},
	number={2},
	year={2016},
	publisher={MIT press Cambridge}
}

@inproceedings{subramaniam2020n2nskip,
	title={N2NSkip: Learning Highly Sparse Networks using Neuron-to-Neuron Skip Connections.},
	author={Sharma, Avinash and Subramaniam, Arvind and {}},
	booktitle={BMVC},
	year={2020}
}

@inproceedings{lym2019prunetrain,
	title={PruneTrain: fast neural network training by dynamic sparse model reconfiguration},
	author={Lym, Sangkug and Choukse, Esha and Zangeneh, Siavash and Wen, Wei and Sanghavi, Sujay and Erez, Mattan},
	booktitle={Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
	pages={1--13},
	year={2019}
}

@article{yang2019deephoyer,
	title={Deephoyer: Learning sparser neural network with differentiable scale-invariant sparsity measures},
	author={Yang, Huanrui and Wen, Wei and Li, Hai},
	journal={arXiv preprint arXiv:1908.09979},
	year={2019}
}

@inproceedings{kang2020operation,
	title={Operation-aware soft channel pruning using differentiable masks},
	author={Kang, Minsoo and Han, Bohyung},
	booktitle={International Conference on Machine Learning},
	pages={5122--5131},
	year={2020},
	organization={PMLR}
}

@article{wang2020picking,
	title={Picking winning tickets before training by preserving gradient flow},
	author={Wang, Chaoqi and Zhang, Guodong and Grosse, Roger},
	journal={arXiv preprint arXiv:2002.07376},
	year={2020}
}

@article{lee2018snip,
	title={Snip: Single-shot network pruning based on connection sensitivity},
	author={Lee, Namhoon and Ajanthan, Thalaiyasingam and Torr, Philip HS},
	journal={arXiv preprint arXiv:1810.02340},
	year={2018}
}

@article{dai2023adaptive,
	title={An adaptive half-space projection method for stochastic optimization problems with group sparse regularization},
	author={Dai, Yutong and Chen, Tianyi and Wang, Guanyi and Robinson, Daniel P},
	journal={Transactions on machine learning research},
	year={2023}
}

@inproceedings{kang2020operation,
	title={Operation-aware soft channel pruning using differentiable masks},
	author={Kang, Minsoo and Han, Bohyung},
	booktitle={International Conference on Machine Learning},
	pages={5122--5131},
	year={2020},
	organization={PMLR}
}

@article{you2019gate,
	title={Gate decorator: Global filter pruning method for accelerating deep convolutional neural networks},
	author={You, Zhonghui and Yan, Kun and Ye, Jinmian and Ma, Meng and Wang, Ping},
	journal={arXiv preprint arXiv:1909.08174},
	year={2019}
}

@inproceedings{chen2023otov2,
	title={OTOv2: Automatic, Generic, User-Friendly},
	author={Chen, Tianyi and Liang, Luming and Tianyu, DING and Zhu, Zhihui and Zharkov, Ilya},
	booktitle={International Conference on Learning Representations},
	year={2023}
}

@article{zhu2023caesarnerf,
	title={CaesarNeRF: Calibrated Semantic Representation for Few-shot Generalizable Neural Rendering},
	author={Zhu, Haidong and Ding, Tianyu and Chen, Tianyi and Zharkov, Ilya and Nevatia, Ram and Liang, Luming},
	journal={arXiv preprint arXiv:2311.15510},
	year={2023}
}

@inproceedings{zhou2024dream,
	title={Dream: Diffusion rectification and estimation-adaptive models},
	author={Zhou, Jinxin and Ding, Tianyu and Chen, Tianyi and Jiang, Jiachen and Zharkov, Ilya and Zhu, Zhihui and Liang, Luming},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={8342--8351},
	year={2024}
}

@article{ji2019generative,
	title={Generative adversarial network for handwritten text},
	author={Ji, Bo and Chen, Tianyi},
	journal={arXiv preprint arXiv:1907.11845},
	year={2019}
}

@article{ko2024distillm,
	title={Distillm: Towards streamlined distillation for large language models},
	author={Ko, Jongwoo and Kim, Sungnyun and Chen, Tianyi and Yun, Se-Young},
	journal={arXiv preprint arXiv:2402.03898},
	year={2024}
}

@article{ding2020lossless,
	title={Lossless CNN Channel Pruning via Decoupling Remembering and Forgetting},
	author={Ding, Xiaohan and Hao, Tianxiang and Tan, Jianchao and Liu, Ji and Han, Jungong and Guo, Yuchen and Ding, Guiguang},
	journal={Proceedings of the IEEE International Conference on Computer Vision},
	year={2021}
}

@article{gale2019state,
	title={The state of sparsity in deep neural networks},
	author={Gale, Trevor and Elsen, Erich and Hooker, Sara},
	journal={arXiv preprint arXiv:1902.09574},
	year={2019}
}

@inproceedings{wu2016quantized,
	title={Quantized convolutional neural networks for mobile devices},
	author={Wu, Jiaxiang and Leng, Cong and Wang, Yuhang and Hu, Qinghao and Cheng, Jian},
	booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages={4820--4828},
	year={2016}
}

@misc{shi2020object,
	title={OBJECT DETECTION AND SEGMENTATION FOR INKING APPLICATIONS},
	author={Shi, Yixin and Orazaev, Aman and Chen, Tianyi and YI, Sheng},
	year={2020},
	month=sep # "~24",
	note={US Patent App. 16/360,006}
}

@article{chen2020orthant,
	title={Orthant Based Proximal Stochastic Gradient Method for $ell\_1$-Regularized Optimization},
	author={Chen, Tianyi and Ding, Tianyu and Ji, Bo and Wang, Guanyi and Shi, Yixin and Yi, Sheng and Tu, Xiao and Zhu, Zhihui},
	journal={arXiv preprint arXiv:2004.03639},
	year={2020}
}

@article{chen2020half,
	title={A Half-Space Stochastic Projected Gradient Method for Group-Sparsity Regularization},
	author={Chen, Tianyi and Wang, Guanyi and Ding, Tianyu and Ji, Bo and Yi, Sheng and Zhu, Zhihui},
	journal={arXiv preprint arXiv:2009.12078},
	year={2020}
}

@phdthesis{chen2018fast,
	title={A Fast Reduced-Space Algorithmic Framework for Sparse Optimization},
	author={Chen, Tianyi},
	year={2018},
	school={Johns Hopkins University}
}

@article{li1608pruning,
	title={Pruning filters for efficient convnets. arXiv 2016},
	author={Li, H and Kadav, A and Durdanovic, I and Samet, H and Graf, HP},
	journal={arXiv preprint arXiv:1608.08710}
}


@inproceedings{zhou2019accelerate,
	title={Accelerate cnn via recursive bayesian pruning},
	author={Zhou, Yuefu and Zhang, Ya and Wang, Yanfeng and Tian, Qi},
	booktitle={Proceedings of the IEEE International Conference on Computer Vision},
	pages={3306--3315},
	year={2019}
}


@inproceedings{deng2009imagenet,
	title={Imagenet: A large-scale hierarchical image database},
	author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
	booktitle={2009 IEEE conference on computer vision and pattern recognition},
	pages={248--255},
	year={2009},
	organization={Ieee}
}

@inproceedings{neklyudov2017structured,
	title={Structured bayesian pruning via log-normal multiplicative noise},
	author={Neklyudov, Kirill and Molchanov, Dmitry and Ashukha, Arsenii and Vetrov, Dmitry P},
	booktitle={Advances in Neural Information Processing Systems},
	pages={6775--6784},
	year={2017}
}

@inproceedings{louizos2017bayesian,
	title={Bayesian compression for deep learning},
	author={Louizos, Christos and Ullrich, Karen and Welling, Max},
	booktitle={Advances in neural information processing systems},
	pages={3288--3298},
	year={2017}
}


@article{hu2016network,
	title={Network trimming: A data-driven neuron pruning approach towards efficient deep architectures},
	author={Hu, Hengyuan and Peng, Rui and Tai, Yu-Wing and Tang, Chi-Keung},
	journal={arXiv preprint arXiv:1607.03250},
	year={2016}
}

@article{he2018soft,
	title={Soft filter pruning for accelerating deep convolutional neural networks},
	author={He, Yang and Kang, Guoliang and Dong, Xuanyi and Fu, Yanwei and Yang, Yi},
	journal={arXiv preprint arXiv:1808.06866},
	year={2018}
}


@inproceedings{li2019exploiting,
	title={Exploiting kernel sparsity and entropy for interpretable CNN compression},
	author={Li, Yuchao and Lin, Shaohui and Zhang, Baochang and Liu, Jianzhuang and Doermann, David and Wu, Yongjian and Huang, Feiyue and Ji, Rongrong},
	booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages={2800--2809},
	year={2019}
}

@inproceedings{he2018amc,
	title={Amc: Automl for model compression and acceleration on mobile devices},
	author={He, Yihui and Lin, Ji and Liu, Zhijian and Wang, Hanrui and Li, Li-Jia and Han, Song},
	booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
	pages={784--800},
	year={2018}
}


@inproceedings{defazio2014saga,
	title={SAGA: A fast incremental gradient method with support for non-strongly convex composite objectives},
	author={Defazio, Aaron and Bach, Francis and Lacoste-Julien, Simon},
	booktitle={Advances in neural information processing systems},
	pages={1646--1654},
	year={2014}
}

@inproceedings{roux2012stochastic,
	title={A stochastic gradient method with an exponential convergence \_rate for finite training sets},
	author={Roux, Nicolas L and Schmidt, Mark and Bach, Francis R},
	booktitle={Advances in neural information processing systems},
	pages={2663--2671},
	year={2012}
}


@article{ndiaye2017gap,
	title={Gap safe screening rules for sparsity enforcing penalties},
	author={Ndiaye, Eugene and Fercoq, Olivier and Gramfort, Alexandre and Salmon, Joseph},
	journal={The Journal of Machine Learning Research},
	volume={18},
	number={1},
	pages={4671--4703},
	year={2017},
	publisher={JMLR. org}
}

@article{scardapane2017group,
	title={Group sparse regularization for deep neural networks},
	author={Scardapane, Simone and Comminiello, Danilo and Hussain, Amir and Uncini, Aurelio},
	journal={Neurocomputing},
	volume={241},
	pages={81--89},
	year={2017},
	publisher={Elsevier}
}

@book{nocedal2006numerical,
	title={Numerical optimization},
	author={Nocedal, Jorge and Wright, Stephen},
	year={2006},
	publisher={Springer Science \& Business Media}
}

@article{zhang2020statistical,
	title={Statistical Adaptive Stochastic Gradient Methods},
	author={Zhang, Pengchuan and Lang, Hunter and Liu, Qiang and Xiao, Lin},
	journal={arXiv preprint arXiv:2002.10597},
	year={2020}
}

@inproceedings{jenatton2010structured,
	title={Structured sparse principal component analysis},
	author={Jenatton, Rodolphe and Obozinski, Guillaume and Bach, Francis},
	booktitle={Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics},
	pages={366--373},
	year={2010}
}

@inproceedings{el2018combinatorial,
	title={Combinatorial Penalties: Which structures are preserved by convex relaxations?},
	author={El Halabi, Marwa and Bach, Francis and Cevher, Volkan},
	booktitle={International Conference on Artificial Intelligence and Statistics},
	pages={1551--1560},
	year={2018},
	organization={PMLR}
}

@article{mitzenmacher2005probability,
	title={Probability and Computing-Randomized Algorithms and Probabilistic Analysis},
	author={Mitzenmacher, Michael},
	journal={JOURNAL-OPERATIONAL RESEARCH SOCIETY},
	volume={56},
	number={12},
	pages={1454},
	year={2005},
	publisher={Palgrave Macmillan Ltd}
}

@article{liu2018mri,
	title={MRI reconstruction via enhanced group sparsity and nonconvex regularization},
	author={Liu, Shujun and Cao, Jianxin and Liu, Hongqing and Zhou, Xichuan and Zhang, Kui and Li, Zhengzhou},
	journal={Neurocomputing},
	volume={272},
	pages={108--121},
	year={2018},
	publisher={Elsevier}
}

@article{huang2010benefit,
	title={The benefit of group sparsity},
	author={Huang, Junzhou and Zhang, Tong and others},
	journal={The Annals of Statistics},
	volume={38},
	number={4},
	pages={1978--2004},
	year={2010},
	publisher={Institute of Mathematical Statistics}
}

@article{chen2014group,
	title={Group-sparse signal denoising: non-convex regularization, convex optimization},
	author={Chen, Po-Yu and Selesnick, Ivan W},
	journal={IEEE Transactions on Signal Processing},
	volume={62},
	number={13},
	pages={3464--3478},
	year={2014},
	publisher={IEEE}
}

@inproceedings{elhamifar2012see,
	title={See all by looking at a few: Sparse modeling for finding representative objects},
	author={Elhamifar, Ehsan and Sapiro, Guillermo and Vidal, Rene},
	booktitle={2012 IEEE Conference on Computer Vision and Pattern Recognition},
	pages={1600--1607},
	year={2012},
	organization={IEEE}
}

@article{yuan2006model,
	title={Model selection and estimation in regression with grouped variables},
	author={Yuan, Ming and Lin, Yi},
	journal={Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	volume={68},
	number={1},
	pages={49--67},
	year={2006},
	publisher={Wiley Online Library}
}

@inproceedings{huang2009learning,
	title={Learning with dynamic group sparsity},
	author={Huang, Junzhou and Huang, Xiaolei and Metaxas, Dimitris},
	booktitle={2009 IEEE 12th International Conference on Computer Vision},
	pages={64--71},
	year={2009},
	organization={IEEE}
}


@article{chen2017reduced,
	title={A Reduced-Space Algorithm for Minimizing $\ell_1$-Regularized Convex Functions},
	author={Chen, Tianyi and Curtis, Frank E and Robinson, Daniel P},
	journal={SIAM Journal on Optimization},
	volume={27},
	number={3},
	pages={1583--1610},
	year={2017},
	publisher={SIAM}
}


@phdthesis{chen2018fast,
	title={A Fast Reduced-Space Algorithmic Framework for Sparse Optimization},
	author={Chen, Tianyi},
	year={2018},
	school={Johns Hopkins University}
}

@article{chen2018farsa,
	title={FaRSA for $\ell_1$-regularized convex optimization: local convergence and numerical experience},
	author={Chen, Tianyi and Curtis, Frank E and Robinson, Daniel P},
	journal={Optimization Methods and Software},
	year={2018},
	publisher={Taylor \& Francis}
}

@article{tibshirani1996regression,
	title={Regression shrinkage and selection via the lasso},
	author={Tibshirani, Robert},
	journal={Journal of the Royal Statistical Society: Series B (Methodological)},
	volume={58},
	number={1},
	pages={267--288},
	year={1996},
	publisher={Wiley Online Library}
}

@article{robert2018convergegd,
	title={Convergence Theorems for Gradient Descent},
	author={Robert M. Gower},
	journal={University of Illinois, Urbana Champaign},
	year={2018}
}

@article{shalev2012online,
	title={Online learning and online convex optimization},
	author={Shalev-Shwartz, Shai and others},
	journal={Foundations and Trends{\textregistered} in Machine Learning},
	volume={4},
	number={2},
	pages={107--194},
	year={2012},
	publisher={Now Publishers, Inc.}
}

@phdthesis{zhou2015error,
	title={Error bounds for structured convex programming: theory and applications},
	author={Zhou, Zirui},
	year={2015},
	school={PhD thesis, The Chinese University of Hong Kong}
}

@inproceedings{bucilu2006model,
	title={Model compression},
	author={Buciluǎ, Cristian and Caruana, Rich and Niculescu-Mizil, Alexandru},
	booktitle={Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining},
	pages={535--541},
	year={2006}
}


@article{beck2009fast,
	title={A fast iterative shrinkage-thresholding algorithm for linear inverse problems},
	author={Beck, Amir and Teboulle, Marc},
	journal={SIAM journal on imaging sciences},
	volume={2},
	number={1},
	pages={183--202},
	year={2009},
	publisher={SIAM}
}

@article{wright2009sparse,
	title={Sparse reconstruction by separable approximation},
	author={Wright, Stephen J and Nowak, Robert D and Figueiredo, M{\'a}rio AT},
	journal={IEEE Transactions on Signal Processing},
	volume={57},
	number={7},
	pages={2479--2493},
	year={2009},
	publisher={Citeseer}
}

@article{byrd2013inexact,
	title={An inexact successive quadratic approximation method for convex l-1 regularized optimization},
	author={Byrd, Richard H and Nocedal, Jorge and Oztoprak, Figen},
	journal={arXiv preprint arXiv:1309.3529},
	year={2013}
}

@inproceedings{hsieh2011sparse,
	title={Sparse inverse covariance matrix estimation using quadratic approximation},
	author={Hsieh, Cho-Jui and Dhillon, Inderjit S and Ravikumar, Pradeep K and Sustik, M{\'a}ty{\'a}s A},
	booktitle={Advances in Neural Information Processing Systems},
	pages={2330--2338},
	year={2011}
}

@inproceedings{lee2012proximal,
	title={Proximal Newton-type methods for convex optimization},
	author={Lee, Jason and Sun, Yuekai and Saunders, Michael},
	booktitle={Advances in Neural Information Processing Systems},
	pages={836--844},
	year={2012}
}

@article{scheinberg2013practical,
	title={Practical inexact proximal quasi-Newton method with global complexity analysis},
	author={Scheinberg, Katya and Tang, Xiaocheng},
	journal={arXiv preprint arXiv:1311.6547},
	year={2013}
}

@article{yuan2012improved,
	title={An improved glmnet for l1-regularized logistic regression},
	author={Yuan, Guo-Xun and Ho, Chia-Hua and Lin, Chih-Jen},
	journal={The Journal of Machine Learning Research},
	volume={13},
	number={1},
	pages={1999--2030},
	year={2012},
	publisher={JMLR. org}
}

@inproceedings{andrew2007scalable,
	title={Scalable training of $L_1$-regularized log-linear models},
	author={Andrew, Galen and Gao, Jianfeng},
	booktitle={Proceedings of the 24th international conference on Machine learning},
	pages={33--40},
	year={2007},
	organization={ACM}
}

@article{byrd2012family,
	title={A family of second-order methods for convex l1-regularized optimization},
	author={Byrd, Richard H and Chin, Gillian M and Nocedal, Jorge and Oztoprak, Figen},
	journal={Northwestern University, Tech Report},
	year={2012}
}

@article{keskar2015second,
	title={A Second-Order Method for Convex $\ell_1$-Regularized Optimization with Active Set Prediction},
	author={Keskar, Nitish Shirish and Nocedal, Jorge and Oztoprak, Figen and Waechter, Andreas},
	journal={arXiv preprint arXiv:1505.04315},
	year={2015}
}

@article{hager2006new,
	title={A new active set algorithm for box constrained optimization},
	author={Hager, William W and Zhang, Hongchao},
	journal={SIAM Journal on Optimization},
	volume={17},
	number={2},
	pages={526--557},
	year={2006},
	publisher={SIAM}
}

@article{xiao2010dual,
	title={Dual averaging methods for regularized stochastic learning and online optimization},
	author={Xiao, Lin},
	journal={Journal of Machine Learning Research},
	volume={11},
	number={Oct},
	pages={2543--2596},
	year={2010}
}


@article{xiao2014proximal,
	title={A proximal stochastic gradient method with progressive variance reduction},
	author={Xiao, Lin and Zhang, Tong},
	journal={SIAM Journal on Optimization},
	volume={24},
	number={4},
	pages={2057--2075},
	year={2014},
	publisher={SIAM}
}
@online{xiao2017online,
	author       = {Han Xiao and Kashif Rasul and Roland Vollgraf},
	title        = {Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms},
	year         = {2017},
	eprintclass  = {cs.LG},
	eprinttype   = {arXiv},
	eprint       = {cs.LG/1708.07747},
}

@inproceedings{johnson2013accelerating,
	title={Accelerating stochastic gradient descent using predictive variance reduction},
	author={Johnson, Rie and Zhang, Tong},
	booktitle={Advances in neural information processing systems},
	pages={315--323},
	year={2013}
}
@inproceedings{he2016deep,
	title={Deep residual learning for image recognition},
	author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	year={2016}
}

@article{simonyan2014very,
	title={Very deep convolutional networks for large-scale image recognition},
	author={Simonyan, Karen and Zisserman, Andrew},
	journal={arXiv preprint arXiv:1409.1556},
	year={2014}
}

@inproceedings{sra2011fast,
	title={Fast projections onto $\ell_{1,q}$-norm balls for grouped feature selection},
	author={Sra, Suvrit},
	booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
	year={2011}
}

@inproceedings{riezler2004incremental,
	title={Incremental feature selection and l1 regularization for relaxed maximum-entropy modeling},
	author={Riezler, Stefan and Vasserman, Alexander},
	booktitle={Empirical methods in natural language processing},
	year={2004}
}

@article{Krizhevsky09,
	title={Learning multiple layers of features from tiny images},
	author={Krizhevsky, A. and Hinton, G.},
	journal={Master's thesis, Department of Computer Science, University of Toronto},
	year={2009},
	publisher={Citeseer}
}

@inproceedings{duchi2008efficient,
	title={Efficient projections onto the $\ell_1$-ball for learning in high dimensions},
	author={Duchi, John and Shalev-Shwartz, Shai and Singer, Yoram and Chandra, Tushar},
	booktitle={Proceedings of the 25th international conference on Machine learning},
	pages={272--279},
	year={2008},
	organization={ACM}
}

@article{condat2016fast,
	title={Fast projection onto the simplex and the $\ell_1$ ball},
	author={Condat, Laurent},
	journal={Mathematical Programming},
	volume={158},
	number={1-2},
	pages={575--585},
	year={2016},
	publisher={Springer}
}

@phdthesis{chen2018fast,
	title={A Fast Reduced-Space Algorithmic Framework for Sparse Optimization},
	author={Chen, Tianyi},
	year={2018},
	school={Johns Hopkins University}
}

@article{nesterov2009primal,
	title={Primal-dual subgradient methods for convex problems},
	author={Nesterov, Yurii},
	journal={Mathematical programming},
	year={2009}
}

@article{lecun-mnisthandwrittendigit-2010,
	added-at = {2010-06-28T21:16:30.000+0200},
	author = {LeCun, Yann and Cortes, Corinna},
	biburl = {https://www.bibsonomy.org/bibtex/2935bad99fa1f65e03c25b315aa3c1032/mhwombat},
	groups = {public},
	howpublished = {http://yann.lecun.com/exdb/mnist/},
	interhash = {21b9d0558bd66279df9452562df6e6f3},
	intrahash = {935bad99fa1f65e03c25b315aa3c1032},
	keywords = {MSc _checked character_recognition mnist network neural},
	lastchecked = {2016-01-14 14:24:11},
	timestamp = {2016-07-12T19:25:30.000+0200},
	title = {{MNIST} handwritten digit database},
	url = {http://yann.lecun.com/exdb/mnist/},
	username = {mhwombat},
	year = 2010
}

@book{bertsekas2009convex,
	title={Convex optimization theory},
	author={Bertsekas, Dimitri P},
	year={2009},
	publisher={Athena Scientific Belmont}
}

@article{bradley1977applied,
	title={Applied mathematical programming},
	author={Bradley, Stephen and Hax, Arnoldo and Magnanti, Thomas},
	year={1977},
	publisher={Addison Wesley}
}

@inproceedings{li2018simple,
	title={A simple proximal stochastic gradient method for nonsmooth nonconvex optimization},
	author={Li, Zhize and Li, Jian},
	booktitle={Advances in neural information processing systems},
	year={2018}
}

@article{yang2019stochastic,
	title={A Stochastic Extra-Step Quasi-Newton Method for Nonsmooth Nonconvex Optimization},
	author={Yang, Minghan and Milzarek, Andre and Wen, Zaiwen and Zhang, Tong},
	journal={arXiv preprint arXiv:1910.09373},
	year={2019}
}

@book{parkinson2013opten,
	title={Optimization methods for engineering design},
	author={A. Parkinson and R. Balling and J. Hedengren},
	year={2013},
	publisher={Provo, UT: Brigham Young University.}
}

@book{dixit1990optimization,
	title={Optimization in economic theory},
	author={Dixit, Avinash K.},
	year={1990},
	publisher={Oxford University Press on Demand}
}

@article{tikhonov1977,
	title={Solution of Ill-posed Problems.},
	author={Tikhonov, N. and Y. Arsenin.},
	journal={Winston and Sons.},
	year={1977}
}

@article{tibshirani1996regression,
	title={Regression shrinkage and selection via the lasso},
	author={Tibshirani, Robert},
	journal={Journal of the Royal Statistical Society: Series B (Methodological)},
	volume={58},
	number={1},
	pages={267--288},
	year={1996},
	publisher={Wiley Online Library}
}

@book{bishop2006pattern,
	title={Pattern recognition and machine learning},
	author={Bishop, Christopher M},
	year={2006},
	publisher={Springer Science}
}

@article{han2015deep,
	title={Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding},
	author={Han, Song and Mao, Huizi and Dally, William J},
	journal={arXiv preprint arXiv:1510.00149},
	year={2015}
}


@article{zou2005regularization,
	title={Regularization and variable selection via the elastic net},
	author={Zou, Hui and Hastie, Trevor},
	journal={Journal of the royal statistical society: series B (statistical methodology)},
	year={2005},
	publisher={Wiley Online Library}
}

@inproceedings{krizhevsky2012imagenet,
	title={Imagenet classification with deep convolutional neural networks},
	author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
	booktitle={Advances in neural information processing systems},
	pages={1097--1105},
	year={2012}
}

@article{zaremba2014recurrent,
	title={Recurrent neural network regularization},
	author={Zaremba, Wojciech and Sutskever, Ilya and Vinyals, Oriol},
	journal={arXiv preprint arXiv:1409.2329},
	year={2014}
}

@article{zeiler2013stochastic,
	title={Stochastic pooling for regularization of deep convolutional neural networks},
	author={Zeiler, Matthew D and Fergus, Rob},
	journal={arXiv preprint arXiv:1301.3557},
	year={2013}
}

@article{duchi2009efficient,
	title={Efficient online and batch learning using forward backward splitting},
	author={Duchi, John and Singer, Yoram},
	journal={Journal of Machine Learning Research},
	volume={10},
	number={Dec},
	pages={2899--2934},
	year={2009}
}

@inproceedings{andrew2007scalable,
	title={Scalable training of L1-regularized log-linear models},
	author={Andrew, Galen and Gao, Jianfeng},
	booktitle={Proceedings of the 24th international conference on Machine learning},
	pages={33--40},
	year={2007},
	organization={ACM}
}

@article{parikh2014proximal,
	title={Proximal algorithms},
	author={Parikh, Neal and Boyd, Stephen and others},
	journal={Foundations and Trends{\textregistered} in Optimization},
	volume={1},
	number={3},
	pages={127--239},
	year={2014},
	publisher={Now Publishers, Inc.}
}


@article{howard2017mobilenets,
	title={Mobilenets: Efficient convolutional neural networks for mobile vision applications},
	author={Howard, Andrew G and Zhu, Menglong and Chen, Bo and Kalenichenko, Dmitry and Wang, Weijun and Weyand, Tobias and Andreetto, Marco and Adam, Hartwig},
	journal={arXiv preprint arXiv:1704.04861},
	year={2017}
}



@inproceedings{ge2015escaping,
	title={Escaping from saddle points—online stochastic gradient for tensor decomposition},
	author={Ge, Rong and Huang, Furong and Jin, Chi and Yuan, Yang},
	booktitle={Conference on Learning Theory},
	pages={797--842},
	year={2015}
}

@article{sun2016complete,
	title={Complete dictionary recovery over the sphere I: Overview and the geometric picture},
	author={Sun, Ju and Qu, Qing and Wright, John},
	journal={IEEE Transactions on Information Theory},
	year={2016}
}

@article{park2016non,
	title={Non-square matrix sensing without spurious local minima via the Burer-Monteiro approach},
	author={Park, Dohyung and Kyrillidis, Anastasios and Caramanis, Constantine and Sanghavi, Sujay},
	journal={arXiv preprint arXiv:1609.03240},
	year={2016}
}

@article{sun2016guaranteed,
	title={Guaranteed matrix completion via non-convex factorization},
	author={Sun, Ruoyu and Luo, Zhi-Quan},
	journal={IEEE Transactions on Information Theory},
	year={2016},
	publisher={IEEE}
}

@article{li2016symmetry,
	title={Symmetry, saddle points, and global geometry of nonconvex matrix factorization},
	author={Li, Xingguo and Wang, Zhaoran and Lu, Junwei and Arora, Raman and Haupt, Jarvis and Liu, Han and Zhao, Tuo},
	journal={arXiv preprint arXiv:1612.09296},
	volume={1},
	pages={5--1},
	year={2016}
}

@inproceedings{zhong2017recovery,
	title={Recovery guarantees for one-hidden-layer neural networks},
	author={Zhong, Kai and Song, Zhao and Jain, Prateek and Bartlett, Peter L and Dhillon, Inderjit S},
	booktitle={International Conference on Machine Learning},
	year={2017}
}

@inproceedings{zaheer2018adaptive,
	title={Adaptive methods for nonconvex optimization},
	author={Zaheer, Manzil and Reddi, Sashank and Sachan, Devendra and Kale, Satyen and Kumar, Sanjiv},
	booktitle={Advances in neural information processing systems},
	pages={9793--9803},
	year={2018}
}

@inproceedings{karimi2016linear,
	title={Linear convergence of gradient and proximal-gradient methods under the polyak-{\l}ojasiewicz condition},
	author={Karimi, Hamed and Nutini, Julie and Schmidt, Mark},
	booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
	year={2016},
	organization={Springer}
}

@article{drusvyatskiy2018error,
	title={Error bounds, quadratic growth, and linear convergence of proximal methods},
	author={Drusvyatskiy, Dmitriy and Lewis, Adrian S},
	journal={Mathematics of Operations Research},
	volume={43},
	number={3},
	pages={919--948},
	year={2018},
	publisher={INFORMS}
}

@inproceedings{defazio2019ineffectiveness,
	title={On the ineffectiveness of variance reduced optimization for deep learning},
	author={Defazio, Aaron and Bottou, L{\'e}on},
	booktitle={Advances in Neural Information Processing Systems},
	year={2019}
}


@article{zhang2019multi,
	title={Multi-level composite stochastic optimization via nested variance reduction},
	author={Zhang, Junyu and Xiao, Lin},
	journal={arXiv preprint arXiv:1908.11468},
	year={2019}
}


@inproceedings{fang2018spider,
	title={Spider: Near-optimal non-convex optimization via stochastic path-integrated differential estimator},
	author={Fang, Cong and Li, Chris Junchi and Lin, Zhouchen and Zhang, Tong},
	booktitle={Advances in Neural Information Processing Systems},
	pages={689--699},
	year={2018}
}


@article{chang2011libsvm,
	title={LIBSVM: A library for support vector machines},
	author={Chang, Chih-Chung and Lin, Chih-Jen},
	journal={ACM transactions on intelligent systems and technology (TIST)},
	volume={2},
	number={3},
	pages={1--27},
	year={2011},
	publisher={Acm New York, NY, USA}
}

@article{bach2012structured,
	title={Structured sparsity through convex optimization},
	author={Bach, Francis and Jenatton, Rodolphe and Mairal, Julien and Obozinski, Guillaume and others},
	journal={Statistical Science},
	volume={27},
	number={4},
	pages={450--468},
	year={2012},
	publisher={Institute of Mathematical Statistics}
}


@article{li2016pruning,
	title={Pruning filters for efficient convnets},
	author={Li, Hao and Kadav, Asim and Durdanovic, Igor and Samet, Hanan and Graf, Hans Peter},
	journal={arXiv preprint arXiv:1608.08710},
	year={2016}
}

@inproceedings{luo2017thinet,
	title={Thinet: A filter level pruning method for deep neural network compression},
	author={Luo, Jian-Hao and Wu, Jianxin and Lin, Weiyao},
	booktitle={Proceedings of the IEEE international conference on computer vision},
	pages={5058--5066},
	year={2017}
}


@article{yuan2006model,
	title={Model selection and estimation in regression with grouped variables},
	author={Yuan, Ming and Lin, Yi},
	journal={Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	volume={68},
	number={1},
	pages={49--67},
	year={2006},
	publisher={Wiley Online Library}
}

@inproceedings{roth2008group,
	title={The group-lasso for generalized linear models: uniqueness of solutions and efficient algorithms},
	author={Roth, Volker and Fischer, Bernd},
	booktitle={Proceedings of the 25th international conference on Machine learning},
	pages={848--855},
	year={2008}
}

@article{huang2011learning,
	title={Learning with structured sparsity},
	author={Huang, Junzhou and Zhang, Tong and Metaxas, Dimitris},
	journal={Journal of Machine Learning Research},
	volume={12},
	number={Nov},
	pages={3371--3412},
	year={2011}
}

@article{nutini2019active,
	title={“Active-set complexity” of proximal gradient: How long does it take to find the sparsity pattern?},
	author={Nutini, Julie and Schmidt, Mark and Hare, Warren},
	journal={Optimization Letters},
	volume={13},
	number={4},
	pages={645--655},
	year={2019},
	publisher={Springer}
}

@inproceedings{yang2010online,
	title={Online learning for group lasso},
	author={Yang, Haiqin and Xu, Zenglin and King, Irwin and Lyu, Michael R},
	booktitle={Proceedings of the 27th International Conference on Machine Learning (ICML-10)},
	pages={1191--1198},
	year={2010}
}


@article{howard2017mobilenets,
	title={Mobilenets: Efficient convolutional neural networks for mobile vision applications},
	author={Howard, Andrew G and Zhu, Menglong and Chen, Bo and Kalenichenko, Dmitry and Wang, Weijun and Weyand, Tobias and Andreetto, Marco and Adam, Hartwig},
	journal={arXiv preprint arXiv:1704.04861},
	year={2017}
}

@inproceedings{long2015fully,
	title={Fully convolutional networks for semantic segmentation},
	author={Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={3431--3440},
	year={2015}
}

@inproceedings{ren2015faster,
	title={Faster r-cnn: Towards real-time object detection with region proposal networks},
	author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
	booktitle={Advances in neural information processing systems},
	pages={91--99},
	year={2015}
}

@inproceedings{jacob2018quantization,
	title={Quantization and training of neural networks for efficient integer-arithmetic-only inference},
	author={Jacob, Benoit and Kligys, Skirmantas and Chen, Bo and Zhu, Menglong and Tang, Matthew and Howard, Andrew and Adam, Hartwig and Kalenichenko, Dmitry},
	booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
	pages={2704--2713},
	year={2018}
}

@article{zhou2016dorefa,
	title={Dorefa-net: Training low bitwidth convolutional neural networks with low bitwidth gradients},
	author={Zhou, Shuchang and Wu, Yuxin and Ni, Zekun and Zhou, Xinyu and Wen, He and Zou, Yuheng},
	journal={arXiv preprint arXiv:1606.06160},
	year={2016}
}

@inproceedings{vaswani2017attention,
	title={Attention is all you need},
	author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
	booktitle={Advances in neural information processing systems},
	pages={5998--6008},
	year={2017}
}

@article{polino2018model,
	title={Model compression via distillation and quantization},
	author={Polino, Antonio and Pascanu, Razvan and Alistarh, Dan},
	journal={arXiv preprint arXiv:1802.05668},
	year={2018}
}

@article{zhang2010nearly,
	title={Nearly unbiased variable selection under minimax concave penalty},
	author={Zhang, Cun-Hui and others},
	journal={The Annals of statistics},
	volume={38},
	number={2},
	pages={894--942},
	year={2010},
	publisher={Institute of Mathematical Statistics}
}

@inproceedings{bucilua2006model,
	title={Model compression},
	author={Buciluǎ, Cristian and Caruana, Rich and Niculescu-Mizil, Alexandru},
	booktitle={Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining},
	pages={535--541},
	year={2006}
}

@article{han2015learning,
	title={Learning both weights and connections for efficient neural networks},
	author={Han, Song and Pool, Jeff and Tran, John and Dally, William J},
	journal={arXiv preprint arXiv:1506.02626},
	year={2015}
}

@article{cheng2017survey,
	title={A survey of model compression and acceleration for deep neural networks},
	author={Cheng, Yu and Wang, Duo and Zhou, Pan and Zhang, Tao},
	journal={arXiv preprint arXiv:1710.09282},
	year={2017}
}

@article{han2016eie,
	title={EIE: Efficient inference engine on compressed deep neural network},
	author={Han, Song and Liu, Xingyu and Mao, Huizi and Pu, Jing and Pedram, Ardavan and Horowitz, Mark A and Dally, William J},
	journal={ACM SIGARCH Computer Architecture News},
	volume={44},
	number={3},
	pages={243--254},
	year={2016},
	publisher={ACM New York, NY, USA}
}

@article{chen2018escoin,
	title={Escoin: Efficient sparse convolutional neural network inference on GPUs},
	author={Chen, Xuhao},
	journal={arXiv preprint arXiv:1802.10280},
	year={2018}
}

@misc{chen2020spatially,
	title={Spatially sparse convolutional neural networks for inking applications},
	author={Chen, Tianyi and Shi, Yixin and Yi, Sheng},
	year={2020},
	month=sep # "~17",
	publisher={Google Patents},
	note={US Patent App. 16/355,702}
}

@article{lin2019toward,
	title={Toward compact convnets via structure-sparsity regularized filter pruning},
	author={Lin, Shaohui and Ji, Rongrong and Li, Yuchao and Deng, Cheng and Li, Xuelong},
	journal={IEEE transactions on neural networks and learning systems},
	volume={31},
	number={2},
	pages={574--588},
	year={2019},
	publisher={IEEE}
}

@inproceedings{NIPS2017_3f5ee243,
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Lukasz and Polosukhin, Illia},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
	pages = {},
	publisher = {Curran Associates, Inc.},
	title = {Attention is All you Need},
	volume = {30},
	year = {2017}
}

@article{sehwag2020hydra,
	title={Hydra: Pruning adversarially robust neural networks},
	author={Sehwag, Vikash and Wang, Shiqi and Mittal, Prateek and Jana, Suman},
	journal={Advances in Neural Information Processing Systems (NeurIPS)},
	volume={7},
	year={2020}
}

@article{chen2019storage,
	title={Storage Efficient and Dynamic Flexible Runtime Channel Pruning via Deep Reinforcement Learning},
	author={Chen, Jianda and Chen, Shangyu and Pan, Sinno Jialin},
	year={2019}
}

@article{meng2020pruning,
	title={Pruning Filter in Filter},
	author={Meng, Fanxu and Cheng, Hao and Li, Ke and Luo, Huixiang and Guo, Xiaowei and Lu, Guangming and Sun, Xing},
	journal={arXiv preprint arXiv:2009.14410},
	year={2020}
}

@article{hinton2015distilling,
	title={Distilling the knowledge in a neural network},
	author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff},
	journal={arXiv preprint arXiv:1503.02531},
	year={2015}
}

@misc{onnxruntime,
	title={ONNX Runtime},
	author={ONNX Runtime developers},
	year={2021},
	howpublished={\url{https://onnxruntime.ai/}}
}

@article{tang2020scop,
	title={SCOP: Scientific Control for Reliable Neural Network Pruning},
	author={Tang, Yehui and Wang, Yunhe and Xu, Yixing and Tao, Dacheng and Xu, Chunjing and Xu, Chao and Xu, Chang},
	journal={arXiv preprint arXiv:2010.10732},
	year={2020}
}

@article{van2020bayesian,
	title={Bayesian bits: Unifying quantization and pruning},
	author={van Baalen, Mart and Louizos, Christos and Nagel, Markus and Amjad, Rana Ali and Wang, Ying and Blankevoort, Tijmen and Welling, Max},
	journal={arXiv preprint arXiv:2005.07093},
	year={2020}
}


@article{frankle2018lottery,
	title={The lottery ticket hypothesis: Finding sparse, trainable neural networks},
	author={Frankle, Jonathan and Carbin, Michael},
	journal={arXiv preprint arXiv:1803.03635},
	year={2018}
}

@article{frankle2019stabilizing,
	title={Stabilizing the lottery ticket hypothesis},
	author={Frankle, Jonathan and Dziugaite, Gintare Karolina and Roy, Daniel M and Carbin, Michael},
	journal={arXiv preprint arXiv:1903.01611},
	year={2019}
}

@article{renda2020comparing,
	title={Comparing rewinding and fine-tuning in neural network pruning},
	author={Renda, Alex and Frankle, Jonathan and Carbin, Michael},
	journal={arXiv preprint arXiv:2003.02389},
	year={2020}
}

@article{ren2015faster,
	title={Faster r-cnn: Towards real-time object detection with region proposal networks},
	author={Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
	journal={arXiv preprint arXiv:1506.01497},
	year={2015}
}

@inproceedings{redmon2016you,
	title={You only look once: Unified, real-time object detection},
	author={Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={779--788},
	year={2016}
}

@Inbook{Jolliffe2011,
	author="Jolliffe, Ian",
	editor="Lovric, Miodrag",
	title="Principal Component Analysis",
	bookTitle="International Encyclopedia of Statistical Science",
	year="2011",
	publisher="Springer Berlin Heidelberg",
	address="Berlin, Heidelberg",
	pages="1094--1096",
	isbn="978-3-642-04898-2",
	doi="10.1007/978-3-642-04898-2_455",
	url="https://doi.org/10.1007/978-3-642-04898-2_455"
}

@misc{imagenethierychy,
	title={ImageNet Hierarchy},
	author={Bostock, Mike},
	howpublished={\url{https://observablehq.com/@mbostock/imagenet-hierarchy}}
}

@article{lee2012manifold,
	title={Manifold identification in dual averaging for regularized stochastic online learning},
	author={Lee, Sangkyun and Wright, Stephen J},
	journal={The Journal of Machine Learning Research},
	volume={13},
	number={1},
	pages={1705--1744},
	year={2012},
	publisher={JMLR. org}
}

@inproceedings{li2020eagleeye,
	title={Eagleeye: Fast sub-net evaluation for efficient neural network pruning},
	author={Li, Bailin and Wu, Bowen and Su, Jiang and Wang, Guangrun},
	booktitle={European Conference on Computer Vision},
	pages={639--654},
	year={2020},
	organization={Springer}
}

@CONFERENCE{ThiNet_ICCV17,
	author={Luo, Jianhao and Wu, Jianxin and Lin, Weiyao},
	title={ThiNet: A Filter Level Pruning Method for Deep Neural Network Compression},
	booktitle={ICCV},
	year = {2017},
	pages={5058-5066},
}

@article{rajpurkar2016squad,
	title={Squad: 100,000+ questions for machine comprehension of text},
	author={Rajpurkar, Pranav and Zhang, Jian and Lopyrev, Konstantin and Liang, Percy},
	journal={arXiv preprint arXiv:1606.05250},
	year={2016}
}

@InProceedings{He_2017_ICCV,
	author = {He, Yihui and Zhang, Xiangyu and Sun, Jian},
	title = {Channel Pruning for Accelerating Very Deep Neural Networks},
	booktitle = {The IEEE International Conference on Computer Vision (ICCV)},
	month = {Oct},
	year = {2017}
}

@inproceedings{huang2018data,
	title={Data-driven sparse structure selection for deep neural networks},
	author={Huang, Zehao and Wang, Naiyan},
	booktitle={Proceedings of the European conference on computer vision (ECCV)},
	pages={304--320},
	year={2018}
}


@inproceedings{zhang2018systematic,
	title={A systematic dnn weight pruning framework using alternating direction method of multipliers},
	author={Zhang, Tianyun and Ye, Shaokai and Zhang, Kaiqi and Tang, Jian and Wen, Wujie and Fardad, Makan and Wang, Yanzhi},
	booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
	pages={184--199},
	year={2018}
}

@book{boyd2011distributed,
	title={Distributed optimization and statistical learning via the alternating direction method of multipliers},
	author={Boyd, Stephen and Parikh, Neal and Chu, Eric},
	year={2011},
	publisher={Now Publishers Inc}
}

% joint quantization learning
@InProceedings{Tung_2018_CVPR,
	author = {Tung, Frederick and Mori, Greg},
	title = {CLIP-Q: Deep Network Compression Learning by In-Parallel Pruning-Quantization},
	booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	month = {June},
	year = {2018}
}

@inproceedings{yang2020automatic,
	title={Automatic neural network compression by sparsity-quantization joint learning: A constrained optimization-based approach},
	author={Yang, Haichuan and Gui, Shupeng and Zhu, Yuhao and Liu, Ji},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={2178--2188},
	year={2020}
}

@inproceedings{gao2020highly,
	title={Highly efficient salient object detection with 100k parameters},
	author={Gao, Shang-Hua and Tan, Yong-Qiang and Cheng, Ming-Ming and Lu, Chengze and Chen, Yunpeng and Yan, Shuicheng},
	booktitle={European Conference on Computer Vision},
	pages={702--721},
	year={2020},
	organization={Springer}
}

% structured sparsity
@article{wen2016learning,
	title={Learning structured sparsity in deep neural networks},
	author={Wen, Wei and Wu, Chunpeng and Wang, Yandan and Chen, Yiran and Li, Hai},
	journal={arXiv preprint arXiv:1608.03665},
	year={2016}
}

@inproceedings{li2020group,
	title={Group sparsity: The hinge between filter pruning and decomposition for network compression},
	author={Li, Yawei and Gu, Shuhang and Mayer, Christoph and Gool, Luc Van and Timofte, Radu},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={8018--8027},
	year={2020}
}

@article{zhuang2020neuron,
	title={Neuron-level Structured Pruning using Polarization Regularizer},
	author={Zhuang, Tao and Zhang, Zhixuan and Huang, Yuheng and Zeng, Xiaoyi and Shuang, Kai and Li, Xiang},
	journal={Advances in Neural Information Processing Systems},
	volume={33},
	year={2020}
}

% for bert pruning
@article{deleu2021structured,
	title={Structured Sparsity Inducing Adaptive Optimizers for Deep Learning},
	author={Deleu, Tristan and Bengio, Yoshua},
	journal={arXiv preprint arXiv:2102.03869},
	year={2021}
}

@article{sanh2020movement,
	title={Movement pruning: Adaptive sparsity by fine-tuning},
	author={Sanh, Victor and Wolf, Thomas and Rush, Alexander M},
	journal={arXiv preprint arXiv:2005.07683},
	year={2020}
}

@article{fan2019reducing,
	title={Reducing transformer depth on demand with structured dropout},
	author={Fan, Angela and Grave, Edouard and Joulin, Armand},
	journal={arXiv preprint arXiv:1909.11556},
	year={2019}
}

@article{guo2019reweighted,
	title={Reweighted proximal pruning for large-scale language representation},
	author={Guo, Fu-Ming and Liu, Sijia and Mungall, Finlay S and Lin, Xue and Wang, Yanzhi},
	journal={arXiv preprint arXiv:1909.12486},
	year={2019}
}

@article{gordon2020compressing,
	title={Compressing bert: Studying the effects of weight pruning on transfer learning},
	author={Gordon, Mitchell A and Duh, Kevin and Andrews, Nicholas},
	journal={arXiv preprint arXiv:2002.08307},
	year={2020}
}

@article{vaswani2017attention,
	title={Attention is all you need},
	author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Lukasz and Polosukhin, Illia},
	journal={arXiv preprint arXiv:1706.03762},
	year={2017}
}
@inproceedings{niklaus2017video,
	title={Video frame interpolation via adaptive separable convolution},
	author={Niklaus, Simon and Mai, Long and Liu, Feng},
	booktitle={Proceedings of the IEEE International Conference on Computer Vision},
	pages={261--270},
	year={2017}
}

@inproceedings{bao2019depth,
	title={Depth-aware video frame interpolation},
	author={Bao, Wenbo and Lai, Wei-Sheng and Ma, Chao and Zhang, Xiaoyun and Gao, Zhiyong and Yang, Ming-Hsuan},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={3703--3712},
	year={2019}
}

@article{ding2021cdfi,
	title={CDFI: Compression-Driven Network Design for Frame Interpolation},
	author={Ding, Tianyu and Liang, Luming and Zhu, Zhihui and Zharkov, Ilya},
	journal={arXiv preprint arXiv:2103.10559},
	year={2021}
}

@article{wang2018video,
	title={Video-to-video synthesis},
	author={Wang, Ting-Chun and Liu, Ming-Yu and Zhu, Jun-Yan and Liu, Guilin and Tao, Andrew and Kautz, Jan and Catanzaro, Bryan},
	journal={arXiv preprint arXiv:1808.06601},
	year={2018}
}

@article{kwatra2003graphcut,
	title={Graphcut textures: Image and video synthesis using graph cuts},
	author={Kwatra, Vivek and Sch{\"o}dl, Arno and Essa, Irfan and Turk, Greg and Bobick, Aaron},
	journal={Acm transactions on graphics (tog)},
	volume={22},
	number={3},
	pages={277--286},
	year={2003},
	publisher={ACM New York, NY, USA}
}

@inproceedings{zhang2018unreasonable,
	title={The unreasonable effectiveness of deep features as a perceptual metric},
	author={Zhang, Richard and Isola, Phillip and Efros, Alexei A and Shechtman, Eli and Wang, Oliver},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={586--595},
	year={2018}
}

@article{fukushima1969visual,
	title={Visual feature extraction by a multilayered network of analog threshold elements},
	author={Fukushima, Kunihiko},
	journal={IEEE Transactions on Systems Science and Cybernetics},
	volume={5},
	number={4},
	pages={322--333},
	year={1969},
	publisher={IEEE}
}

@inproceedings{he2015delving,
	title={Delving deep into rectifiers: Surpassing human-level performance on imagenet classification},
	author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	booktitle={Proceedings of the IEEE international conference on computer vision},
	pages={1026--1034},
	year={2015}
}

@article{hendrycks2016gaussian,
	title={Gaussian error linear units (gelus)},
	author={Hendrycks, Dan and Gimpel, Kevin},
	journal={arXiv preprint arXiv:1606.08415},
	year={2016}
}

@article{xu2015empirical,
	title={Empirical evaluation of rectified activations in convolutional network},
	author={Xu, Bing and Wang, Naiyan and Chen, Tianqi and Li, Mu},
	journal={arXiv preprint arXiv:1505.00853},
	year={2015}
}

@inproceedings{chen2021oto,
	author = {Chen, Tianyi and Ji, Bo and Ding, Tianyu and Fang, Biyi and Wang, Guanyi and Zhu, Zhihui and Liang, Luming and Shi, Yixin and Yi, Sheng and Tu, Xiao},
	booktitle = {Advances in Neural Information Processing Systems},
	title = {Only Train Once: A One-Shot Neural Network Training And Pruning Framework},
	year = {2021}
}

@inproceedings{liu2017learning,
	title={Learning efficient convolutional networks through network slimming},
	author={Liu, Zhuang and Li, Jianguo and Shen, Zhiqiang and Huang, Gao and Yan, Shoumeng and Zhang, Changshui},
	booktitle={Proceedings of the IEEE international conference on computer vision},
	pages={2736--2744},
	year={2017}
}

@inproceedings{zhao2019variational,
	title={Variational convolutional neural network pruning},
	author={Zhao, Chenglong and Ni, Bingbing and Zhang, Jian and Zhao, Qiwei and Zhang, Wenjun and Tian, Qi},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={2780--2789},
	year={2019}
}

@inproceedings{li2022revisiting,
	title={Revisiting Random Channel Pruning for Neural Network Compression},
	author={Li, Yawei and Adamczewski, Kamil and Li, Wen and Gu, Shuhang and Timofte, Radu and Van Gool, Luc},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={191--201},
	year={2022}
}


@InProceedings{pmlr-v162-yu22e,
	title = 	 {Topology-Aware Network Pruning using Multi-stage Graph Embedding and Reinforcement Learning},
	author =       {Yu, Sixing and Mazaheri, Arya and Jannesari, Ali},
	booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
	year = 	 {2022},
}

@article{dichannel2022,
	title={On the Channel Pruning Using Graph Convolution Network for Convolutional Neural Network Acceleration},
	author={Di Jiang, Yuan Cao and Yang, Qiang},
	booktitle = {Proceedings of the International Joint Conference on Automated Reasoning},
	year = {2022},
}

@inproceedings{li2019exploiting,
	title={Exploiting kernel sparsity and entropy for interpretable CNN compression},
	author={Li, Yuchao and Lin, Shaohui and Zhang, Baochang and Liu, Jianzhuang and Doermann, David and Wu, Yongjian and Huang, Feiyue and Ji, Rongrong},
	booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
	pages={2800--2809},
	year={2019}
}

@article{elsken2018efficient,
	title={Efficient multi-objective neural architecture search via lamarckian evolution},
	author={Elsken, Thomas and Metzen, Jan Hendrik and Hutter, Frank},
	journal={arXiv preprint arXiv:1804.09081},
	year={2018}
}

@article{brock2017smash,
	title={Smash: one-shot model architecture search through hypernetworks},
	author={Brock, Andrew and Lim, Theodore and Ritchie, James M and Weston, Nick},
	journal={arXiv preprint arXiv:1708.05344},
	year={2017}
}

@inproceedings{kanter2015deep,
	title={Deep feature synthesis: Towards automating data science endeavors},
	author={Kanter, James Max and Veeramachaneni, Kalyan},
	booktitle={2015 IEEE international conference on data science and advanced analytics (DSAA)},
	pages={1--10},
	year={2015},
	organization={IEEE}
}

@inproceedings{katz2016explorekit,
	title={Explorekit: Automatic feature generation and selection},
	author={Katz, Gilad and Shin, Eui Chul Richard and Song, Dawn},
	booktitle={2016 IEEE 16th International Conference on Data Mining (ICDM)},
	pages={979--984},
	year={2016},
	organization={IEEE}
}

@inproceedings{klein2017fast,
	title={Fast bayesian optimization of machine learning hyperparameters on large datasets},
	author={Klein, Aaron and Falkner, Stefan and Bartels, Simon and Hennig, Philipp and Hutter, Frank},
	booktitle={Artificial intelligence and statistics},
	pages={528--536},
	year={2017},
	organization={PMLR}
}

@inproceedings{huang2017densely,
	title={Densely connected convolutional networks},
	author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={4700--4708},
	year={2017}
}

@inproceedings{ronneberger2015u,
	title={U-net: Convolutional networks for biomedical image segmentation},
	author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
	booktitle={International Conference on Medical image computing and computer-assisted intervention},
	pages={234--241},
	year={2015},
	organization={Springer}
}

@inproceedings{ahn2018fast,
	title={Fast, accurate, and lightweight super-resolution with cascading residual network},
	author={Ahn, Namhyuk and Kang, Byungkon and Sohn, Kyung-Ah},
	booktitle={Proceedings of the European conference on computer vision (ECCV)},
	pages={252--268},
	year={2018}
}

@article{netzer2011reading,
	title={Reading digits in natural images with unsupervised feature learning},
	author={Netzer, Yuval and Wang, Tao and Coates, Adam and Bissacco, Alessandro and Wu, Bo and Ng, Andrew Y},
	year={2011}
}

@article{chen2020neural,
	title={Neural network compression via sparse optimization},
	author={Chen, Tianyi and Ji, Bo and Shi, Yixin and Ding, Tianyu and Fang, Biyi and Yi, Sheng and Tu, Xiao},
	journal={arXiv preprint arXiv:2011.04868},
	year={2020}
}

@inproceedings{hou2022chex,
	title={CHEX: CHannel EXploration for CNN Model Compression},
	author={Hou, Zejiang and Qin, Minghai and Sun, Fei and Ma, Xiaolong and Yuan, Kun and Xu, Yi and Chen, Yen-Kuang and Jin, Rong and Xie, Yuan and Kung, Sun-Yuan},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={12287--12298},
	year={2022}
}

@article{kingma2014adam,
	title={Adam: A method for stochastic optimization},
	author={Kingma, Diederik P and Ba, Jimmy},
	journal={arXiv preprint arXiv:1412.6980},
	year={2014}
}

@inproceedings{miao2021learning,
	title={Learning Pruning-Friendly Networks via Frank-Wolfe: One-Shot, Any-Sparsity, And No Retraining},
	author={Miao, Lu and Luo, Xiaolong and Chen, Tianlong and Chen, Wuyang and Liu, Dong and Wang, Zhangyang},
	booktitle={International Conference on Learning Representations},
	year={2021}
}


@incollection{torch2019nips,
	title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
	author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
	booktitle = {Advances in Neural Information Processing Systems 32},
	year = {2019},
}

@misc{bai2019,
	author = {Bai, Junjie and Lu, Fang and Zhang, Ke and others},
	title = {ONNX: Open Neural Network Exchange},
	year = {2019},
	publisher = {GitHub},
	journal = {GitHub repository},
	howpublished = {\url{https://github.com/onnx/onnx}},
	commit = {94d238d96e3fb3a7ba34f03c284b9ad3516163be}
}

@misc{onnx2torch2022,
	author = {Arseny},
	title = {ONNX2Torch: an ONNX to PyTorch converter.},
	year = {2022},
	publisher = {GitHub},
	journal = {GitHub repository},
	howpublished = {\url{https://github.com/ENOT-AutoDL/onnx2torch}},
}

@article{chen2020half,
	title={Half-space proximal stochastic gradient method for group-sparsity regularized problem},
	author={Chen, Tianyi and Wang, Guanyi and Ding, Tianyu and Ji, Bo and Yi, Sheng and Zhu, Zhihui},
	journal={arXiv preprint arXiv:2009.12078},
	year={2020}
}

@inproceedings{agustsson2017ntire,
	title={Ntire 2017 challenge on single image super-resolution: Dataset and study},
	author={Agustsson, Eirikur and Timofte, Radu},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition workshops},
	year={2017}
}

@inproceedings{oh2022attentive,
	title={Attentive Fine-Grained Structured Sparsity for Image Restoration},
	author={Oh, Junghun and Kim, Heewon and Nah, Seungjun and Hong, Cheeun and Choi, Jonghyun and Lee, Kyoung Mu},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={17673--17682},
	year={2022}
}

@inproceedings{zeyde2010single,
	title={On single image scale-up using sparse-representations},
	author={Zeyde, Roman and Elad, Michael and Protter, Matan},
	booktitle={International conference on curves and surfaces},
	year={2010},
	organization={Springer}
}

@inproceedings{martin2001database,
	title={A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics},
	author={Martin, David and Fowlkes, Charless and Tal, Doron and Malik, Jitendra},
	booktitle={Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001},
	volume={2},
	pages={416--423},
	year={2001},
	organization={IEEE}
}

@inproceedings{huang2015single,
	title={Single image super-resolution from transformed self-exemplars},
	author={Huang, Jia-Bin and Singh, Abhishek and Ahuja, Narendra},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	year={2015}
}

@inproceedings{radosavovic2020designing,
	title={Designing network design spaces},
	author={Radosavovic, Ilija and Kosaraju, Raj Prateek and Girshick, Ross and He, Kaiming and Doll{\'a}r, Piotr},
	booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
	pages={10428--10436},
	year={2020}
}

@inproceedings{liu2022convnet,
	title={A convnet for the 2020s},
	author={Liu, Zhuang and Mao, Hanzi and Wu, Chao-Yuan and Feichtenhofer, Christoph and Darrell, Trevor and Xie, Saining},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={11976--11986},
	year={2022}
}

@misc{rw2019timm,
	author = {Ross Wightman},
	title = {PyTorch Image Models},
	year = {2019},
	publisher = {GitHub},
	journal = {GitHub repository},
	doi = {10.5281/zenodo.4414861},
	howpublished = {\url{https://github.com/rwightman/pytorch-image-models}}
}

@inproceedings{chen2021orthant,
	title={Orthant Based Proximal Stochastic Gradient Method for ℓ \_1 ℓ 1-Regularized Optimization},
	author={Chen, Tianyi and Ding, Tianyu and Ji, Bo and Wang, Guanyi and Shi, Yixin and Tian, Jing and Yi, Sheng and Tu, Xiao and Zhu, Zhihui},
	booktitle={Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2020, Ghent, Belgium, September 14--18, 2020, Proceedings, Part III},
	pages={57--73},
	year={2021},
	organization={Springer}
}

@article{chen2017reduced,
	title={A reduced-space algorithm for minimizing $\backslash$ell\_1-regularized convex functions},
	author={Chen, Tianyi and Curtis, Frank E and Robinson, Daniel P},
	journal={SIAM Journal on Optimization},
	volume={27},
	number={3},
	pages={1583--1610},
	year={2017},
	publisher={SIAM}
}

@article{lepikhin2020gshard,
	title={Gshard: Scaling giant models with conditional computation and automatic sharding},
	author={Lepikhin, Dmitry and Lee, HyoukJoong and Xu, Yuanzhong and Chen, Dehao and Firat, Orhan and Huang, Yanping and Krikun, Maxim and Shazeer, Noam and Chen, Zhifeng},
	journal={arXiv preprint arXiv:2006.16668},
	year={2020}
}

@article{fedus2022switch,
	title={Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity},
	author={Fedus, William and Zoph, Barret and Shazeer, Noam},
	journal={Journal of Machine Learning Research},
	volume={23},
	number={120},
	pages={1--39},
	year={2022}
}

@article{alizadeh2023llm,
	title={LLM in a flash: Efficient large language model inference with limited memory},
	author={Alizadeh, Keivan and Mirzadeh, Iman and Belenko, Dmitry and Khatamifard, Karen and Cho, Minsik and Del Mundo, Carlo C and Rastegari, Mohammad and Farajtabar, Mehrdad},
	journal={arXiv preprint arXiv:2312.11514},
	year={2023}
}

@article{ji2022fscnn,
	title={FSCNN: A Fast Sparse Convolution Neural Network Inference System},
	author={Ji, Bo and Chen, Tianyi},
	journal={arXiv preprint arXiv:2212.08815},
	year={2022}
}

@article{chen2023otov3,
	title={OTOv3: Automatic Architecture-Agnostic Neural Network Training and Compression from Structured Pruning to Erasing Operators},
	author={Chen, Tianyi and Ding, Tianyu and Zhu, Zhihui and Chen, Zeyu and Wu, HsiangTao and Zharkov, Ilya and Liang, Luming},
	journal={arXiv preprint arXiv:2312.09411},
	year={2023}
}

@article{zuo2022moebert,
	title={Moebert: from bert to mixture-of-experts via importance-guided adaptation},
	author={Zuo, Simiao and Zhang, Qingru and Liang, Chen and He, Pengcheng and Zhao, Tuo and Chen, Weizhu},
	journal={arXiv preprint arXiv:2204.07675},
	year={2022}
}

@article{wang2024q,
	title={Q-Sparse: All Large Language Models can be Fully Sparsely-Activated},
	author={Wang, Hongyu and Ma, Shuming and Wang, Ruiping and Wei, Furu},
	journal={arXiv preprint arXiv:2407.10969},
	year={2024}
}

@phdthesis{chen2018fast,
	title={A Fast Reduced-Space Algorithmic Framework for Sparse Optimization},
	author={Chen, Tianyi},
	year={2018},
	school={Johns Hopkins University}
}

@article{chen2018farsa,
	title={FaRSA for ℓ1-regularized convex optimization: local convergence and numerical experience},
	author={Chen, Tianyi and Curtis, Frank E and Robinson, Daniel P},
	journal={Optimization Methods and Software},
	volume={33},
	number={2},
	pages={396--415},
	year={2018},
	publisher={Taylor \& Francis}
}

@misc{yolov5,
	author = {Jocher, Glenn},
	title = {ultralytics/yolov5: v7.0 - YOLOv5 SOTA Realtime Instance Segmentation.},
	year = {2022},
	publisher = {GitHub},
	journal = {GitHub repository},
	howpublished = {\url{https://github.com/ultralytics/yolov5}},
}

@article{yang2024qwen2,
	title={Qwen2. 5 technical report},
	author={Yang, An and Yang, Baosong and Zhang, Beichen and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and Wei, Haoran and others},
	journal={arXiv preprint arXiv:2412.15115},
	year={2024}
}

@article{qu2025automatic,
	title={Automatic Joint Structured Pruning and Quantization for Efficient Neural Network Training and Compression},
	author={Qu, Xiaoyi and Aponte, David and Banbury, Colby and Robinson, Daniel P and Ding, Tianyu and Koishida, Kazuhito and Zharkov, Ilya and Chen, Tianyi},
	journal={arXiv preprint arXiv:2502.16638},
	year={2025}
}
