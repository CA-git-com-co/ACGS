% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% %             Related Work              %
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Related Work}\label{sec:related_work}
Our work builds on three pillars of modern AI safety and governance research: policy-as-code frameworks for technical operationalization, constitutional AI approaches for value alignment, and runtime enforcement systems for agent safety. \acgs{} synthesizes these domains to address a critical gap: the transition from static governance mechanisms to dynamic, co-evolutionary systems that adapt alongside the AI systems they govern.

\subsection{AI Governance and Policy-as-Code}
High-level AI governance frameworks, such as the NIST AI Risk Management Framework~\cite{nist2023ai} and ISO/IEC~42001~\cite{iso42001}, provide essential organizational guidance but lack mechanisms for technical operationalization. Policy-as-Code (PaC) paradigms, exemplified by Open Policy Agent (OPA)~\cite{opa2023} and its policy language Rego~\cite{rego2019}, bridge part of this gap by enabling executable governance rules. However, PaC systems traditionally rely on manually authored rules, creating a bottleneck that inhibits rapid adaptation to evolving AI behaviors. \acgs{} advances this foundation by automating rule generation from high-level constitutional principles, enabling governance systems to evolve at machine speed rather than human timescales.

\subsection{Constitutional AI and Value Alignment}
Anthropic's Constitutional AI~(CAI) pioneered using explicit principles to guide LLM behavior during training~\cite{anthropic2022constitutional}, demonstrating the power of constitutional approaches to AI alignment. While impactful, this approach embeds principles statically during training, limiting adaptability to new contexts or evolving values post-deployment. Value alignment research~\cite{russell2019human} often lacks mechanisms for explicit value representation and real-time verification. \acgs{} extends CAI's constitutional foundation by implementing a dynamic, runtime system where principles are continuously interpreted, operationalized into executable policies, and adapted based on system feedbackâ€”enabling constitutional governance that evolves with both AI capabilities and human values.

\subsection{LLM-driven Policy and Code Synthesis}
Recent work demonstrates the potential of LLMs to translate natural language into structured code and policies~\cite{propertygpt2023, veriplan2023}. However, challenges such as semantic inaccuracy and hallucination persist. We address these through a multi-stage validation pipeline that integrates syntactic checks, semantic alignment scoring, formal verification for critical rules, and human-in-the-loop oversight.

\subsection{Runtime Enforcement for LLM\allowbreak~Agents}
Frameworks like AgentSpec~\cite{agentspec2023} and Progent~\cite{progent2023} provide runtime safety constraints for LLM~agents, demonstrating the feasibility of real-time governance enforcement. These systems excel at preventing harmful behaviors but depend on static, manually crafted rule sets that cannot adapt to novel scenarios or emergent behaviors. The PGC component of \acgs{} draws inspiration from these runtime guards but uniquely integrates enforcement with an adaptive, constitutionally-grounded rule synthesis engine, enabling governance that responds to new challenges while maintaining constitutional consistency.

\subsection{Governance of Evolutionary Computation}
The governance of EC systems is a nascent field. While some research explores synergies between LLMs and EC, it typically focuses on using LLMs to enhance evolutionary operators. \acgs{} is distinct in establishing a co-evolutionary loop where the governance framework itself evolves in response to the emergent behaviors of the EC system, creating a system of checks and balances that adapts at machine speed.
