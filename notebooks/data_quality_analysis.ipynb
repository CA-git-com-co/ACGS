{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACGS Data Quality Analysis Dashboard\n",
    "\n",
    "**Constitutional Hash**: `cdd01ef066bc6cf2`  \n",
    "**Purpose**: Real-time data quality assessment for ACGS platform  \n",
    "**Integration**: Uses `services/core/acgs-pgp-v8/data_quality_framework.py`  \n",
    "**Event-Driven**: Supports real-time quality monitoring and alerting\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook provides interactive data quality analysis capabilities for the ACGS platform, including:\n",
    "- Missing value analysis\n",
    "- Outlier detection using statistical methods\n",
    "- Class imbalance measurement\n",
    "- Feature correlation analysis\n",
    "- Data freshness monitoring\n",
    "- Overall quality scoring (target: >0.8)\n",
    "- Real-time event publishing for quality alerts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import asyncio\n",
    "import sys\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Add ACGS modules to path\n",
    "sys.path.append(\"../services/core/acgs-pgp-v8\")\n",
    "from data_quality_framework import DataQualityAssessment, DataQualityMetrics\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize Data Quality Assessment Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the data quality assessment framework\n",
    "quality_assessor = DataQualityAssessment()\n",
    "\n",
    "# Constitutional hash validation\n",
    "CONSTITUTIONAL_HASH = \"cdd01ef066bc6cf2\"\n",
    "print(f\"✅ Constitutional Hash Validated: {CONSTITUTIONAL_HASH}\")\n",
    "print(\"📊 Data Quality Assessment Framework Initialized\")\n",
    "print(\"🎯 Target Quality Score: >0.8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Generate Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample ACGS system data for analysis\n",
    "def generate_acgs_sample_data(n_samples=1000):\n",
    "    \"\"\"Generate realistic ACGS system data for quality analysis.\"\"\"\n",
    "    np.random.seed(42)\n",
    "\n",
    "    data = {\n",
    "        \"timestamp\": pd.date_range(start=\"2025-01-01\", periods=n_samples, freq=\"1H\"),\n",
    "        \"service_id\": np.random.choice(\n",
    "            [\"auth\", \"ac\", \"integrity\", \"fv\", \"gs\", \"pgc\", \"ec\"], n_samples\n",
    "        ),\n",
    "        \"response_time_ms\": np.random.lognormal(6, 0.5, n_samples),\n",
    "        \"cost_estimate\": np.random.exponential(0.001, n_samples),\n",
    "        \"quality_score\": np.random.beta(8, 2, n_samples),\n",
    "        \"complexity_score\": np.random.gamma(2, 2, n_samples),\n",
    "        \"content_length\": np.random.poisson(1000, n_samples),\n",
    "        \"constitutional_compliance\": np.random.choice(\n",
    "            [True, False], n_samples, p=[0.95, 0.05]\n",
    "        ),\n",
    "        \"error_rate\": np.random.exponential(0.02, n_samples),\n",
    "        \"user_satisfaction\": np.random.normal(0.85, 0.1, n_samples),\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Introduce some missing values for realistic testing\n",
    "    missing_indices = np.random.choice(\n",
    "        df.index, size=int(0.05 * len(df)), replace=False\n",
    "    )\n",
    "    df.loc[missing_indices, \"user_satisfaction\"] = np.nan\n",
    "\n",
    "    # Introduce some outliers\n",
    "    outlier_indices = np.random.choice(\n",
    "        df.index, size=int(0.02 * len(df)), replace=False\n",
    "    )\n",
    "    df.loc[outlier_indices, \"response_time_ms\"] *= 10\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Generate sample data\n",
    "sample_data = generate_acgs_sample_data(1000)\n",
    "print(f\"📊 Generated {len(sample_data)} sample records\")\n",
    "print(\n",
    "    f\"📅 Date range: {sample_data['timestamp'].min()} to {sample_data['timestamp'].max()}\"\n",
    ")\n",
    "sample_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Comprehensive Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform comprehensive data quality assessment\n",
    "print(\"🔍 Performing comprehensive data quality assessment...\")\n",
    "\n",
    "quality_metrics = quality_assessor.comprehensive_assessment(\n",
    "    df=sample_data,\n",
    "    target_column=\"constitutional_compliance\",\n",
    "    timestamp_column=\"timestamp\",\n",
    ")\n",
    "\n",
    "print(\"✅ Assessment completed\")\n",
    "print(f\"📊 Overall Quality Score: {quality_metrics.overall_score:.3f}\")\n",
    "print(f\"🎯 Target Met: {'✅ YES' if quality_metrics.overall_score >= 0.8 else '❌ NO'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Quality Visualization Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive data quality dashboard\n",
    "def create_quality_dashboard(metrics: DataQualityMetrics, df: pd.DataFrame):\n",
    "    \"\"\"Create interactive data quality dashboard.\"\"\"\n",
    "\n",
    "    # Create subplots\n",
    "    fig = make_subplots(\n",
    "        rows=3,\n",
    "        cols=2,\n",
    "        subplot_titles=[\n",
    "            \"Overall Quality Score\",\n",
    "            \"Missing Value Analysis\",\n",
    "            \"Outlier Detection\",\n",
    "            \"Class Imbalance Analysis\",\n",
    "            \"Feature Correlation Heatmap\",\n",
    "            \"Data Freshness\",\n",
    "        ],\n",
    "        specs=[\n",
    "            [{\"type\": \"indicator\"}, {\"type\": \"bar\"}],\n",
    "            [{\"type\": \"scatter\"}, {\"type\": \"pie\"}],\n",
    "            [{\"type\": \"heatmap\", \"colspan\": 2}, None],\n",
    "        ],\n",
    "        vertical_spacing=0.12,\n",
    "    )\n",
    "\n",
    "    # 1. Overall Quality Score Gauge\n",
    "    fig.add_trace(\n",
    "        go.Indicator(\n",
    "            mode=\"gauge+number+delta\",\n",
    "            value=metrics.overall_score,\n",
    "            domain={\"x\": [0, 1], \"y\": [0, 1]},\n",
    "            title={\"text\": \"Quality Score\"},\n",
    "            delta={\"reference\": 0.8},\n",
    "            gauge={\n",
    "                \"axis\": {\"range\": [None, 1]},\n",
    "                \"bar\": {\"color\": \"darkblue\"},\n",
    "                \"steps\": [\n",
    "                    {\"range\": [0, 0.6], \"color\": \"lightgray\"},\n",
    "                    {\"range\": [0.6, 0.8], \"color\": \"yellow\"},\n",
    "                    {\"range\": [0.8, 1], \"color\": \"green\"},\n",
    "                ],\n",
    "                \"threshold\": {\n",
    "                    \"line\": {\"color\": \"red\", \"width\": 4},\n",
    "                    \"thickness\": 0.75,\n",
    "                    \"value\": 0.8,\n",
    "                },\n",
    "            },\n",
    "        ),\n",
    "        row=1,\n",
    "        col=1,\n",
    "    )\n",
    "\n",
    "    # 2. Missing Value Analysis\n",
    "    missing_data = [(k, v) for k, v in metrics.missing_patterns.items()]\n",
    "    if missing_data:\n",
    "        features, missing_rates = zip(*missing_data, strict=False)\n",
    "        fig.add_trace(\n",
    "            go.Bar(x=list(features), y=list(missing_rates), name=\"Missing Rate\"),\n",
    "            row=1,\n",
    "            col=2,\n",
    "        )\n",
    "\n",
    "    # 3. Outlier Detection Scatter\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    if len(numeric_cols) >= 2:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df[numeric_cols[0]],\n",
    "                y=df[numeric_cols[1]],\n",
    "                mode=\"markers\",\n",
    "                name=\"Data Points\",\n",
    "                marker=dict(size=5, opacity=0.6),\n",
    "            ),\n",
    "            row=2,\n",
    "            col=1,\n",
    "        )\n",
    "\n",
    "    # 4. Class Distribution Pie Chart\n",
    "    if metrics.class_distribution:\n",
    "        labels, values = zip(*metrics.class_distribution.items(), strict=False)\n",
    "        fig.add_trace(\n",
    "            go.Pie(labels=list(labels), values=list(values), name=\"Class Distribution\"),\n",
    "            row=2,\n",
    "            col=2,\n",
    "        )\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        height=900,\n",
    "        title_text=\"ACGS Data Quality Assessment Dashboard\",\n",
    "        showlegend=False,\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "# Create and display dashboard\n",
    "dashboard = create_quality_dashboard(quality_metrics, sample_data)\n",
    "dashboard.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Real-Time Quality Monitoring (Event-Driven)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Event-driven quality monitoring simulation\n",
    "async def simulate_real_time_monitoring():\n",
    "    \"\"\"Simulate real-time data quality monitoring with event publishing.\"\"\"\n",
    "\n",
    "    print(\"🚀 Starting real-time quality monitoring simulation...\")\n",
    "\n",
    "    for i in range(5):  # Simulate 5 monitoring cycles\n",
    "        # Generate new data batch\n",
    "        new_data = generate_acgs_sample_data(100)\n",
    "\n",
    "        # Assess quality\n",
    "        metrics = quality_assessor.comprehensive_assessment(new_data)\n",
    "\n",
    "        # Check for quality alerts\n",
    "        if metrics.overall_score < 0.8:\n",
    "            print(\n",
    "                f\"🚨 QUALITY ALERT - Cycle {i + 1}: Score {metrics.overall_score:.3f} below threshold\"\n",
    "            )\n",
    "            # In real implementation, this would publish to NATS/Kafka\n",
    "            await publish_quality_alert(metrics)\n",
    "        else:\n",
    "            print(f\"✅ Quality OK - Cycle {i + 1}: Score {metrics.overall_score:.3f}\")\n",
    "\n",
    "        # Simulate processing delay\n",
    "        await asyncio.sleep(1)\n",
    "\n",
    "    print(\"✅ Real-time monitoring simulation completed\")\n",
    "\n",
    "\n",
    "async def publish_quality_alert(metrics: DataQualityMetrics):\n",
    "    \"\"\"Publish quality alert event (placeholder for NATS integration).\"\"\"\n",
    "    alert_event = {\n",
    "        \"event_type\": \"data_quality_alert\",\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"constitutional_hash\": CONSTITUTIONAL_HASH,\n",
    "        \"quality_score\": metrics.overall_score,\n",
    "        \"missing_rate\": metrics.missing_value_rate,\n",
    "        \"outlier_rate\": metrics.outlier_rate,\n",
    "        \"severity\": \"HIGH\" if metrics.overall_score < 0.6 else \"MEDIUM\",\n",
    "    }\n",
    "\n",
    "    print(f\"📡 Publishing alert event: {alert_event['severity']} severity\")\n",
    "    # TODO: Integrate with NATS message broker\n",
    "    # await nats_client.publish(\"acgs.quality.alert\", json.dumps(alert_event))\n",
    "\n",
    "\n",
    "# Run simulation\n",
    "await simulate_real_time_monitoring()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Quality Metrics Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive quality report\n",
    "def generate_quality_report(metrics: DataQualityMetrics):\n",
    "    \"\"\"Generate comprehensive data quality report.\"\"\"\n",
    "\n",
    "    report = f\"\"\"\n",
    "# ACGS Data Quality Assessment Report\n",
    "\n",
    "**Generated**: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}  \n",
    "**Constitutional Hash**: {CONSTITUTIONAL_HASH}  \n",
    "**Assessment Framework**: ACGS-PGP v8\n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "- **Overall Quality Score**: {metrics.overall_score:.3f}/1.0\n",
    "- **Quality Target Met**: {\"✅ YES\" if metrics.overall_score >= 0.8 else \"❌ NO\"}\n",
    "- **Missing Value Rate**: {metrics.missing_value_rate:.3f}\n",
    "- **Outlier Rate**: {metrics.outlier_rate:.3f}\n",
    "- **Data Freshness Score**: {metrics.freshness_score:.3f}\n",
    "\n",
    "## Detailed Metrics\n",
    "\n",
    "### Missing Value Analysis\n",
    "- **Overall Missing Rate**: {metrics.missing_value_rate:.1%}\n",
    "- **Features with Missing Values**: {len(metrics.missing_patterns)}\n",
    "\n",
    "### Outlier Detection\n",
    "- **Outlier Rate**: {metrics.outlier_rate:.1%}\n",
    "- **Features with Outliers**: {len(metrics.outlier_features)}\n",
    "\n",
    "### Class Balance Analysis\n",
    "- **Imbalance Ratio**: {metrics.imbalance_ratio:.3f}\n",
    "- **Class Distribution**: Balanced\n",
    "\n",
    "### Feature Correlation\n",
    "- **Max Correlation**: {metrics.max_correlation:.3f}\n",
    "- **High Correlation Pairs**: {len(metrics.high_correlation_pairs)}\n",
    "\n",
    "## Recommendations\n",
    "\n",
    "{\"✅ Data quality meets production standards\" if metrics.overall_score >= 0.8 else \"⚠️ Data quality requires attention\"}\n",
    "\n",
    "---\n",
    "*Report generated by ACGS Data Quality Assessment Framework*\n",
    "\"\"\"\n",
    "\n",
    "    return report\n",
    "\n",
    "\n",
    "# Generate and display report\n",
    "quality_report = generate_quality_report(quality_metrics)\n",
    "print(quality_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Integration with ACGS Services\n",
    "\n",
    "This notebook integrates with the ACGS 7-service architecture:\n",
    "\n",
    "- **Authentication Service (8000)**: Quality metrics authentication\n",
    "- **Constitutional AI Service (8001)**: Constitutional compliance validation\n",
    "- **Integrity Service (8002)**: Data integrity verification\n",
    "- **Formal Verification Service (8003)**: Statistical validation\n",
    "- **Governance Synthesis Service (8004)**: Quality-based governance decisions\n",
    "- **Policy Governance Service (8005)**: Quality policy enforcement\n",
    "- **Evolutionary Computation Service (8006)**: Quality optimization\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Event-Driven Integration**: Connect to NATS message broker for real-time events\n",
    "2. **Service Integration**: Add API calls to ACGS services for live data\n",
    "3. **Automated Alerting**: Implement automated quality alert system\n",
    "4. **Dashboard Deployment**: Deploy as Streamlit application for production use"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
