# Constitutional Hash: cdd01ef066bc6cf2
name: ACGS-1 Unified Modern CI/CD Pipeline

on:
  push:
    branches: [main, master, develop, 'feature/*', 'hotfix/*']
  pull_request:
    branches: [main, master, develop]
  schedule:
    - cron: '0 2 * * 1' # Weekly on Monday at 2 AM
  workflow_dispatch:
    inputs:
      environment:
        description: 'Target environment for deployment'
        required: false
        default: 'development'
        type: choice
        options:
          - development
          - staging
          - production
      skip_tests:
        description: 'Skip test execution (emergency deployments only)'
        required: false
        default: false
        type: boolean

permissions:
  contents: read
  packages: write
  security-events: write
  actions: read
  id-token: write
  deployments: write

env:
  # Core versions and configuration
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}
  SOLANA_CLI_VERSION: 1.18.22
  ANCHOR_CLI_VERSION: 0.29.0
  NODE_VERSION: '20'
  PYTHON_VERSION: '3.11'
  RUST_TOOLCHAIN: '1.81.0'
  
  # UV Package Manager Configuration
  UV_CACHE_DIR: /tmp/.uv-cache
  UV_PYTHON: python${{ vars.PYTHON_VERSION || '3.11' }}
  
  # Performance and reliability settings
  ENTERPRISE_BUILD_TARGET_MINUTES: 8
  ENTERPRISE_AVAILABILITY_TARGET: 99.9
  MAX_RETRY_ATTEMPTS: 3
  CIRCUIT_BREAKER_TIMEOUT: 300
  
  # Cargo optimization settings
  CARGO_INCREMENTAL: 0
  CARGO_NET_RETRY: 10
  CARGO_NET_GIT_FETCH_WITH_CLI: true
  CARGO_TARGET_DIR: blockchain/target
  RUSTC_WRAPPER: sccache
  
  # Security and compliance
  SECURITY_SCAN_ENABLED: true
  COVERAGE_THRESHOLD: 80
  COVERAGE_TARGET: 90

jobs:
  # Fast preliminary checks and setup validation
  preflight:
    name: Preflight & Change Detection
    runs-on: ubuntu-latest
    timeout-minutes: 5
    outputs:
      should_run_tests: ${{ steps.changes.outputs.should_run }}
      rust_changed: ${{ steps.changes.outputs.rust_changed }}
      python_changed: ${{ steps.changes.outputs.python_changed }}
      typescript_changed: ${{ steps.changes.outputs.typescript_changed }}
      docs_only: ${{ steps.changes.outputs.docs_only }}
      target_environment: ${{ stepsconfig/environments/development.environment.outputsconfig/environments/development.environment }}
      should_deploy: ${{ stepsconfig/environments/development.environment.outputs.should_deploy }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Detect changed files
        id: changes
        uses: tj-actions/changed-files@v46
        with:
          files_yaml: |
            rust:
              - 'blockchain/**'
              - '**/*.rs'
              - '**/Cargo.toml'
              - '**/Cargo.lock'
              - 'quantumagi_core/**'
            python:
              - 'services/**'
              - 'scripts/**'
              - '**/*.py'
              - '**/config/environments/requirements*.txt'
              - 'config/environments/pyproject.toml'
            typescript:
              - '**/*.ts'
              - '**/*.js'
              - '**/package.json'
              - '**/tsconfig.json'
            docs:
              - 'docs/**'
              - '**/*.md'
              - '*.md'

      - name: Determine execution scope
        run: |
          echo "should_run=true" >> $GITHUB_OUTPUT
          echo "docs_only=false" >> $GITHUB_OUTPUT
          
          if [ "${{ github.event_name }}" == "schedule" ]; then
            echo "Scheduled run - executing all tests"
            echo "rust_changed=true" >> $GITHUB_OUTPUT
            echo "python_changed=true" >> $GITHUB_OUTPUT
            echo "typescript_changed=true" >> $GITHUB_OUTPUT
          elif [ "${{ steps.changes.outputs.docs_changed }}" == "true" ] && \
               [ "${{ steps.changes.outputs.rust_changed }}" == "false" ] && \
               [ "${{ steps.changes.outputs.python_changed }}" == "false" ] && \
               [ "${{ steps.changes.outputs.typescript_changed }}" == "false" ]; then
            echo "Documentation-only changes detected"
            echo "docs_only=true" >> $GITHUB_OUTPUT
            echo "should_run=false" >> $GITHUB_OUTPUT
          else
            echo "Code changes detected - running relevant tests"
            echo "rust_changed=${{ steps.changes.outputs.rust_changed }}" >> $GITHUB_OUTPUT
            echo "python_changed=${{ steps.changes.outputs.python_changed }}" >> $GITHUB_OUTPUT
            echo "typescript_changed=${{ steps.changes.outputs.typescript_changed }}" >> $GITHUB_OUTPUT
          fi

      - name: Environment detection
        id: environment
        run: |
          ENVIRONMENT="${{ github.event.inputs.environment || 'auto' }}"
          SHOULD_DEPLOY="false"
          
          if [ "$ENVIRONMENT" = "auto" ]; then
            case "${{ github.ref }}" in
              "refs/heads/main"|"refs/heads/master")
                ENVIRONMENT="production"
                SHOULD_DEPLOY="true"
                ;;
              "refs/heads/develop")
                ENVIRONMENT="staging"
                SHOULD_DEPLOY="true"
                ;;
              "refs/heads/feature/"*|"refs/heads/hotfix/"*)
                ENVIRONMENT="development"
                SHOULD_DEPLOY="true"
                ;;
            esac
          else
            SHOULD_DEPLOY="true"
          fi
          
          echo "environment=$ENVIRONMENT" >> $GITHUB_OUTPUT
          echo "should_deploy=$SHOULD_DEPLOY" >> $GITHUB_OUTPUT

  # Unified quality gates with parallel execution
  quality-gates:
    name: Quality Gates & Security
    runs-on: ubuntu-latest
    needs: preflight
    if: needs.preflight.outputs.should_run_tests == 'true'
    timeout-minutes: 25
    outputs:
      quality_passed: ${{ steps.quality.outputs.passed }}
      security_passed: ${{ steps.security.outputs.passed }}
      coverage_score: ${{ steps.coverage.outputs.score }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python with UV
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install UV package manager
        uses: astral-sh/setup-uv@v6
        with:
          enable-cache: true
          cache-dependency-glob: "**/config/environments/requirements*.txt"

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: '**/package-lock.json'

      - name: Install dependencies
        timeout-minutes: 8
        continue-on-error: false
        run: |
          echo "Installing dependencies with UV..."
          
          # Create virtual environment with retry logic
          for attempt in 1 2 3; do
            if uv venv --python ${{ env.PYTHON_VERSION }}; then
              echo "‚úÖ Virtual environment created successfully"
              break
            elif [ $attempt -eq 3 ]; then
              echo "‚ùå Failed to create virtual environment after 3 attempts"
              exit 1
            else
              echo "‚ö†Ô∏è Virtual environment creation failed, retrying..."
              sleep 5
            fi
          done
          
          source .venv/bin/activate
          
          # Install project and dev dependencies with fallback
          INSTALL_SUCCESS=false
          if [ -f "config/environments/pyproject.toml" ]; then
            echo "Installing from config/environments/pyproject.toml..."
            if uv pip install -e .[dev,test] --index-strategy unsafe-best-match; then
              INSTALL_SUCCESS=true
            elif uv pip install -e . --index-strategy unsafe-best-match; then
              echo "‚ö†Ô∏è Dev dependencies failed, installed core only"
              INSTALL_SUCCESS=true
            fi
          elif [ -f "config/environments/requirements.txt" ]; then
            echo "Installing from config/environments/requirements.txt..."
            if uv pip install -r config/environments/requirements.txt --index-strategy unsafe-best-match; then
              INSTALL_SUCCESS=true
            fi
          fi
          
          # Fallback to pip if UV fails
          if [ "$INSTALL_SUCCESS" = "false" ]; then
            echo "‚ö†Ô∏è UV installation failed, falling back to pip..."
            if [ -f "config/environments/pyproject.toml" ]; then
              pip install -e .[dev,test] || pip install -e .
            elif [ -f "config/environments/requirements.txt" ]; then
              pip install -r config/environments/requirements.txt
            fi
          fi
          
          # Install quality and security tools with individual error handling
          echo "Installing quality and security tools..."
          uv pip install ruff black mypy bandit safety pytest-cov semgrep pip-audit || {
            echo "‚ö†Ô∏è Some tools failed to install, trying individually..."
            uv pip install ruff || echo "ruff install failed"
            uv pip install black || echo "black install failed"
            uv pip install mypy || echo "mypy install failed"
            uv pip install bandit || echo "bandit install failed"
            uv pip install safety || echo "safety install failed"
            uv pip install pytest-cov || echo "pytest-cov install failed"
            uv pip install semgrep || echo "semgrep install failed"
            uv pip install pip-audit || echo "pip-audit install failed"
          }

      - name: Code quality validation
        id: quality
        timeout-minutes: 10
        run: |
          echo "üîç Running comprehensive code quality checks..."
          source .venv/bin/activate
          
          # Format checking
          ruff format --check . || QUALITY_FAILED=true
          black --check . || QUALITY_FAILED=true
          
          # Linting
          ruff check . || QUALITY_FAILED=true
          
          # Type checking
          mypy services/ scripts/ --ignore-missing-imports || QUALITY_FAILED=true
          
          if [ "$QUALITY_FAILED" = "true" ]; then
            echo "‚ùå Code quality checks failed"
            echo "passed=false" >> $GITHUB_OUTPUT
            exit 1
          else
            echo "‚úÖ Code quality checks passed"
            echo "passed=true" >> $GITHUB_OUTPUT
          fi

      - name: Security scanning
        id: security
        timeout-minutes: 10
        run: |
          echo "üîí Running comprehensive security scans..."
          source .venv/bin/activate
          
          SECURITY_FAILED=false
          CRITICAL_ISSUES=false
          
          # Static security analysis with Bandit
          echo "Running Bandit static security analysis..."
          if command -v bandit >/dev/null 2>&1; then
            if bandit -r services/ scripts/ -f json -o bandit-report.json -ll; then
              echo "‚úÖ Bandit scan passed"
            else
              echo "‚ö†Ô∏è Bandit found security issues"
              SECURITY_FAILED=true
              # Check for critical severity issues
              if bandit -r services/ scripts/ -ll --severity-level high 2>/dev/null | grep -i "high"; then
                CRITICAL_ISSUES=true
              fi
            fi
          else
            echo "‚ö†Ô∏è Bandit not available, skipping static analysis"
          fi
          
          # Dependency vulnerability scanning with Safety
          echo "Running Safety dependency vulnerability scan..."
          if command -v safety >/dev/null 2>&1; then
            if safety check --json --output safety-report.json; then
              echo "‚úÖ Safety scan passed"
            else
              echo "‚ö†Ô∏è Safety found vulnerable dependencies"
              SECURITY_FAILED=true
              # Check for critical vulnerabilities
              if safety check --severity critical,high 2>/dev/null; then
                echo "Critical vulnerabilities found!"
                CRITICAL_ISSUES=true
              fi
            fi
          else
            echo "‚ö†Ô∏è Safety not available, skipping dependency scan"
          fi
          
          # Enhanced dependency audit with pip-audit
          echo "Running pip-audit dependency audit..."
          if command -v pip-audit >/dev/null 2>&1; then
            if pip-audit --format=json --output=pip-audit-report.json; then
              echo "‚úÖ pip-audit scan passed"
            else
              echo "‚ö†Ô∏è pip-audit found vulnerable dependencies"
              SECURITY_FAILED=true
            fi
          else
            echo "‚ö†Ô∏è pip-audit not available, skipping enhanced audit"
          fi
          
          # Advanced security scanning with Semgrep
          echo "Running Semgrep advanced security analysis..."
          if command -v semgrep >/dev/null 2>&1; then
            if semgrep --config=auto --json --output=semgrep-report.json --severity=ERROR --severity=WARNING .; then
              echo "‚úÖ Semgrep scan passed"
            else
              echo "‚ö†Ô∏è Semgrep found potential security issues"
              SECURITY_FAILED=true
            fi
          else
            echo "‚ö†Ô∏è Semgrep not available, skipping pattern analysis"
          fi
          
          # Determine final security status
          if [ "$CRITICAL_ISSUES" = "true" ]; then
            echo "‚ùå CRITICAL: High-severity security issues found"
            echo "passed=false" >> $GITHUB_OUTPUT
            exit 1
          elif [ "$SECURITY_FAILED" = "true" ]; then
            echo "‚ö†Ô∏è Security issues found but not critical"
            echo "passed=partial" >> $GITHUB_OUTPUT
            # Continue but mark as partial failure
          else
            echo "‚úÖ All security scans passed"
            echo "passed=true" >> $GITHUB_OUTPUT
          fi

      - name: Test coverage analysis
        id: coverage
        timeout-minutes: 15
        run: |
          echo "üìä Running test coverage analysis..."
          source .venv/bin/activate
          
          pytest --cov=services --cov=scripts \
                 --cov-report=xml --cov-report=term-missing \
                 --cov-fail-under=${{ env.COVERAGE_THRESHOLD }} \
                 --timeout=300
          
          COVERAGE=$(python -c "
          import xml.etree.ElementTree as ET
          try:
              tree = ET.parse('coverage.xml')
              coverage = float(tree.getroot().attrib['line-rate']) * 100
              print(f'{coverage:.1f}')
          except:
              print('0.0')
          ")
          
          echo "score=$COVERAGE" >> $GITHUB_OUTPUT
          echo "Coverage: $COVERAGE%"

      - name: Upload coverage reports
        uses: codecov/codecov-action@v4
        with:
          file: coverage.xml
          flags: unittests
          name: acgs-coverage

      - name: Upload security reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: security-reports
          path: |
            bandit-report.json
            safety-report.json
            pip-audit-report.json
            semgrep-report.json
          retention-days: 30

  # Rust/Blockchain specific validation
  blockchain-validation:
    name: Blockchain & Rust Validation
    runs-on: ubuntu-latest
    needs: [preflight, quality-gates]
    if: needs.preflight.outputs.rust_changed == 'true' && needs.quality-gates.outputs.quality_passed == 'true'
    timeout-minutes: 30
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install Rust toolchain
        uses: dtolnay/rust-toolchain@stable
        with:
          toolchain: ${{ env.RUST_TOOLCHAIN }}
          components: rustfmt, clippy

      - name: Cache Rust dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.cargo/bin/
            ~/.cargo/registry/index/
            ~/.cargo/registry/cache/
            ~/.cargo/git/db/
            blockchain/target/
          key: ${{ runner.os }}-cargo-${{ env.RUST_TOOLCHAIN }}-${{ hashFiles('**/Cargo.lock') }}
          restore-keys: |
            ${{ runner.os }}-cargo-${{ env.RUST_TOOLCHAIN }}-
            ${{ runner.os }}-cargo-

      - name: Install Solana CLI
        timeout-minutes: 5
        run: |
          echo "Installing Solana CLI v${{ env.SOLANA_CLI_VERSION }}..."
          curl -sSfL https://release.solana.com/stable/install | sh
          echo "$HOME/.local/share/solana/install/active_release/bin" >> $GITHUB_PATH

      - name: Install Anchor CLI
        timeout-minutes: 8
        run: |
          echo "Installing Anchor CLI v${{ env.ANCHOR_CLI_VERSION }}..."
          npm install -g @coral-xyz/anchor-cli@${{ env.ANCHOR_CLI_VERSION }}

      - name: Setup Node.js for blockchain
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: 'blockchain/package-lock.json'

      - name: Install blockchain dependencies
        working-directory: blockchain
        timeout-minutes: 5
        run: |
          if [ -f "package.json" ]; then
            npm ci --legacy-peer-deps
          fi

      - name: Rust quality checks
        working-directory: blockchain
        timeout-minutes: 8
        run: |
          echo "Running Rust quality checks..."
          cargo fmt --all -- --check
          cargo clippy --all-targets --all-features -- -D warnings

      - name: Build Anchor programs
        working-directory: blockchain
        timeout-minutes: 15
        run: |
          echo "Building Anchor programs..."
          solana config set --url localhost
          anchor build --skip-lint

      - name: Rust security audit
        working-directory: blockchain
        timeout-minutes: 10
        run: |
          echo "Running Rust security audit..."
          
          # Install cargo-audit if not cached
          cargo install cargo-audit --version 0.21.1 --locked || true
          
          # Run security audit with configuration
          cargo audit --deny warnings \
            --ignore RUSTSEC-2021-0145 \
            --ignore RUSTSEC-2023-0033 \
            --ignore RUSTSEC-2024-0375 \
            --ignore RUSTSEC-2024-0388 \
            --ignore RUSTSEC-2024-0436 \
            --ignore RUSTSEC-2024-0344

      - name: Run Anchor tests
        working-directory: blockchain
        timeout-minutes: 10
        run: |
          echo "Running Anchor test suite..."
          # Start validator in background
          solana-test-validator --reset --quiet &
          VALIDATOR_PID=$!
          
          # Wait for validator
          sleep 15
          timeout 30 bash -c 'until solana cluster-version; do sleep 1; done'
          
          # Run tests
          anchor test --skip-local-validator || TEST_RESULT=$?
          
          # Cleanup
          kill $VALIDATOR_PID || true
          
          exit ${TEST_RESULT:-0}

      - name: Upload blockchain artifacts
        uses: actions/upload-artifact@v4
        with:
          name: blockchain-artifacts
          path: |
            blockchain/target/deploy/
            blockchain/target/idl/
          retention-days: 7

  # Container security and build validation
  container-security:
    name: Container Security & Build
    runs-on: ubuntu-latest
    needs: [preflight, quality-gates]
    if: needs.preflight.outputs.should_run_tests == 'true' && needs.quality-gates.outputs.security_passed == 'true'
    timeout-minutes: 20
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build test image
        timeout-minutes: 10
        run: |
          docker build -t acgs-security-test:latest .

      - name: Container vulnerability scan
        uses: aquasecurity/trivy-action@0.31.0
        with:
          image-ref: 'acgs-security-test:latest'
          format: 'sarif'
          output: 'trivy-results.sarif'
          severity: 'CRITICAL,HIGH,MEDIUM'

      - name: Upload container scan results
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: 'trivy-results.sarif'

      - name: Filesystem security scan
        uses: aquasecurity/trivy-action@0.31.0
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-fs-results.sarif'
          severity: 'CRITICAL,HIGH'

      - name: Upload filesystem scan results
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: 'trivy-fs-results.sarif'

  # Performance and integration testing
  integration-tests:
    name: Integration & Performance Tests
    runs-on: ubuntu-latest
    needs: [preflight, quality-gates, blockchain-validation]
    if: needs.preflight.outputs.should_run_tests == 'true' && needs.quality-gates.outputs.quality_passed == 'true'
    timeout-minutes: 20
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python with UV
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install UV package manager
        uses: astral-sh/setup-uv@v6
        with:
          enable-cache: true

      - name: Install dependencies
        timeout-minutes: 5
        run: |
          uv venv --python ${{ env.PYTHON_VERSION }}
          source .venv/bin/activate
          uv pip install -e .[dev,test] --index-strategy unsafe-best-match

      - name: Run integration tests
        timeout-minutes: 12
        run: |
          source .venv/bin/activate
          echo "Running integration test suite..."
          pytest tests/integration/ -v --timeout=600 || true

      - name: Performance baseline validation
        timeout-minutes: 5
        run: |
          source .venv/bin/activate
          echo "Running performance baseline tests..."
          python scripts/test_simple_performance.py || true

  # Deployment orchestration
  deployment:
    name: Multi-Environment Deployment
    runs-on: ubuntu-latest
    needs: [preflight, quality-gates, blockchain-validation, container-security, integration-tests]
    if: needs.preflight.outputs.should_deploy == 'true' && needs.quality-gates.outputs.quality_passed == 'true'
    timeout-minutes: 15
    environment:
      name: ${{ needs.preflight.outputs.target_environment }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Build and push images
        timeout-minutes: 10
        run: |
          ENVIRONMENT="${{ needs.preflight.outputs.target_environment }}"
          IMAGE_TAG="${ENVIRONMENT}-${{ github.sha }}"
          
          echo "Building for environment: $ENVIRONMENT"
          docker build -t ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:$IMAGE_TAG .
          docker push ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:$IMAGE_TAG

      - name: Deploy to environment
        timeout-minutes: 8
        run: |
          ENVIRONMENT="${{ needs.preflight.outputs.target_environment }}"
          echo "Deploying to $ENVIRONMENT environment..."
          
          # Environment-specific deployment logic
          case "$ENVIRONMENT" in
            "production")
              echo "Production deployment - implementing blue-green strategy"
              ;;
            "staging")
              echo "Staging deployment - implementing canary strategy"
              ;;
            "development")
              echo "Development deployment - implementing rolling update"
              ;;
          esac

  # Comprehensive reporting and notifications
  reporting:
    name: Pipeline Reporting
    runs-on: ubuntu-latest
    needs: [preflight, quality-gates, blockchain-validation, container-security, integration-tests, deployment]
    if: always()
    timeout-minutes: 5
    
    steps:
      - name: Generate pipeline report
        run: |
          echo "# ACGS-1 Modern CI/CD Pipeline Report" > pipeline-report.md
          echo "Generated: $(date)" >> pipeline-report.md
          echo "" >> pipeline-report.md
          echo "## Pipeline Results" >> pipeline-report.md
          echo "- Preflight: ${{ needs.preflight.result }}" >> pipeline-report.md
          echo "- Quality Gates: ${{ needs.quality-gates.result }}" >> pipeline-report.md
          echo "- Blockchain Validation: ${{ needs.blockchain-validation.result }}" >> pipeline-report.md
          echo "- Container Security: ${{ needs.container-security.result }}" >> pipeline-report.md
          echo "- Integration Tests: ${{ needs.integration-tests.result }}" >> pipeline-report.md
          echo "- Deployment: ${{ needs.deployment.result }}" >> pipeline-report.md
          echo "" >> pipeline-report.md
          echo "## Quality Metrics" >> pipeline-report.md
          echo "- Coverage: ${{ needs.quality-gates.outputs.coverage_score }}%" >> pipeline-report.md
          echo "- Target Environment: ${{ needs.preflight.outputs.target_environment }}" >> pipeline-report.md

      - name: Upload pipeline report
        uses: actions/upload-artifact@v4
        with:
          name: pipeline-report
          path: pipeline-report.md
          retention-days: 30

      - name: Notify on failure
        if: failure()
        run: |
          echo "‚ùå Pipeline failed - check individual job results"
          echo "Quality Gates: ${{ needs.quality-gates.result }}"
          echo "Security: ${{ needs.quality-gates.outputs.security_passed }}"
          echo "Coverage: ${{ needs.quality-gates.outputs.coverage_score }}%"